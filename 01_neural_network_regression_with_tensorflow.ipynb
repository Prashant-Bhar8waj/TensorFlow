{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0410e44",
   "metadata": {},
   "source": [
    "# Introduction to Regression with Neural Networks in TensorFlow\n",
    "\n",
    "There are many definations for a regression problem but in our case, we're going to simplify it: predicting a numerical variable based on some other combination of variables, even shorter...predicting a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51bf9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c4e588",
   "metadata": {},
   "source": [
    "## Creating a data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0fe0a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create features\n",
    "x =  np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "# Create lables\n",
    "y = np.array([3 , 6, 9, 12, 15, 18, 21, 24], dtype = np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccc3ee15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-7., -4., -1.,  2.,  5.,  8., 11., 14.]),\n",
       " array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float16))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f419d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1d5d4813cd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOM0lEQVR4nO3df2jc933H8ddrigZHGlCCFWNpMR4lHAuDWZsIg8BI6drL8o+VPzqWP4rHAs4fDXSsHET9p4ExCLv++Gej4NAQD9qMQhUljNJrZspMYYzJlakcvCOlOJ3vjK3QHc3gC1Ou7/3hOyO5lu6H7vS9+9zzAeLuPvrK9+aL8vT5+/1ezhEhAEA6fivvAQAAw0XYASAxhB0AEkPYASAxhB0AEkPYASAxXcNu+zHbP7J9zfZ7tr/YXn/Fdt32lfbXs6MfFwDQjbtdx277hKQTEfET2w9JuixpRdKfS/rfiPjqyKcEAPTsgW4bRMRNSTfb9z+yfU3S4qgHAwAMpusr9j0b26ckXZL0+5L+RtJfSvqVpA1JX4qI/zno548dOxanTp0acFQAmE6XL1/+MCLme92+57Db/oSkf5P0dxGxZvu4pA8lhaS/1Z3DNX91n587J+mcJJ08efKPPvjgg15nAwBIsn05IpZ73b6nq2Jsz0r6nqRvR8SaJEXErYhoRcSvJb0m6cn7/WxEnI+I5YhYnp/v+S8cAMCAerkqxpK+JelaRHx91/qJXZs9J+nq8McDAPSr68lTSU9J+rykLdtX2mtflvS87dO6cyjmuqQXRzAfAKBPvVwV82NJvs+3vj/8cQAAh8U7TwEgMb0cigEADGh9s65KtaZGM9PCXEHlUlErS6N9KxBhB4ARWd+sa3VtS9lOS5JUb2ZaXduSpJHGnUMxADAilWrtbtQ7sp2WKtXaSJ+XsAPAiDSaWV/rw0LYAWBEFuYKfa0PC2EHgBEpl4oqzM7sWSvMzqhcKo70eTl5CgAj0jlBylUxAJCQlaXFkYf8XhyKAYDEEHYASAxhB4DEEHYASAxhB4DEEHYASAxhB4DEEHYASAxhB4DEEHYASAxhB4DEEHYASAxhB4DEEHYASAxhB4DEEHYASAxhB4DEEHYASAxhB4DEEHYASAwfZg1goqxv1lWp1tRoZlqYK6hcKh75h0WPO8IOYGKsb9a1uralbKclSao3M62ubUkScd+FQzEAJkalWrsb9Y5sp6VKtZbTROOJsAOYGI1m1tf6tCLsACbGwlyhr/VpRdgBTIxyqajC7MyetcLsjMqlYk4TjSdOngKYGJ0TpFwVczDCDmCirCwtEvIuOBQDAInpGnbbj9n+ke1rtt+z/cX2+iO237X9fvv24dGPCwDoppdX7B9L+lJE/J6kP5b0BdtPSHpZ0sWIeFzSxfZjAEDOuoY9Im5GxE/a9z+SdE3SoqQzki60N7sgaWVEMwIA+tDXMXbbpyQtSfoPSccj4qZ0J/6SHh36dACAvvUcdtufkPQ9SX8dEb/q4+fO2d6wvbG9vT3IjACAPvQUdtuzuhP1b0fEWnv5lu0T7e+fkHT7fj8bEecjYjkilufn54cxMwDgAL1cFWNJ35J0LSK+vutb70g6275/VtLbwx8PANCvXt6g9JSkz0vasn2lvfZlSa9K+q7tFyT9QtLnRjIhAKAvXcMeET+W5H2+/enhjgMAOCzeeQoAiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AienlfwIGIHHrm3VVqjU1mpkW5goql4paWVrMeywMiLADU259s67VtS1lOy1JUr2ZaXVtS5KI+4TiUAww5SrV2t2od2Q7LVWqtZwmwmERdmDKNZpZX+sYf4QdmHILc4W+1jH+CDsw5cqlogqzM3vWCrMzKpeKOU2Ew+LkKTDlOidIuSomHYQdgFaWFgl5QjgUAwCJIewAkBjCDgCJIewAkBjCDgCJIewAkBjCDgCJIewAkBjCDgCJIewAkBjCDgCJIewAkBjCDgCJIewAkBjCDgCJIewAkBjCDgCJIewAkBjCDgCJ6Rp226/bvm376q61V2zXbV9pfz072jEBAL3q5cOs35D0D5L+6Z71b0TEV4c+EZCA9c26KtWaGs1MC3MFlUtFPiwaR6Zr2CPiku1TRzALkIT1zbpW17aU7bQkSfVmptW1LUki7jgShznG/pLtn7YP1Tw8tImACVep1u5GvSPbaalSreU0EabNoGH/pqRPSjot6aakr+23oe1ztjdsb2xvbw/4dMDkaDSzvtaBYRso7BFxKyJaEfFrSa9JevKAbc9HxHJELM/Pzw86JzAxFuYKfa0DwzZQ2G2f2PXwOUlX99sWmDblUlGF2Zk9a4XZGZVLxZwmwrTpevLU9puSnpZ0zPYNSV+R9LTt05JC0nVJL45uRGCydE6QclUM8uKIOLInW15ejo2NjSN7PgBIge3LEbHc6/a88xQAEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxD+Q9ANCr9c26KtWaGs1MC3MFlUtFrSwt5j0WMHYIOybC+mZdq2tbynZakqR6M9Pq2pYkEXfgHhyKwUSoVGt3o96R7bRUqdZymggYX4QdE6HRzPpaB6YZYcdEWJgr9LUOTDPCjolQLhVVmJ3Zs1aYnVG5VMxpImB8cfIUE6FzgpSrYoDuCDsmxsrSIiEHesChGABIDGEHgMQQdgBIDGEHgMQQdgBIDGEHgMQQdgBIDGEHgMQQdgBIDGEHgMR0Dbvt123ftn1119ojtt+1/X779uHRjgkA6FUvr9jfkPTMPWsvS7oYEY9Luth+DAAYA13DHhGXJP3ynuUzki6071+QtDLcsQAAgxr0GPvxiLgpSe3bR4c3EgDgMEZ+8tT2Odsbtje2t7dH/XQAMPUGDfst2yckqX17e78NI+J8RCxHxPL8/PyATwcA6NWgYX9H0tn2/bOS3h7OOACAw+rlcsc3Jf27pKLtG7ZfkPSqpM/Yfl/SZ9qPAQBjoOtH40XE8/t869NDngUAMAS88xQAEsOHWU+x9c26KtWaGs1MC3MFlUtFPiwaSABhn1Lrm3Wtrm0p22lJkurNTKtrW5JE3IEJx6GYKVWp1u5GvSPbaalSreU0EYBhIexTqtHM+loHMDkI+5RamCv0tQ5gchD2KVUuFVWYndmzVpidUblUzGkiAMPCydMp1TlBylUxQHoI+xRbWVok5ECCOBQDAIkh7ACQGMIOAIkh7ACQGMIOAIkh7ACQGMIOAIkh7ACQGMIOAIkh7ACQGMIOAIkh7ACQGMIOAIkh7ACQGMIOAIkh7ACQGMIOAIkh7ACQGMIOAIkh7ACQGMIOAIl5IO8BUrO+WVelWlOjmWlhrqByqaiVpcW8xwIwRQj7EK1v1rW6tqVspyVJqjczra5tSRJxB3BkOBQzRJVq7W7UO7KdlirVWk4TAZhGhH2IGs2sr3UAGAXCPkQLc4W+1gFgFAj7EJVLRRVmZ/asFWZnVC4Vc5oIwDTi5OkQdU6QclUMgDwR9iFbWVok5ABydaiw274u6SNJLUkfR8TyMIYCAAxuGK/YPxURHw7hzwEADAEnTwEgMYcNe0j6oe3Lts8NYyAAwOEc9lDMUxHRsP2opHdt/1dEXNq9QTv45yTp5MmTh3w6AEA3h3rFHhGN9u1tSW9JevI+25yPiOWIWJ6fnz/M0wEAejBw2G0/aPuhzn1Jn5V0dViDAQAGc5hDMcclvWW78+d8JyJ+MJSpAAADGzjsEfFzSX8wxFkAAEPA5Y4AkBjCDgCJIewAkBjCDgCJIewAkBjCDgCJIewAkBjCDgCJIewAkBjCDgCJIewAkJix/zDr9c26KtWaGs1MC3MFlUtFPiwaAA4w1mFf36xrdW1L2U5LklRvZlpd25Ik4g4A+xjrQzGVau1u1DuynZYq1VpOEwHA+BvrsDeaWV/rAIAxD/vCXKGvdQDAmIe9XCqqMDuzZ60wO6NyqZjTRAAw/sb65GnnBClXxQBA78Y67NKduBNyAOjdWB+KAQD0j7ADQGIIOwAkhrADQGIIOwAkxhFxdE9mb0v64Mie8PCOSfow7yHGHPvoYOyf7thHBzsm6cGImO/1B4407JPG9kZELOc9xzhjHx2M/dMd++hgg+wfDsUAQGIIOwAkhrAf7HzeA0wA9tHB2D/dsY8O1vf+4Rg7ACSGV+wAkBjC3oXtV2zXbV9pfz2b90zjwPYztmu2f2b75bznGUe2r9veav/ebOQ9T95sv277tu2ru9Yesf2u7ffbtw/nOWPe9tlHfTeIsPfmGxFxuv31/byHyZvtGUn/KOnPJD0h6XnbT+Q71dj6VPv3hsv5pDckPXPP2suSLkbE45Iuth9Pszf0m/tI6rNBhB2DeFLSzyLi5xHxf5L+WdKZnGfCmIuIS5J+ec/yGUkX2vcvSFo5ypnGzT77qG+EvTcv2f5p+59JU/1PxbZFSf+96/GN9hr2Ckk/tH3Z9rm8hxlTxyPipiS1bx/NeZ5x1VeDCLsk2/9q++p9vs5I+qakT0o6LemmpK/lOeuY8H3WuLzqNz0VEX+oO4esvmD7T/IeCBOp7waN/ScoHYWI+NNetrP9mqR/GfE4k+CGpMd2Pf4dSY2cZhlbEdFo3962/ZbuHMK6lO9UY+eW7RMRcdP2CUm38x5o3ETErc79XhvEK/Yu2r9sHc9JurrftlPkPyU9bvt3bf+2pL+Q9E7OM40V2w/afqhzX9Jnxe/O/bwj6Wz7/llJb+c4y1gapEG8Yu/u722f1p1DDdclvZjrNGMgIj62/ZKkqqQZSa9HxHs5jzVujkt6y7Z057+z70TED/IdKV+235T0tKRjtm9I+oqkVyV91/YLkn4h6XP5TZi/ffbR0/02iHeeAkBiOBQDAIkh7ACQGMIOAIkh7ACQGMIOAIkh7ACQGMIOAIkh7ACQmP8HZ8fRmwFzBQ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a Scatter plot\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f4c6616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == x + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36548d47",
   "metadata": {},
   "source": [
    "## Input and output shapes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8496e68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700])>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a demo tensor for our housing price prediction problem\n",
    "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
    "house_price = tf.constant([939700])\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9cfe75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), ())"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = x[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape,  output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe96fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn Our NumPy arrays as tensor with dtype float32\n",
    "x = tf.cast(tf.constant(x), dtype = tf.float32)\n",
    "y = tf.cast(tf.constant(y), dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7ffa98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8]), TensorShape([8]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899213eb",
   "metadata": {},
   "source": [
    "## Steps in modelling with TensorFlow\n",
    "\n",
    "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
    "2. **Compiling a model** - define the loss function( in other words, the function which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
    "3. **Fitting a model** - letting the model try to find patterns between x and y (features and labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5d802c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 998us/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 984us/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 998us/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d5d61c02e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model using the sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1) #with 1 neuron\n",
    "])\n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss = tf.keras.losses.mae, # mean absoloute error\n",
    "              optimizer = tf.keras.optimizers.SGD(), # sgd = stochasti c gradient descent\n",
    "              metrics = ['mae'])\n",
    "# 3. fit the model \n",
    "model.fit(x, y, epochs=5 ) #epochs = 5 mean you have 5 opportunity to go through all of x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5043626f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out x and y\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37f4910d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.716021]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try and make a prediction using our model\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd9855",
   "metadata": {},
   "source": [
    "### Improving the Model\n",
    "\n",
    "we can improve our model, by altering the steps we took to create a model.\n",
    "\n",
    "1. **Creating a model** - Here we might add more layers, increase the numbr of hidden units(all called neurons) within each of the hidden layers, change the activation function of the layer.\n",
    "2. **Compiling a model** - here we might change the optimization function or perhaps the learning rate of the optimization function.\n",
    "3. **Fitting a model** - here wr might fit a model for more epochs(leave it training for longer) or on more data(give the model more examples to learn from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a12d5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 988us/step - loss: 11.2219 - mae: 11.2219\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 989us/step - loss: 11.0894 - mae: 11.0894\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 10.9569 - mae: 10.9569\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.8244 - mae: 10.8244\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 984us/step - loss: 10.6919 - mae: 10.6919\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.5594 - mae: 10.5594\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.4269 - mae: 10.4269\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 988us/step - loss: 10.2944 - mae: 10.2944\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.1619 - mae: 10.1619\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.0294 - mae: 10.0294\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 9.8969 - mae: 9.8969\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 9.7644 - mae: 9.7644\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 9.6319 - mae: 9.6319\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 9.4994 - mae: 9.4994\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 895us/step - loss: 9.3669 - mae: 9.3669\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.2344 - mae: 9.2344\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 729us/step - loss: 9.1019 - mae: 9.1019\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 8.9694 - mae: 8.9694\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 8.8369 - mae: 8.8369\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.7044 - mae: 8.7044\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 8.5719 - mae: 8.5719\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 947us/step - loss: 8.4394 - mae: 8.4394\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 8.3069 - mae: 8.3069\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 8.1744 - mae: 8.1744\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.0419 - mae: 8.0419\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.9094 - mae: 7.9094\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 10us/step - loss: 7.7769 - mae: 7.7769\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.6444 - mae: 7.6444\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.5119 - mae: 7.5119\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 7.3794 - mae: 7.3794\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.2750 - mae: 7.2750\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2694 - mae: 7.2694\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.2638 - mae: 7.2638\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.2581 - mae: 7.2581\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.2525 - mae: 7.2525\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.2469 - mae: 7.2469\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 896us/step - loss: 7.2412 - mae: 7.2412\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.2356 - mae: 7.2356\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.2300 - mae: 7.2300\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.2244 - mae: 7.2244\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.2188 - mae: 7.2188\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 990us/step - loss: 7.2131 - mae: 7.2131\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.2075 - mae: 7.2075\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2019 - mae: 7.2019\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.1962 - mae: 7.1962\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.1906 - mae: 7.1906\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.1850 - mae: 7.1850\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.1794 - mae: 7.1794\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 7.1737 - mae: 7.1737\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 7.1681 - mae: 7.1681\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 7.1625 - mae: 7.1625\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 988us/step - loss: 7.1569 - mae: 7.1569\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.1512 - mae: 7.1512\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 942us/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.1400 - mae: 7.1400\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 7.1344 - mae: 7.1344\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.1287 - mae: 7.1287\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 7.1231 - mae: 7.1231\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.1175 - mae: 7.1175\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.1119 - mae: 7.1119\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 7.1062 - mae: 7.1062\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.1006 - mae: 7.1006\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.0894 - mae: 7.0894\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.0781 - mae: 7.0781\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.0725 - mae: 7.0725\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 987us/step - loss: 7.0669 - mae: 7.0669\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.0613 - mae: 7.0613\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 970us/step - loss: 7.0556 - mae: 7.0556\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.0500 - mae: 7.0500\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.0444 - mae: 7.0444\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 980us/step - loss: 7.0388 - mae: 7.0388\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.0331 - mae: 7.0331\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.0275 - mae: 7.0275\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0219 - mae: 7.0219\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0163 - mae: 7.0163\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0106 - mae: 7.0106\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.0050 - mae: 7.0050\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9994 - mae: 6.9994\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9938 - mae: 6.9938\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9825 - mae: 6.9825\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9769 - mae: 6.9769\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9656 - mae: 6.9656\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 6.9600 - mae: 6.9600\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9544 - mae: 6.9544\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 889us/step - loss: 6.9488 - mae: 6.9488\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9431 - mae: 6.9431\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9375 - mae: 6.9375\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9319 - mae: 6.9319\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.9263 - mae: 6.9263\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.9206 - mae: 6.9206\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.9150 - mae: 6.9150\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.9094 - mae: 6.9094\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9038 - mae: 6.9038\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.8981 - mae: 6.8981\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.8925 - mae: 6.8925\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.8869 - mae: 6.8869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d5d675b370>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's rebuid the model \n",
    "\n",
    "# 1. Create the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics =[\"mae\"]\n",
    "             )\n",
    "# 3. Fit the model \n",
    "model.fit(x,y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0441f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8510f60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29.739855]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6f15ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.3193 - mae: 12.3193\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 11.7804 - mae: 11.7804\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.2324 - mae: 11.2324\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.6601 - mae: 10.6601\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 561us/step - loss: 10.0632 - mae: 10.0632\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.4503 - mae: 9.4503\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.7991 - mae: 8.7991\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.1072 - mae: 8.1072\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.3691 - mae: 7.3691\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.5758 - mae: 6.5758\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.7205 - mae: 5.7205\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 4.7947 - mae: 4.7947\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 911us/step - loss: 4.3581 - mae: 4.3581\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 4.3134 - mae: 4.3134\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2550 - mae: 4.2550\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 4.2442 - mae: 4.2442\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 4.1520 - mae: 4.1520\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4.1739 - mae: 4.1739\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4.0681 - mae: 4.0681\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 4.0807 - mae: 4.0807\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9954 - mae: 3.9954\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.9739 - mae: 3.9739\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.9208 - mae: 3.9208\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 992us/step - loss: 3.9047 - mae: 3.9047\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 992us/step - loss: 3.9267 - mae: 3.9267\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8797 - mae: 3.8797\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 3.9341 - mae: 3.9341\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8678 - mae: 3.8678\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.9274 - mae: 3.9274\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8751 - mae: 3.8751\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.9080 - mae: 3.9080\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8893 - mae: 3.8893\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8834 - mae: 3.8834\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.8969 - mae: 3.8969\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.8581 - mae: 3.8581\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 954us/step - loss: 3.9046 - mae: 3.9046\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.8386 - mae: 3.8386\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9054 - mae: 3.9054\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8482 - mae: 3.8482\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8862 - mae: 3.8862\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8605 - mae: 3.8605\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8608 - mae: 3.8608\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8683 - mae: 3.8683\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 965us/step - loss: 3.8352 - mae: 3.8352\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8762 - mae: 3.8762\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8106 - mae: 3.8106\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.8821 - mae: 3.8821\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8234 - mae: 3.8234\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 912us/step - loss: 3.8626 - mae: 3.8626\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8328 - mae: 3.8328\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.8369 - mae: 3.8369\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8408 - mae: 3.8408\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8111 - mae: 3.8111\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8489 - mae: 3.8489\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.7850 - mae: 3.7850\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8585 - mae: 3.8585\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 897us/step - loss: 3.7982 - mae: 3.7982\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8377 - mae: 3.8377\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.8062 - mae: 3.8062\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8117 - mae: 3.8117\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8144 - mae: 3.8144\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.7856 - mae: 3.7856\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8227 - mae: 3.8227\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7593 - mae: 3.7593\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.8352 - mae: 3.8352\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.7725 - mae: 3.7725\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 965us/step - loss: 3.8115 - mae: 3.8115\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7807 - mae: 3.7807\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.7853 - mae: 3.7853\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 923us/step - loss: 3.7891 - mae: 3.7891\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7588 - mae: 3.7588\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.7975 - mae: 3.7975\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.7337 - mae: 3.7337\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.8105 - mae: 3.8105\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 3.7478 - mae: 3.7478\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.7840 - mae: 3.7840\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.7563 - mae: 3.7563\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7575 - mae: 3.7575\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7648 - mae: 3.7648\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7307 - mae: 3.7307\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.7735 - mae: 3.7735\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7125 - mae: 3.7125\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.7820 - mae: 3.7820\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7242 - mae: 3.7242\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.7552 - mae: 3.7552\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.7329 - mae: 3.7329\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 538us/step - loss: 3.7284 - mae: 3.7284\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.7416 - mae: 3.7416\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7013 - mae: 3.7013\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7505 - mae: 3.7505\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.6921 - mae: 3.6921\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7522 - mae: 3.7522\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 880us/step - loss: 3.7016 - mae: 3.7016\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.7251 - mae: 3.7251\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7105 - mae: 3.7105\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.6979 - mae: 3.6979\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.7194 - mae: 3.7194\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.6705 - mae: 3.6705\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.7299 - mae: 3.7299\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.6711 - mae: 3.6711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d5d79aad00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create a model with 1 hidden layer\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(100, activation =\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics = ['mae'])\n",
    "\n",
    "# 3. Fit the model\n",
    "\n",
    "model.fit(x,y , epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "462394ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31.223137]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f6938",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "\n",
    "In Practice, a typical workflow you'll when building a neural networks is:\n",
    "\n",
    "```Build a model -> fit it -> evaluate it -> tewak a model -> fit it -> evaluate it -> tweal a model -> fit it -> evaluate it...```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f769981",
   "metadata": {},
   "source": [
    "When it comes to evaluation.. there are 3 words you should memorize:\n",
    "    \n",
    "> \"Visuallize, Visuallize and Visuallize\"\n",
    "\n",
    "It's good idea to visualize:\n",
    "* The data - what are we working with? what does it look like?\n",
    "* The model itself - what does our model look like?\n",
    "* The training of a model - how does a model perform while it learns?\n",
    "* The Predictions of the model - how do the predictions of a model line up against the ground truth(the original labels)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5189e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a bigger dataset \n",
    "x= tf.range(-100,100,4)\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f77fc9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x+10\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53f89ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1d5d7c44ee0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec885a03",
   "metadata": {},
   "source": [
    "###  The Three sets..\n",
    "\n",
    "* Training set\n",
    "* validation set\n",
    "* Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4036137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test sets\n",
    "x_train = x[:40]\n",
    "y_train = y[:40]\n",
    "x_test = x[40:]\n",
    "y_test = y[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "755755f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5273 - mae: 10.5273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d5d7c7fa60>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let' have alook at hoe to build a neural network for our data\n",
    "\n",
    "# 1. Create a model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "          \n",
    "# 2. compile the model\n",
    "model.compile(loss= tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "              metrics = ['mae'])\n",
    "# 3. Fit the model\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcafdf1",
   "metadata": {},
   "source": [
    "### Visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f78989ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e2eb1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a model which automatically by defining the input shape argument in the first layer\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model = tf.keras.Sequential(name= \"model_1\")\n",
    "model.add(tf.keras.layers.Dense(10, input_shape = [1], name=\"input_layer\")) # Define the no. of inputs you have\n",
    "model.add(tf.keras.layers.Dense(1, name=\"output_layers\"))\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics =[\"mae\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a22d5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "output_layers (Dense)        (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91789b9",
   "metadata": {},
   "source": [
    "Dense layer is the Fully Connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6065f0e0",
   "metadata": {},
   "source": [
    "* Total params - total number of parameters in the model.\n",
    "* Trainable params - these are the parameters (patterns) th model can update as it trains.\n",
    "* Non-trainable params - there parameters aren't updated during training(this is typical when you bring in already learn patterns or parameters from other model during **transfer learning**) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a754977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d5d7e9e310>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's first our model to the training data \n",
    "model.fit(x_train, y_train, epochs = 100, verbose= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af2a86a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model= model, show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b72243",
   "metadata": {},
   "source": [
    "### Visualizing our model's predictions\n",
    "\n",
    "To visualize predictions, it's a good idea to plot them against the ground truth labels.\n",
    "\n",
    "often you'll see this in the form of `y_test` or `y_true` versus `y_pred` (ground truth versus your model's predicitons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b99f99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 70.552185],\n",
       "       [ 75.13991 ],\n",
       "       [ 79.72764 ],\n",
       "       [ 84.315346],\n",
       "       [ 88.90308 ],\n",
       "       [ 93.49081 ],\n",
       "       [ 98.07852 ],\n",
       "       [102.666245],\n",
       "       [107.253975],\n",
       "       [111.84169 ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predicitons \n",
    "y_preds = model.predict(x_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "186f2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create a plotting function\n",
    "def plot_predictions(train_data = x_train,\n",
    "                     train_labels = y_train,\n",
    "                     test_data = x_test,\n",
    "                     test_labels = y_test,\n",
    "                     predictions = y_preds):\n",
    "    \"\"\"\n",
    "    plots training data, test data and compares predictions to ground truthlabels.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize = (10,7))\n",
    "    # plot training data in blue\n",
    "    plt.scatter(train_data, train_labels, c='b', label ='Training data')\n",
    "    #plot testing data in green\n",
    "    plt.scatter(test_data, test_labels, c='g' , label ='Testing data')\n",
    "    #plot model's predictions in red\n",
    "    plt.scatter(test_data, predictions, c= 'r', label='Predictons')\n",
    "    #show the legend\n",
    "    plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36c6caf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b337b7",
   "metadata": {},
   "source": [
    "###  Evalutaing our model's predictions with regression evaluation metrics\n",
    "\n",
    "Depending on the model you're woring on, there will be different evalutation metrics to evaluate your model's predictions\n",
    "\n",
    "Since we are working on regression, two of the main metrics:\n",
    "* MAE- mean absoloute error, \"on average, how wrong is each of my model's predictions\" - should use when larger errors are more significant than smaller error\n",
    "* MSE - mean square error, \"square the average errors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b4a6b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 3.1969 - mae: 3.1969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.196941375732422, 3.196941375732422]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb89c388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 70.552185,  75.13991 ,  79.72764 ,  84.315346,  88.90308 ,\n",
       "        93.49081 ,  98.07852 , 102.666245, 107.253975, 111.84169 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f00548e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.19694>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the mean absoloute error\n",
    "mae = tf.metrics.mean_absolute_error(y_test, tf.squeeze(y_preds))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d7fa489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean squared error\n",
    "mse = tf.metrics.mean_squared_error(y_test, tf.squeeze(y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7abb220e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=13.070127>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165e6abc",
   "metadata": {},
   "source": [
    "### Running experiments to improve our model\n",
    "\n",
    "\n",
    "1. Get more data - get more examples for your model to train on(more opportunities to learn patterns or relationships between features and labels).\n",
    "2. Make your model larger (using a more complex model) - this might come in the form of more layers or more hidden units in each layer.\n",
    "3. Train for longer - Give your model more of a chance to find patterns in the data.\n",
    "\n",
    "\n",
    "Let's do 3 modelling experiments:\n",
    "\n",
    "1. `model_1` - same as the original model, 1 layer, trained for 100 epochs\n",
    "2. `mdoel_2` - 2 layers, trained for 100 epochs.\n",
    "3. `model_3` - 2 layers, trained for 500 epochs.\n",
    "\n",
    "**Build** `model_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49b63490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.9024 - mae: 15.9024\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 516us/step - loss: 11.2837 - mae: 11.2837\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 469us/step - loss: 11.1075 - mae: 11.1075\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2990 - mae: 9.2990\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 994us/step - loss: 10.1677 - mae: 10.1677\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 984us/step - loss: 9.4303 - mae: 9.4303\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 8.5704 - mae: 8.5704\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.0442 - mae: 9.0442\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 516us/step - loss: 18.7517 - mae: 18.7517\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.1142 - mae: 10.1142\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.3980 - mae: 8.3980\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.6639 - mae: 10.6639\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 9.7977 - mae: 9.7977\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.0103 - mae: 16.0103\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.4068 - mae: 11.4068\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.5393 - mae: 8.5393\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.6348 - mae: 13.6348\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.4629 - mae: 11.4629\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 17.9148 - mae: 17.9148\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 15.0494 - mae: 15.0494\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 11.0216 - mae: 11.0216\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.1558 - mae: 8.1558\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.5138 - mae: 9.5138\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 7.6617 - mae: 7.6617\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 483us/step - loss: 13.1859 - mae: 13.1859\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 750us/step - loss: 16.4211 - mae: 16.4211\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 982us/step - loss: 13.1660 - mae: 13.1660\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 946us/step - loss: 14.2559 - mae: 14.2559\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.0670 - mae: 10.0670\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 991us/step - loss: 16.3409 - mae: 16.3409\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.6444 - mae: 23.6444\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 497us/step - loss: 7.6215 - mae: 7.6215\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 9.3221 - mae: 9.3221\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.7313 - mae: 13.7313\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.1276 - mae: 11.1276\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.3222 - mae: 13.3222\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.4763 - mae: 9.4763\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.1381 - mae: 10.1381\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.1793 - mae: 10.1793\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.9137 - mae: 10.9137\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 497us/step - loss: 7.9063 - mae: 7.9063\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.0914 - mae: 10.0914\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.7006 - mae: 8.7006\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 12.2046 - mae: 12.2046\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.7970 - mae: 13.7970\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 509us/step - loss: 8.4687 - mae: 8.4687\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.1330 - mae: 9.1330\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6190 - mae: 10.6190\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 994us/step - loss: 7.7503 - mae: 7.7503\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 846us/step - loss: 9.5407 - mae: 9.5407\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 9.1584 - mae: 9.1584\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.3630 - mae: 16.3630\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 14.1299 - mae: 14.1299\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 21.1247 - mae: 21.1247\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 16.3961 - mae: 16.3961\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.9806 - mae: 9.9806\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 9.9606 - mae: 9.9606\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 992us/step - loss: 9.2209 - mae: 9.2209\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.4239 - mae: 8.4239\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 993us/step - loss: 9.4869 - mae: 9.4869\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 514us/step - loss: 11.4354 - mae: 11.4354\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.6887 - mae: 11.6887\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 16.9675 - mae: 16.9675\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.4599 - mae: 12.4599\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.0184 - mae: 13.0184\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 981us/step - loss: 8.0600 - mae: 8.0600\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.1888 - mae: 10.1888\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 983us/step - loss: 12.3633 - mae: 12.3633\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.0516 - mae: 9.0516\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.0378 - mae: 10.0378\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.0516 - mae: 10.0516\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.6151 - mae: 12.6151\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 993us/step - loss: 10.3819 - mae: 10.3819\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.7229 - mae: 9.7229\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.2252 - mae: 11.2252\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 8.3642 - mae: 8.3642\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.1274 - mae: 9.1274\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 999us/step - loss: 19.5039 - mae: 19.5039\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 987us/step - loss: 14.8945 - mae: 14.8945\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 9.0034 - mae: 9.0034\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.0206 - mae: 13.0206\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.9299 - mae: 7.9299\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 999us/step - loss: 7.6872 - mae: 7.6872\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.0328 - mae: 10.0328\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 998us/step - loss: 9.2433 - mae: 9.2433\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 515us/step - loss: 12.0209 - mae: 12.0209\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.6389 - mae: 10.6389\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 979us/step - loss: 7.2667 - mae: 7.2667\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.7786 - mae: 12.7786\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.3481 - mae: 7.3481\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.7175 - mae: 7.7175\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.1263 - mae: 7.1263\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.6190 - mae: 12.6190\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.0912 - mae: 10.0912\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.3558 - mae: 9.3558\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.6834 - mae: 12.6834\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.6762 - mae: 8.6762\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 9.4693 - mae: 9.4693\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 935us/step - loss: 8.7067 - mae: 8.7067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d5d67574c0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model \n",
    "model_1 = tf.keras.Sequential()\n",
    "model_1.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "# 2. Compile the model\n",
    "model_1.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics = ['mae'])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_1.fit(x_train, y_train, epochs= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7aa4a9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D5D92750D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAGbCAYAAAAY8u5bAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtF0lEQVR4nO3de3BV9b338c+XiyDCwVu8QUmw1SJIDJjicwApKfVe6mW8YKPFByvq0UO14ynVTI+0z2TGqq0O9qk0nmOtM6nio1Vrqx5FpdSjHho0B8LNGwmlMpjiFPHEC4Tv88feiZuwk+zNXvuy1nq/ZjLJXvuyfvuS8OG31vosc3cBAAAgOAOKPQAAAICoIWABAAAEjIAFAAAQMAIWAABAwAhYAAAAARtU7AGkOvzww72ioqLYwwAAAOjXqlWr/ubuZemuK6mAVVFRoaampmIPAwAAoF9m1tbbdWwiBAAACBgBCwAAIGAELAAAgICV1D5Y6ezatUtbtmzRJ598UuyhIGno0KEaPXq0Bg8eXOyhAABQkko+YG3ZskUjRoxQRUWFzKzYw4k9d9f27du1ZcsWjR07ttjDAQCgJJX8JsJPPvlEhx12GOGqRJiZDjvsMGYUAQDoQ8kHLEmEqxLD+wEAQN9CEbAAAADChIDVj+3bt6uqqkpVVVU66qijNGrUqO7Ln332WZ/3bWpq0oIFC/pdx9SpU4Ma7l5mzpzZb3Hr3XffrY6OjrysHwCAuCr5ndyL7bDDDlNzc7MkadGiRRo+fLhuuumm7ut3796tQYPSv4zV1dWqrq7udx2vvPJKIGPdH3fffbcuu+wyDRs2rGhjAAAgaiI3g9XYKFVUSAMGJL43Nga/jiuuuELf+973VFNTo4ULF2rlypWaOnWqJk2apKlTp2rjxo2SpOXLl+sb3/iGpEQ4mzdvnmbOnKljjz1Wixcv7n684cOHd99+5syZuvDCCzVu3DjV1tbK3SVJTz/9tMaNG6fp06drwYIF3Y+b6uOPP9acOXNUWVmpSy65RB9//HH3dddee62qq6s1YcIE3XrrrZKkxYsX67333lNNTY1qamp6vR0AAMhOpGawGhul+fOlri1ebW2Jy5JUWxvsut58800tW7ZMAwcO1IcffqgVK1Zo0KBBWrZsmW655RY99thj+9xnw4YNeumll7Rz5059+ctf1rXXXrtPl9Qbb7yhtWvX6phjjtG0adP0n//5n6qurtbVV1+tFStWaOzYsbr00kvTjunee+/VsGHDtHr1aq1evVqTJ0/uvq6+vl6HHnqoOjs7NWvWLK1evVoLFizQz372M7300ks6/PDDe71dZWVlgK8cAADRF6kZrLq6z8NVl46OxPKgXXTRRRo4cKAkaceOHbrooot04okn6sYbb9TatWvT3uecc87RkCFDdPjhh+uII47Qtm3b9rnNlClTNHr0aA0YMEBVVVVqbW3Vhg0bdOyxx3b3TvUWsFasWKHLLrtMklRZWblXMHrkkUc0efJkTZo0SWvXrtW6devSPkamtwMAAL2LVMDavDm75bk46KCDun/+4Q9/qJqaGrW0tOipp57qtSNqyJAh3T8PHDhQu3fvzug2XZsJM5GuQmHTpk2688479cILL2j16tU655xz0o4x09sBAFCqGtc0quLuCg340QBV3F2hxjV52FcoA5EKWGPGZLc8KDt27NCoUaMkSQ888EDgjz9u3Di9++67am1tlSQtXbo07e1mzJihxuROZy0tLVq9erUk6cMPP9RBBx2kkSNHatu2bXrmmWe67zNixAjt3Lmz39sBAFDqGtc0av5T89W2o00uV9uONs1/an5RQlakAlZ9vdTzYLhhwxLL8+n73/++br75Zk2bNk2dnZ2BP/6BBx6oX/ziFzrzzDM1ffp0HXnkkRo5cuQ+t7v22mv10UcfqbKyUrfffrumTJkiSTrppJM0adIkTZgwQfPmzdO0adO67zN//nydddZZqqmp6fN2AACUuroX6tSxa+99hTp2dajuhTzsK9QPy2bzU75VV1d7z96m9evX64QTTsj4MRobE/tcbd6cmLmqrw9+B/di+OijjzR8+HC5u6677jodd9xxuvHGG4s2nmzfFwAA8m3AjwbItW+uMZn23Lon8PWZ2Sp3T9vHFKkZLCkRplpbpT17Et+jEK4k6b777lNVVZUmTJigHTt26Oqrry72kAAAKCljRqbfJ6i35fkUuYAVVTfeeKOam5u1bt06NTY2UgwKAEAP9bPqNWzw3v8+Dhs8TPWz8ryvUBoELAAAEAm1E2vVMLtB5SPLZTKVjyxXw+wG1U4s/OasSBWNAgCAaGpc06i6F+q0ecdmjRk5RvWz6tMGp9qJtUUJVD0RsAAAQEnrql/oOkKwq35BUkmEqXTYRAgAAEpaKdUvZCrjgGVm95vZ+2bWkrLsUDN73szeSn4/JOW6m83sbTPbaGZnBD3wQtm+fbuqqqpUVVWlo446SqNGjeq+/Nlnn/V7/+XLl+uVV17pvrxkyRI9+OCDgY8z9cTSvWlubtbTTz8d+LoBAMinzTvSn5Klt+WlIJtNhA9I+rmk1HTwA0kvuPttZvaD5OWFZjZe0hxJEyQdI2mZmR3v7sG3cObZYYcdpubmZknSokWLNHz4cN10000Z33/58uUaPny4pk6dKkm65ppr8jHMjDQ3N6upqUlnn3120cYAAEC2xowco7YdbWmXl6qMZ7DcfYWkD3osPlfSr5M//1rSeSnLH3b3T919k6S3JU3JbaiZKcQ5iFatWqWvfvWrOvnkk3XGGWdo69atkqTFixdr/Pjxqqys1Jw5c9Ta2qolS5borrvuUlVVlf70pz9p0aJFuvPOOyVJM2fO1MKFCzVlyhQdf/zx+tOf/iRJ6ujo0MUXX6zKykpdcsklOuWUU9SzgFWSnn32WY0bN07Tp0/Xb3/72+7lK1eu1NSpUzVp0iRNnTpVGzdu1GeffaZ//dd/1dKlS1VVVaWlS5emvR0AAKWmlOoXMpXrTu5HuvtWSXL3rWZ2RHL5KEmvpdxuS3LZPsxsvqT5kjQmx5MGFmInOHfXP//zP+vJJ59UWVmZli5dqrq6Ot1///267bbbtGnTJg0ZMkR///vfdfDBB+uaa67Za9brhRde2Ovxdu/erZUrV+rpp5/Wj370Iy1btky/+MUvdMghh2j16tVqaWlRVVXVPuP45JNPdNVVV+nFF1/Ul770JV1yySXd140bN04rVqzQoEGDtGzZMt1yyy167LHH9OMf/1hNTU36+c9/Lilx7sF0twMAoJR0/RueyVGEpSJfRxFammVpz8nj7g2SGqTEqXJyWWlfO8EF9SZ8+umnamlp0WmnnSZJ6uzs1NFHHy1JqqysVG1trc477zydd955GT3eBRdcIEk6+eSTu0/m/PLLL+u73/2uJOnEE09UZWXlPvfbsGGDxo4dq+OOO06SdNlll6mhoUFS4uTTc+fO1VtvvSUz065du9KuO9PbAQCQD5lWL0ilU7+QqVyPItxmZkdLUvL7+8nlWyR9IeV2oyW9l+O6+lWIneDcXRMmTFBzc7Oam5u1Zs0aPffcc5KkP/zhD7ruuuu0atUqnXzyydq9e3e/jzdkyBBJ0sCBA7tvn+n5Ic3S5Vjphz/8oWpqatTS0qKnnnpKn3zySU63AwAgaF1bndp2tMnl3Vud8rFrTzHkGrB+J2lu8ue5kp5MWT7HzIaY2VhJx0lameO6+lWIcxANGTJE7e3tevXVVyVJu3bt0tq1a7Vnzx795S9/UU1NjW6//Xb9/e9/10cffaQRI0Zo586dWa1j+vTpeuSRRyRJ69at05o1a/a5zbhx47Rp0ya98847kqSHHnqo+7odO3Zo1KjEFtkHHnige3nPsfR2OwAA8i2M1QvZyKam4SFJr0r6spltMbMrJd0m6TQze0vSacnLcve1kh6RtE7Ss5KuK8QRhIXYCW7AgAF69NFHtXDhQp100kmqqqrSK6+8os7OTl122WWaOHGiJk2apBtvvFEHH3ywZs+erccff7x7J/dM/NM//ZPa29tVWVmpn/zkJ6qsrNTIkSP3us3QoUPV0NCgc845R9OnT1d5eXn3dd///vd18803a9q0aers/Pxlr6mp0bp167p3cu/tdgAA5FsYqxeyYZlujiqE6upq73m03Pr163XCCSdk/BjZbM8tVZ2dndq1a5eGDh2qd955R7NmzdKbb76pAw44oNhD65bt+wIAQKqKuyvSVi+UjyxX6w2thR/QfjCzVe5ene66yJ0qJ2w7waXT0dGhmpoa7dq1S+6ue++9t6TCFQAAuaqfVb/Xkf9S6VcvZCNyASsKRowYkbb3CgCAqAhj9UI2CFgAACBQme6uE4WtTr0hYAEAgMAUovQ7DHKtaQAAAOgW9fqFTBGwAABAYKJev5ApAlYGBg4cqKqqKp144om66KKL1NHR0f+denHFFVfo0UcflSR95zvf0bp163q97fLly/XKK6/s97oAACi0QpR+hwEBKwMHHnigmpub1dLSogMOOEBLlizZ6/r9Len8t3/7N40fP77X6wlYAICwKUTpdxhEL2A1NkoVFdKAAYnvjcGe0+jUU0/V22+/reXLl6umpkbf+ta3NHHiRHV2dupf/uVf9JWvfEWVlZX65S9/KSlxXsHrr79e48eP1znnnKP333+/+7FmzpzZXcfw7LPPavLkyTrppJM0a9Ystba2asmSJbrrrru6W+Db2to0a9YsVVZWatasWdq8OTHdesUVV2jBggWaOnWqjj322O4Zsq1bt2rGjBnds2+ZNskDALC/aifWqmF2g8pHlstkKh9ZrobZDbHawV2K2lGEjY3S/PlS1ya8trbEZUmqzf2N3b17t5555hmdeeaZkqSVK1eqpaVFY8eOVUNDg0aOHKk///nP+vTTTzVt2jSdfvrpeuONN7Rx40atWbNG27Zt0/jx4zVv3ry9Hre9vV1XXXWVVqxYobFjx+qDDz7QoYceqmuuuUbDhw/XTTfdJEmaPXu2vv3tb2vu3Lm6//77tWDBAj3xxBOSEmHq5Zdf1oYNG/TNb35TF154oX7zm9/ojDPOUF1dnTo7O3PatAkAAPULmYvWDFZd3efhqktHR2J5Dj7++GNVVVWpurpaY8aM0ZVXXilJmjJlisaOHStJeu655/Tggw+qqqpKp5xyirZv36633npLK1as0KWXXqqBAwfqmGOO0de+9rV9Hv+1117TjBkzuh/r0EMPTTuOV199Vd/61rckSZdffrlefvnl7uvOO+88DRgwQOPHj9e2bdskSV/5ylf0q1/9SosWLdKaNWs0YsSInF4HAEB8ddUvtO1ok8u76xca1wS7pSgqohWwNvdyhEJvyzPUtQ9Wc3Oz7rnnnu7T1hx00EHdt3F33XPPPd2327Rpk04//XRJkpn1+fju3u9t0km9z5AhQ/Z6PEmaMWOGVqxYoVGjRunyyy/Xgw8+mPU6AACQqF/IVrQC1phejlDobXmAzjjjDN17773atWuXJOnNN9/U//zP/2jGjBl6+OGH1dnZqa1bt+qll17a577/+I//qD/+8Y/atGmTJOmDDz6QlDhlzs6dO7tvN3XqVD388MOSpMbGRk2fPr3PMbW1temII47QVVddpSuvvFKvv/56IM8VABA/1C9kJ1r7YNXX770PliQNG5ZYnmff+c531NraqsmTJ8vdVVZWpieeeELnn3++XnzxRU2cOFHHH3+8vvrVr+5z37KyMjU0NOiCCy7Qnj17dMQRR+j555/X7NmzdeGFF+rJJ5/UPffco8WLF2vevHm64447VFZWpl/96ld9jmn58uW64447NHjwYA0fPpwZLADAfhszcozadrSlXY59WdfmpFJQXV3tPU9yvH79ep1wwgmZP0hjY2Kfq82bEzNX9fWB7OCOvWX9vgAAQq3nKXCkRP1CHI8Q7GJmq9y9Ot110ZrBkhJhikAFAECgukJUJkcRIooBCwAAZCzT6gWJ+oVshCJg7e9RdsiPUtqsDADYfz03+3VVL0giSOWo5I8iHDp0qLZv384/6iXC3bV9+3YNHTq02EMBAOQoktULeT6jS6ZKfgZr9OjR2rJli9rb24s9FCQNHTpUo0ePLvYwAAA5ilz1Qp7P6JKNkg9YgwcP7m44BwAAwYlc9UJfZ3QpcMAq+U2EAAAgP+pn1WvY4GF7LRs2eJjqZ+W/PzIv8nRGl/1BwAIAIKZqJ9aqYXaDykeWy2QqH1ke7l6rIp7RpScCFgAAEdS4plEVd1dowI8GqOLuil5Pylw7sVatN7Rqz6171HpDa3jDlZQoFx+294xcoc7o0hMBCwCAiOmqX2jb0SaXd9cv9BayQiGTowNra6WGBqm8XDJLfG9oKEoBecmfKgcAAGSn4u6KtDuvl48sV+sNrYUfUK56Hh0oJWamihSeuvR1qhxmsAAAiJjI1S/0dXRgiSJgAQAQMb3VLIS2fqGEjg7MFAELAICIiVz9QgkdHZgpAhYAABETufqFEjo6MFMELAAAQiLT6gUpJPULmZ43sISODswURxECABACXdULqSdnHjZ4WHhnpkr0yMBs9HUUIQELAIAQiFz1QkVF4mTMPZWXS62thR7NfqGmAQCAkItc9UIIjwzMBgELAIAQiFz1QgiPDMxGzgHLzL5sZs0pXx+a2Q1mtsjM/pqy/OwgBgwAQBxFrnohhEcGZiPngOXuG929yt2rJJ0sqUPS48mr7+q6zt2fznVdAADEVaiqF0J23sB8CHQndzM7XdKt7j7NzBZJ+sjd78z0/uzkDgCIo8Y1jap7oU6bd2zWmJFjVD+rvjSDUyYicHRgpgq5k/scSQ+lXL7ezFab2f1mdkgvg5tvZk1m1tTe3h7wcAAAKG1d9QttO9rkcrXtaNP8p+b32XFV0kJ43sB8CGwGy8wOkPSepAnuvs3MjpT0N0ku6f9IOtrd5/X1GMxgAQDiJnL1CwMGSOmyhZm0Z0/hx5NHhZrBOkvS6+6+TZLcfZu7d7r7Hkn3SZoS4LoAAIiEyNUvRPzowEwFGbAuVcrmQTM7OuW68yW1BLguAAAiIXL1CxE/OjBTgQQsMxsm6TRJv01ZfLuZrTGz1ZJqJN0YxLoAAIiSUNUvcHRgxjhVDgAARRaKowhjdHRgpjgXIQAARRCK4JSpCJw7MGh9BaxBhR4MAABx0FW/0LErMePTVb8gKZwhK+LnDgwa5yIEACAP6l6o6w5XXTp2dajuhZD2QXF0YFYIWAAA5EHk6hc4OjArBCwAAPIgcvULHB2YFQIWAAB5EJr6hUyqF7rU1iZ2aN+zJ/GdcNUrAhYAAHlQO7FWDbMbVD6yXCZT+chyNcxuKK0d3LuqF9raEqe3aWtLXO4rZCEj1DQAAJCFxsbEeYs3b07s311fH+KJHKoXckJNAwAAAejZtdk14SOFNGRRvZA3bCIEACBDdXV7F5lLict1IW1eoHohfwhYAABkKHITPlQv5A0BCwCADIVqwocTMxcVAQsAgAyFZsInm6MDqV7ICwIWAAAZCs2ET+R2FgsfAhYAAMq8bzMUEz6R21ksfAhYAIDYi1zfZqh2FosmAhYAIPYit0UtNDuLRRcBCwAQe6HZopbNdsxQ7CwWXTS5AwBib8yY9GeMKaktatnWyNfWEqiKiBksAEDshWKLWuS2Y0YbAQsAEHuh2KIWmu2YkAhYAICIi0z9AkcGhgoBCwAQWZGqXwjFdkx0IWABACIrNLstcd7AyDF3L/YYulVXV3tTU1OxhwEAiIgBAxIzVz2ZJTYFloSeRwdKiZkpwlPJM7NV7l6d7jpmsAAAkRWK3ZZCM82GbBCwAACRFYrdljg6MJIIWACAyArFbkuhmGZDtghYAIDQybR6QQpB/UIoptmQLQIWACBUQlW9wNGBscVRhACAUKmoSH/ewPLyxAxVyeDowMjjKEIAQGSEZp9wjg6MNQIWACBUQrNPeGiSIPKBgAUACJXQ7BMemiSIfCBgAQBCJTT7hIcmCSIfAglYZtZqZmvMrNnMmpLLDjWz583sreT3Q4JYFwAgujKtXyj56gUpREkQ+RDIUYRm1iqp2t3/lrLsdkkfuPttZvYDSYe4+8K+HoejCAEgvjjoDmFTrKMIz5X06+TPv5Z0Xh7XBQAIOQ66Q5QEFbBc0nNmtsrM5ieXHenuWyUp+f2IdHc0s/lm1mRmTe3t7QENBwAQNhx0hygJKmBNc/fJks6SdJ2Zzcj0ju7e4O7V7l5dVlYW0HAAAGHDQXeIkkAClru/l/z+vqTHJU2RtM3Mjpak5Pf3g1gXACCaOOgOUZJzwDKzg8xsRNfPkk6X1CLpd5LmJm82V9KTua4LABBdHHSHKAliButISS+b2X9LWinpD+7+rKTbJJ1mZm9JOi15GQAQQ5GqXwAyMCjXB3D3dyWdlGb5dkmzcn18AEC49axfaGtLXJYIUIgumtwBAHlF/QLiiIAFAMgr6hcQRwQsAEBeUb+AOCJgAQDyivoFxBEBCwCQV9QvII5yPooQAID+1NYSqBAvzGABAPZLpt1WQBwxgwUAyBrdVkDfmMECAGSNbiugbwQsAEDW6LYC+kbAAgBkjW4roG8ELABA1ui2AvpGwAIAZI1uK6BvBCwAwF4yrV+orZVaW6U9exLfCVfA56hpAAB0o34BCAYzWACAbtQvAMEgYAEAulG/AASDgAUA6Eb9AhAMAhYAoBv1C0AwCFgAgG7ULwDBIGABQExQvwAUDjUNABAD1C8AhcUMFgDEAPULQGERsAAgBqhfAAqLgAUAMUD9AlBYBCwAiAHqF4DCImABQAxQvwAUFgELAEIs0+oFifoFoJCoaQCAkKJ6AShdzGABQEhRvQCULgIWAIQU1QtA6SJgAUBIUb0AlC4CFgCEFNULQOkiYAFASFG9AJQuAhYAlKBM6xeoXgBKU84By8y+YGYvmdl6M1trZt9NLl9kZn81s+bk19m5DxcAoq+rfqGtTXL/vH6hr44rAKXF3D23BzA7WtLR7v66mY2QtErSeZIulvSRu9+Z6WNVV1d7U1NTTuMBgLCrqEiEqp7KyxOzVABKg5mtcvfqdNflXDTq7lslbU3+vNPM1ksalevjAkBcUb8AhF+g+2CZWYWkSZL+K7noejNbbWb3m9khQa4LAKKK+gUg/AILWGY2XNJjkm5w9w8l3Svpi5KqlJjh+mkv95tvZk1m1tTe3h7UcAAgtKhfAMIvkIBlZoOVCFeN7v5bSXL3be7e6e57JN0naUq6+7p7g7tXu3t1WVlZEMMBgFCjfgEIvyCOIjRJ/y5pvbv/LGX50Sk3O19SS67rAoCwo34BiIecd3KXNE3S5ZLWmFlzctktki41sypJLqlV0tUBrAsAQqurfqHrBM1d9QsSAQqImpxrGoJETQOAKKN+AYiWvmoaaHIHgAKhfgGIDwIWABQI9QtAfBCwAKBAqF8A4oOABQAFQv0CEB8ELADIUabVCxL1C0BcBFHTAACxRfUCgHSYwQKAHNTVfR6uunR0JJYDiC8CFgDkgOoFAOkQsAAgB1QvAEiHgAUAOaB6AUA6BCwAyAHVCwDSIWABQC8yrV+gegFAT9Q0AEAa1C8AyAUzWACQBvULAHJBwAKANKhfAJALAhYApEH9AoBcELAAIA3qFwDkgoAFAGlQvwAgFwQsALFD/QKAfKOmAUCsUL8AoBCYwQIQK9QvACgEAhaAWKF+AUAhELAAxAr1CwAKgYAFIFaoXwBQCAQsALFC/QKAQiBgAYiETKsXJOoXAOQfNQ0AQo/qBQClhhksAKFH9QKAUkPAAhB6VC8AKDUELAChR/UCgFJDwAIQelQvACg1BCwAoUf1AoBSQ8ACUNIyrV+gegFAKaGmAUDJon4BQFgxgwWgZFG/ACCsCFgAShb1CwDCKu8By8zONLONZva2mf0g3+sDEB3ULwAIq7wGLDMbKOn/SjpL0nhJl5rZ+HyuE0B0UL8AIKzyPYM1RdLb7v6uu38m6WFJ5+Z5nQAigvoFAGGV74A1StJfUi5vSS7rZmbzzazJzJra29vzPBwApSDT6gWJ+gUA4ZTvgGVplvleF9wb3L3a3avLysryPBwAxdZVvdDWJrl/Xr3QV8gCgLDJd8DaIukLKZdHS3ovz+sEUMKoXgAQB/kOWH+WdJyZjTWzAyTNkfS7PK8TQAmjegFAHOQ1YLn7bknXS/oPSeslPeLua/O5TgCljeoFAHGQ9x4sd3/a3Y939y+6OwdXAzFH9QKAOKDJHUBBUb0AIA4IWAACk2n9AtULAKJuULEHACAauuoXuo4Q7KpfkAhQAOKHGSwAgaB+AQA+R8ACEAjqFwDgcwQsAIGgfgEAPkfAAhAI6hcA4HMELACBoH4BAD5HwALQL+oXACA71DQA6BP1CwCQPWawAPSJ+gUAyB4BC0CfqF8AgOwRsAD0ifoFAMgeAQtAn6hfAIDsEbAA9In6BQDIHgELiKlMqxck6hcAIFvUNAAxRPUCAOQXM1hADFG9AAD5RcACYojqBQDILwIWEENULwBAfhGwgBiiegEA8ouABcQQ1QsAkF8ELCBiMq1foHoBAPKHmgYgQqhfAIDSwAwWECHULwBAaSBgARFC/QIAlAYCFhAh1C8AQGkgYAERQv0CAJQGAhYQIdQvAEBpIGABIUH9AgCEBzUNQAhQvwAA4cIMFhAC1C8AQLgQsIAQoH4BAMKFgAWEAPULABAuBCwgBKhfAIBwySlgmdkdZrbBzFab2eNmdnByeYWZfWxmzcmvJYGMFogp6hcAIFzM3ff/zmanS3rR3Xeb2U8kyd0XmlmFpN+7+4nZPF51dbU3NTXt93gAAAAKxcxWuXt1uutymsFy9+fcfXfy4muSRufyeEDcZNptBQAIlyD3wZon6ZmUy2PN7A0z+6OZndrbncxsvpk1mVlTe3t7gMMBSltXt1Vbm+T+ebcVIQsAwq/fTYRmtkzSUWmuqnP3J5O3qZNULekCd3czGyJpuLtvN7OTJT0haYK7f9jXuthEiDipqEiEqp7KyxMN7ACA0tbXJsJ+m9zd/ev9PPhcSd+QNMuTac3dP5X0afLnVWb2jqTjJZGegCS6rQAgunI9ivBMSQslfdPdO1KWl5nZwOTPx0o6TtK7uawLiBq6rQAgunLdB+vnkkZIer5HHcMMSavN7L8lPSrpGnf/IMd1AZFCtxUARFdOJ3t29y/1svwxSY/l8thA1HV1WNXVJTYLjhmTCFd0WwFA+NHkDuRBpvULtbWJHdr37El8J1wBQDTkNIMFYF9d9Qsdyb0Su+oXJAIUAMQFM1hAwOrqPg9XXTo6EssBAPFAwAICRv0CAICABQSM+gUAAAELCBj1CwAAAhYQsNpaqaEhccobs8T3hgZ2cAeAOCFgAVmgfgEAkAlqGoAMUb8AAMgUM1hAhqhfAABkioAFZIj6BQBApghYQIaoXwAAZIqABWSI+gUAQKYIWECGqF8AAGSKgIXYy7R6QaJ+AQCQGWoaEGtULwAA8oEZLMQa1QsAgHwgYCHWqF4AAOQDAQuxRvUCACAfCFiINaoXAAD5QMBCrFG9AADIBwIWIivT+gWqFwAAQaOmAZFE/QIAoJiYwUIkUb8AACgmAhYiifoFAEAxEbAQSdQvAACKiYCFSKJ+AQBQTAQsRBL1CwCAYiJgIXSoXwAAlDpqGhAq1C8AAMKAGSyECvULAIAwIGAhVKhfAACEAQELoUL9AgAgDAhYCBXqFwAAYUDAQqhQvwAACIOcApaZLTKzv5pZc/Lr7JTrbjazt81so5mdkftQEWWZVi9I1C8AAEpfEDUNd7n7nakLzGy8pDmSJkg6RtIyMzve3TsDWB8ihuoFAEDU5GsT4bmSHnb3T919k6S3JU3J07oQclQvAACiJoiAdb2ZrTaz+83skOSyUZL+knKbLcll+zCz+WbWZGZN7e3tAQwHYUP1AgAgavoNWGa2zMxa0nydK+leSV+UVCVpq6Sfdt0tzUN5usd39wZ3r3b36rKysv17Fgg1qhcAAFHT7z5Y7v71TB7IzO6T9PvkxS2SvpBy9WhJ72U9OsRCff3e+2BJVC8AAMIt16MIj065eL6kluTPv5M0x8yGmNlYScdJWpnLuhBdVC8AAKIm132wbjezNWa2WlKNpBslyd3XSnpE0jpJz0q6jiMI4ynT+gWqFwAAUZJTTYO7X97HdfWS2MgTY9QvAADiiiZ35A31CwCAuCJgIW+oXwAAxBUBC3lD/QIAIK4IWMib+vpE3UIq6hcAAHFAwELeUL8AAIgrAhb2C/ULAAD0LqeaBsQT9QsAAPSNGSxkjfoFAAD6RsBC1qhfAACgbwQsZI36BQAA+kbAQtaoXwAAoG8ELGSN+gUAAPpGwEK3TKsXJOoXAADoCzUNkET1AgAAQWIGC5KoXgAAIEgELEiiegEAgCARsCCJ6gUAAIJEwIIkqhcAAAgSAQuSqF4AACBIBKwYyLR+geoFAACCQU1DxFG/AABA4TGDFXHULwAAUHgErIijfgEAgMIjYEUc9QsAABQeASviqF8AAKDwCFgRR/0CAACFR8AKqUyrFyTqFwAAKDRqGkKI6gUAAEobM1ghRPUCAACljYAVQlQvAABQ2ghYIUT1AgAApY2AFUJULwAAUNoIWCFE9QIAAKWNgFViMq1foHoBAIDSRU1DCaF+AQCAaMhpBsvMlppZc/Kr1cyak8srzOzjlOuWBDLaiKN+AQCAaMhpBsvdL+n62cx+KmlHytXvuHtVLo8fN9QvAAAQDYHsg2VmJuliSQ8F8XhxRf0CAADRENRO7qdK2ubub6UsG2tmb5jZH83s1N7uaGbzzazJzJra29sDGk44Ub8AAEA09BuwzGyZmbWk+To35WaXau/Zq62Sxrj7JEnfk/QbM/uHdI/v7g3uXu3u1WVlZbk8l9CjfgEAgGjoN2C5+9fd/cQ0X09KkpkNknSBpKUp9/nU3bcnf14l6R1Jx+fnKYQD9QsAAMRHEDUNX5e0wd23dC0wszJJH7h7p5kdK+k4Se8GsK5Qon4BAIB4CWIfrDnad+f2GZJWm9l/S3pU0jXu/kEA6wol6hcAAIiXnGew3P2KNMsek/RYro8dFdQvAAAQL5wqpwCoXwAAIF4IWAVA/QIAAPFCwCoA6hcAAIgXAlYOMq1ekKhfAAAgToKoaYglqhcAAEBvmMHaT1QvAACA3hCw9hPVCwAAoDcErP1E9QIAAOgNAWs/Ub0AAAB6Q8DaT1QvAACA3hCw0si0foHqBQAAkA41DT1QvwAAAHLFDFYP1C8AAIBcEbB6oH4BAADkioDVA/ULAAAgVwSsHqhfAAAAuSJg9UD9AgAAyBVHEaZRW0ugAgAA+y9WM1iZ9lsBAADkIjYzWPRbAQCAQonNDBb9VgAAoFBiE7DotwIAAIUSm4BFvxUAACiU2AQs+q0AAEChxCZg0W8FAAAKJTZHEUr0WwEAgMKIzQwWAABAoRCwAAAAAkbAAgAACBgBCwAAIGAELAAAgIARsAAAAAJGwAIAAAgYAQsAACBgBCwAAICAEbAAAAACRsACAAAIGAELAAAgYObuxR5DNzNrl9RWgFUdLulvBVhPqYr785d4DSReA4nXIO7PX+I1kHgNcnn+5e5elu6KkgpYhWJmTe5eXexxFEvcn7/EayDxGki8BnF//hKvgcRrkK/nzyZCAACAgBGwAAAAAhbXgNVQ7AEUWdyfv8RrIPEaSLwGcX/+Eq+BxGuQl+cfy32wAAAA8imuM1gAAAB5Q8ACAAAIWKQDlpldZGZrzWyPmVX3uO5mM3vbzDaa2Rkpy082szXJ6xabmRV+5PlhZkvNrDn51WpmzcnlFWb2ccp1S4o81Lwxs0Vm9teU53p2ynVpPxNRYmZ3mNkGM1ttZo+b2cHJ5bH5DEiSmZ2ZfJ/fNrMfFHs8hWBmXzCzl8xsffLv4neTy3v9nYia5N+9Ncnn2ZRcdqiZPW9mbyW/H1LsceaLmX055X1uNrMPzeyGqH8GzOx+M3vfzFpSlvX6vgf1b0Gk98EysxMk7ZH0S0k3uXvXL9R4SQ9JmiLpGEnLJB3v7p1mtlLSdyW9JulpSYvd/ZlijD+fzOynkna4+4/NrELS7939xCIPK+/MbJGkj9z9zh7Le/1MFHyQeWRmp0t60d13m9lPJMndF8bsMzBQ0puSTpO0RdKfJV3q7uuKOrA8M7OjJR3t7q+b2QhJqySdJ+lipfmdiCIza5VU7e5/S1l2u6QP3P22ZNg+xN0XFmuMhZL8PfirpFMk/W9F+DNgZjMkfSTpwa6/cb2970H+WxDpGSx3X+/uG9Ncda6kh939U3ffJOltSVOSf4D+wd1f9UTyfFCJP0CRkpyVu1iJDxES0n4mijymwLn7c+6+O3nxNUmjizmeIpki6W13f9fdP5P0sBLvf6S5+1Z3fz35805J6yWNKu6oSsK5kn6d/PnXiuDf/F7MkvSOuxfi7ClF5e4rJH3QY3Fv73tg/xZEOmD1YZSkv6Rc3pJcNir5c8/lUXOqpG3u/lbKsrFm9oaZ/dHMTi3WwArk+uQmsvtTpoV7+0xE2TxJqbOzcfkMxPG93ktyxnKSpP9KLkr3OxFFLuk5M1tlZvOTy450961SIoRKOqJooyusOdr7P9lx+Qx06e19D+zvQ+gDlpktM7OWNF99/Y803X5V3sfy0Mjw9bhUe/9ibZU0xt0nSfqepN+Y2T8UctxB6uc1uFfSFyVVKfG8f9p1tzQPFar3vksmnwEzq5O0W1JjclGkPgP9iMx7vT/MbLikxyTd4O4fqvffiSia5u6TJZ0l6brkpqPYMbMDJH1T0v9LLorTZ6A/gf19GJTjQIrO3b++H3fbIukLKZdHS3ovuXx0muWh0d/rYWaDJF0g6eSU+3wq6dPkz6vM7B1Jx0tqyuNQ8ybTz4SZ3Sfp98mLvX0mQieDz8BcSd+QNCu5KTxyn4F+ROa9zpaZDVYiXDW6+28lyd23pVyf+jsROe7+XvL7+2b2uBKbfraZ2dHuvjW5m8j7RR1kYZwl6fWu9z5On4EUvb3vgf19CP0M1n76naQ5ZjbEzMZKOk7SyuQ04U4z+1/J/ZS+LenJYg40D74uaYO7d28KNbOy5A6PMrNjlXg93i3S+PIq+YvU5XxJXUeVpP1MFHp8+WZmZ0paKOmb7t6Rsjw2nwEldmo/zszGJv8nP0eJ9z/Skn/T/l3Senf/Wcry3n4nIsXMDkru3C8zO0jS6Uo8199Jmpu82VxF729+OnttxYjLZ6CH3t73wP4tCP0MVl/M7HxJ90gqk/QHM2t29zPcfa2ZPSJpnRKbSa5LOULgWkkPSDpQif1TonYEYc/t7pI0Q9KPzWy3pE5J17h7zx0Co+J2M6tSYsq3VdLVktTPZyJKfi5piKTnE//e6jV3v0Yx+gwkj6C8XtJ/SBoo6X53X1vkYRXCNEmXS1pjyYoWSbdIujTd70QEHSnp8eTnfpCk37j7s2b2Z0mPmNmVkjZLuqiIY8w7MxumxBG0qe9z2r+LUWFmD0maKelwM9si6VZJtynN+x7kvwWRrmkAAAAohrhuIgQAAMgbAhYAAEDACFgAAAABI2ABAAAEjIAFAAAQMAIWAABAwAhYAAAAAfv/jA05ZEFVXW4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make and plot some predictions for model_1\n",
    "y_preds_1 = model_1.predict(x_test)\n",
    "plot_predictions(predictions = y_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3a60af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate model_1 evaluation metrics\n",
    "mae_1 = tf.metrics.mean_absolute_error(y_test,tf.squeeze(y_preds))\n",
    "mse_1 = tf.metrics.mean_squared_error(y_test, tf.squeeze(y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3018c61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=13.070127>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.19694>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_1, mae_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ff822e",
   "metadata": {},
   "source": [
    "**Build** `model_2`\n",
    "\n",
    "* 2 dense layers, traied for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cebf7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 979us/step - loss: 27.4058 - mae: 27.4058\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 24.6339 - mae: 24.6339\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 993us/step - loss: 29.8935 - mae: 29.8935\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 27.4055 - mae: 27.4055\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.9463 - mae: 14.9463\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.8819 - mae: 11.8819\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 999us/step - loss: 11.1988 - mae: 11.1988\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.0910 - mae: 11.0910\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 995us/step - loss: 40.4763 - mae: 40.4763\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 874us/step - loss: 27.8687 - mae: 27.8687\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.2473 - mae: 10.2473\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 25.2803 - mae: 25.2803\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.9897 - mae: 16.9897\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 991us/step - loss: 25.9217 - mae: 25.9217\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 17.9948 - mae: 17.9948\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 517us/step - loss: 7.3510 - mae: 7.3510\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 10.8636 - mae: 10.8636\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 19.5304 - mae: 19.5304\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.3469 - mae: 10.3469\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 892us/step - loss: 17.6985 - mae: 17.6985\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.8985 - mae: 15.8985\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.1991 - mae: 14.1991\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.7720 - mae: 8.7720\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 982us/step - loss: 11.0570 - mae: 11.0570\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.6838 - mae: 12.6838\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 26.1877 - mae: 26.1877\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.7432 - mae: 11.7432\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 22.8730 - mae: 22.8730\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2459 - mae: 9.2459\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 29.2641 - mae: 29.2641\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 53.0224 - mae: 53.0224\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 994us/step - loss: 11.9951 - mae: 11.9951\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.6357 - mae: 15.6357\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.6925 - mae: 12.6925\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.2398 - mae: 9.2398\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 16.6497 - mae: 16.6497\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.0382 - mae: 11.0382\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 18.1634 - mae: 18.1634\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 19.1013 - mae: 19.1013\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 20.4324 - mae: 20.4324\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 14.9102 - mae: 14.9102\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 12.2809 - mae: 12.2809\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 10.7333 - mae: 10.7333\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 23.0260 - mae: 23.0260\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.3897 - mae: 10.3897\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.7904 - mae: 11.7904\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.6438 - mae: 9.6438\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 17.2335 - mae: 17.2335\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5729 - mae: 9.5729\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.8185 - mae: 13.8185\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 11.5958 - mae: 11.5958\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 788us/step - loss: 30.5538 - mae: 30.5538\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.3541 - mae: 14.3541\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 23.9713 - mae: 23.9713\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.1938 - mae: 23.1938\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.8837 - mae: 10.8837\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.7445 - mae: 12.7445\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5995 - mae: 9.5995\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 12.5172 - mae: 12.5172\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.3200 - mae: 12.3200\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.4604 - mae: 17.4604\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.6052 - mae: 10.6052\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.4893 - mae: 10.4893\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.8450 - mae: 24.8450\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 10.6761 - mae: 10.6761\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 21.7809 - mae: 21.7809\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.7136 - mae: 10.7136\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.6397 - mae: 10.6397\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 968us/step - loss: 22.6914 - mae: 22.6914\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 9.3316 - mae: 9.3316\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 15.4355 - mae: 15.4355\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 6.7437 - mae: 6.7437\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.6891 - mae: 11.6891\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 860us/step - loss: 24.0400 - mae: 24.0400\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.5896 - mae: 9.5896\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 12.4371 - mae: 12.4371\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 16.6488 - mae: 16.6488\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.0614 - mae: 9.0614\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.9675 - mae: 23.9675\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 26.7462 - mae: 26.7462\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.6714 - mae: 11.6714\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 991us/step - loss: 12.0228 - mae: 12.0228\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 17.4218 - mae: 17.4218\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 7.2629 - mae: 7.2629\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 14.9650 - mae: 14.9650\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 525us/step - loss: 15.2862 - mae: 15.2862\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 19.1086 - mae: 19.1086\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 29.8228 - mae: 29.8228\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 978us/step - loss: 10.1742 - mae: 10.1742\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 21.5240 - mae: 21.5240\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.5716 - mae: 10.5716\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 18.3977 - mae: 18.3977\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.4138 - mae: 7.4138\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 986us/step - loss: 17.7380 - mae: 17.7380\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.1144 - mae: 11.1144\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 19.4346 - mae: 19.4346\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 12.1593 - mae: 12.1593\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 927us/step - loss: 11.5653 - mae: 11.5653\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.8827 - mae: 13.8827\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 796us/step - loss: 20.2277 - mae: 20.2277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d5d926db20>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_2 = tf.keras.Sequential()\n",
    "model_2.add(tf.keras.layers.Dense(10))\n",
    "model_2.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "# 2. Compile the model\n",
    "model_2.compile(loss = tf.keras.losses.mae,\n",
    "               optimizer = tf.keras.optimizers.SGD(),\n",
    "               metrics = ['mae'])\n",
    "\n",
    "#. Fit the model\n",
    "model_2.fit(x_train, y_train, epochs= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c524ae93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D5D9341EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions of model_2\n",
    "y_preds_2 = model_2.predict(x_test)\n",
    "plot_predictions(predictions=y_preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea06e6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=3.19694>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=13.070127>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_2 evaluation metrics\n",
    "mae_2 = tf.metrics.mean_absolute_error(y_test, tf.squeeze(y_preds_2))\n",
    "mse_2 = tf.metrics.mean_squared_error(y_test, tf.squeeze(y_preds_2))\n",
    "mae_2, mse_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25165a71",
   "metadata": {},
   "source": [
    "**Build `model_3`**\n",
    "\n",
    "* 2 layers, trained for 500 epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16d95600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 25.7765 - mae: 25.7765WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.4058 - mae: 27.4058\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 24.6339 - mae: 24.6339\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 29.8935 - mae: 29.8935\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.4055 - mae: 27.4055\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.9463 - mae: 14.9463\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.8819 - mae: 11.8819\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 11.1988 - mae: 11.1988\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 11.0910 - mae: 11.0910\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 40.4763 - mae: 40.4763\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 27.8687 - mae: 27.8687\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 982us/step - loss: 10.2473 - mae: 10.2473\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 25.2803 - mae: 25.2803\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.9897 - mae: 16.9897\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 25.9217 - mae: 25.9217\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 17.9948 - mae: 17.9948\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.3510 - mae: 7.3510\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 10.8636 - mae: 10.8636\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.5304 - mae: 19.5304\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.3469 - mae: 10.3469\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 17.6985 - mae: 17.6985\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.8985 - mae: 15.8985\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 980us/step - loss: 14.1991 - mae: 14.1991\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.7720 - mae: 8.7720\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.0570 - mae: 11.0570\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 12.6838 - mae: 12.6838\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 26.1877 - mae: 26.1877\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 981us/step - loss: 11.7432 - mae: 11.7432\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 22.8730 - mae: 22.8730\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2459 - mae: 9.2459\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 29.2641 - mae: 29.2641\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 53.0224 - mae: 53.0224\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.9951 - mae: 11.9951\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 515us/step - loss: 15.6357 - mae: 15.6357\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 980us/step - loss: 12.6925 - mae: 12.6925\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2398 - mae: 9.2398\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.6497 - mae: 16.6497\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.0382 - mae: 11.0382\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 18.1634 - mae: 18.1634\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 19.1013 - mae: 19.1013\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 20.4324 - mae: 20.4324\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 14.9102 - mae: 14.9102\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.2809 - mae: 12.2809\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.7333 - mae: 10.7333\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.0260 - mae: 23.0260\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.3897 - mae: 10.3897\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.7904 - mae: 11.7904\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 9.6438 - mae: 9.6438\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 17.2335 - mae: 17.2335\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.5729 - mae: 9.5729\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.8185 - mae: 13.8185\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 11.5958 - mae: 11.5958\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 30.5538 - mae: 30.5538\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.3541 - mae: 14.3541\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 23.9713 - mae: 23.9713\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.1938 - mae: 23.1938\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 10.8837 - mae: 10.8837\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.7445 - mae: 12.7445\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.5995 - mae: 9.5995\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 12.5172 - mae: 12.5172\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.3200 - mae: 12.3200\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 17.4604 - mae: 17.4604\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 995us/step - loss: 10.6052 - mae: 10.6052\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.4893 - mae: 10.4893\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 24.8450 - mae: 24.8450\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.6761 - mae: 10.6761\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 21.7809 - mae: 21.7809\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.7136 - mae: 10.7136\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.6397 - mae: 10.6397\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 22.6914 - mae: 22.6914\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.3316 - mae: 9.3316\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.4355 - mae: 15.4355\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 6.7437 - mae: 6.7437\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 11.6891 - mae: 11.6891\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.0400 - mae: 24.0400\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 9.5896 - mae: 9.5896\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.4371 - mae: 12.4371\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.6488 - mae: 16.6488\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.0614 - mae: 9.0614\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.9675 - mae: 23.9675\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 26.7462 - mae: 26.7462\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.6714 - mae: 11.6714\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.0228 - mae: 12.0228\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 997us/step - loss: 17.4218 - mae: 17.4218\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.2629 - mae: 7.2629\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 14.9650 - mae: 14.9650\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 15.2862 - mae: 15.2862\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.1086 - mae: 19.1086\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.8228 - mae: 29.8228\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.1742 - mae: 10.1742\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 21.5240 - mae: 21.5240\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.5716 - mae: 10.5716\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.3977 - mae: 18.3977\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 7.4138 - mae: 7.4138\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 17.7380 - mae: 17.7380\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 11.1144 - mae: 11.1144\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 19.4346 - mae: 19.4346\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.1593 - mae: 12.1593\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.5653 - mae: 11.5653\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.8827 - mae: 13.8827\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 20.2277 - mae: 20.2277\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 11.4479 - mae: 11.4479\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.4842 - mae: 17.4842\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 7.0217 - mae: 7.0217\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.5789 - mae: 23.5789\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 16.8932 - mae: 16.8932\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 9.2954 - mae: 9.2954\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 25.3749 - mae: 25.3749\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 13.4621 - mae: 13.4621\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.5238 - mae: 9.5238\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.6722 - mae: 9.6722\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 14.5987 - mae: 14.5987\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 9.5670 - mae: 9.5670\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 981us/step - loss: 17.8092 - mae: 17.8092\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.1782 - mae: 17.1782\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.1182 - mae: 11.1182\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.3071 - mae: 23.3071\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.6144 - mae: 9.6144\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 10.6899 - mae: 10.6899\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.0355 - mae: 8.0355\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 29.6859 - mae: 29.6859\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.0714 - mae: 8.0714\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 28.3086 - mae: 28.3086\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 32.9014 - mae: 32.9014\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 19.6291 - mae: 19.6291\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 497us/step - loss: 7.0095 - mae: 7.0095\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 21.8056 - mae: 21.8056\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.9812 - mae: 7.9812\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 21.0585 - mae: 21.0585\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.0107 - mae: 9.0107\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 24.0502 - mae: 24.0502\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.7537 - mae: 9.7537\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 18.3052 - mae: 18.3052\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 7.5833 - mae: 7.5833\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 18.5755 - mae: 18.5755\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.5360 - mae: 10.5360\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 18.2694 - mae: 18.2694\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.1658 - mae: 23.1658\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.1362 - mae: 9.1362\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.9181 - mae: 8.9181\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.4732 - mae: 16.4732\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.4208 - mae: 8.4208\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 995us/step - loss: 36.9540 - mae: 36.9540\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 25.5820 - mae: 25.5820\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.5392 - mae: 9.5392\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 26.6058 - mae: 26.6058\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.7248 - mae: 8.7248\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 15.6172 - mae: 15.6172\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.3065 - mae: 18.3065\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.1994 - mae: 8.1994\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 7.4964 - mae: 7.4964\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 18.3374 - mae: 18.3374\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.2895 - mae: 10.2895\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 29.6425 - mae: 29.6425\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.5556 - mae: 10.5556\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.4537 - mae: 15.4537\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.0174 - mae: 17.0174\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 32.8218 - mae: 32.8218\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.7038 - mae: 10.7038\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 8.9054 - mae: 8.9054\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 22.1321 - mae: 22.1321\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.7113 - mae: 11.7113\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 21.5734 - mae: 21.5734\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 19.2485 - mae: 19.2485\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.0156 - mae: 11.0156\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.6187 - mae: 9.6187\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 21.5908 - mae: 21.5908\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 26.2851 - mae: 26.2851\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.8525 - mae: 9.8525\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 22.5631 - mae: 22.5631\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1499 - mae: 10.1499\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.0464 - mae: 18.0464\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 28.8377 - mae: 28.8377\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.5280 - mae: 16.5280\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.2115 - mae: 11.2115\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 27.5839 - mae: 27.5839\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.2680 - mae: 8.2680\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2580 - mae: 9.2580\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.1440 - mae: 18.1440\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5995 - mae: 10.5995\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.8992 - mae: 7.8992\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 17.4015 - mae: 17.4015\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.0089 - mae: 11.0089\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 11.7027 - mae: 11.7027\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 30.4062 - mae: 30.4062\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5557 - mae: 7.5557\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.9905 - mae: 15.9905\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.5579 - mae: 8.5579\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 28.7339 - mae: 28.7339\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.1689 - mae: 13.1689\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 18.3101 - mae: 18.3101\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.7376 - mae: 13.7376\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.7104 - mae: 13.7104\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 28.5842 - mae: 28.5842\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.0707 - mae: 7.0707\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.0550 - mae: 7.0550\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 22.0067 - mae: 22.0067\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 20.8443 - mae: 20.8443\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.4713 - mae: 12.4713\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.9099 - mae: 17.9099\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 995us/step - loss: 13.7493 - mae: 13.7493\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 5.4687 - mae: 5.4687\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.7005 - mae: 13.7005\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 9.4142 - mae: 9.4142\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.9796 - mae: 20.9796\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 516us/step - loss: 9.5470 - mae: 9.5470\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 980us/step - loss: 11.7256 - mae: 11.7256\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.3772 - mae: 14.3772\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 14.8579 - mae: 14.8579\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 14.9706 - mae: 14.9706\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.8998 - mae: 17.8998\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.8327 - mae: 9.8327\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 18.3352 - mae: 18.3352\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.0383 - mae: 15.0383\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.5874 - mae: 14.5874\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 23.3015 - mae: 23.3015\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.3613 - mae: 13.3613\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.8517 - mae: 9.8517\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.5451 - mae: 12.5451\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 981us/step - loss: 4.9472 - mae: 4.9472\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.1130 - mae: 7.1130\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 35.4567 - mae: 35.4567\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 34.8634 - mae: 34.8634\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.9846 - mae: 7.9846\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 516us/step - loss: 14.7004 - mae: 14.7004\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.7196 - mae: 16.7196\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 516us/step - loss: 15.9329 - mae: 15.9329\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.1644 - mae: 16.1644\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.9324 - mae: 13.9324\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 18.0504 - mae: 18.0504\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.6120 - mae: 15.6120\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 21.2041 - mae: 21.2041\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 995us/step - loss: 25.2732 - mae: 25.2732\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 16.3176 - mae: 16.3176\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 7.2729 - mae: 7.2729\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 16.9688 - mae: 16.9688\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 7.1225 - mae: 7.1225\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.2058 - mae: 9.2058\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 497us/step - loss: 8.0961 - mae: 8.0961\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 17.0538 - mae: 17.0538\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.8627 - mae: 8.8627\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.1711 - mae: 13.1711\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 8.7886 - mae: 8.7886\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 18.8161 - mae: 18.8161\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.0531 - mae: 14.0531\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 14.6831 - mae: 14.6831\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 15.8045 - mae: 15.8045\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 17.6810 - mae: 17.6810\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.2367 - mae: 13.2367\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.5070 - mae: 14.5070\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.2322 - mae: 23.2322\n",
      "Epoch 251/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 499us/step - loss: 9.3009 - mae: 9.3009\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 36.6568 - mae: 36.6568\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 21.8205 - mae: 21.8205\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.2792 - mae: 7.2792\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 991us/step - loss: 24.7126 - mae: 24.7126\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.4220 - mae: 12.4220\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.5823 - mae: 10.5823\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 14.4883 - mae: 14.4883\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 8.6132 - mae: 8.6132\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 43.0580 - mae: 43.0580\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 18.4611 - mae: 18.4611\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 6.8820 - mae: 6.8820\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.7211 - mae: 13.7211\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 21.0154 - mae: 21.0154\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 19.3730 - mae: 19.3730\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.4735 - mae: 11.4735\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 7.5302 - mae: 7.5302\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 21.6453 - mae: 21.6453\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 33.1785 - mae: 33.1785\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 981us/step - loss: 10.0833 - mae: 10.0833\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.1012 - mae: 12.1012\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 26.1372 - mae: 26.1372\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.1751 - mae: 12.1751\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.3272 - mae: 13.3272\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 29.3775 - mae: 29.3775\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.3329 - mae: 7.3329\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 31.1362 - mae: 31.1362\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.3015 - mae: 12.3015\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 497us/step - loss: 16.4103 - mae: 16.4103\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 21.9118 - mae: 21.9118\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 22.1500 - mae: 22.1500\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.7429 - mae: 7.7429\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.1429 - mae: 8.1429\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 24.9434 - mae: 24.9434\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.6958 - mae: 13.6958\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 6.8926 - mae: 6.8926\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 24.5352 - mae: 24.5352\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.1721 - mae: 20.1721\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 11.9658 - mae: 11.9658\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.5391 - mae: 16.5391\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.8017 - mae: 16.8017\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 9.4642 - mae: 9.4642\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 15.2711 - mae: 15.2711\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 22.7179 - mae: 22.7179\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 17.9234 - mae: 17.9234\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 6.1742 - mae: 6.1742\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.9440 - mae: 10.9440\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.1530 - mae: 23.1530\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.7331 - mae: 17.7331\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 6.9824 - mae: 6.9824\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 25.1857 - mae: 25.1857\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.9025 - mae: 8.9025\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.7668 - mae: 17.7668\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.0002 - mae: 11.0002\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 12.9191 - mae: 12.9191\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.4033 - mae: 8.4033\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.6094 - mae: 13.6094\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 7.4404 - mae: 7.4404\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.4642 - mae: 9.4642\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 497us/step - loss: 10.7099 - mae: 10.7099\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.2814 - mae: 13.2814\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 29.9763 - mae: 29.9763\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.6304 - mae: 7.6304\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.9106 - mae: 9.9106\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 23.7669 - mae: 23.7669\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.3936 - mae: 16.3936\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 21.0758 - mae: 21.0758\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.9367 - mae: 7.9367\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 17.9731 - mae: 17.9731\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.2375 - mae: 10.2375\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.3338 - mae: 8.3338\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 5.0621 - mae: 5.0621\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.5109 - mae: 23.5109\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 6.8309 - mae: 6.8309\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.3863 - mae: 16.3863\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 7.5019 - mae: 7.5019\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 20.0573 - mae: 20.0573\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.7661 - mae: 13.7661\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.8282 - mae: 16.8282\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 7.0514 - mae: 7.0514\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 21.4846 - mae: 21.4846\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 12.2880 - mae: 12.2880\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.8117 - mae: 11.8117\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 8.3600 - mae: 8.3600\n",
      "Epoch 335/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 515us/step - loss: 12.4833 - mae: 12.4833\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 32.2171 - mae: 32.2171\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 981us/step - loss: 10.4477 - mae: 10.4477\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 19.6832 - mae: 19.6832\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 35.0762 - mae: 35.0762\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.4192 - mae: 10.4192\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 9.7625 - mae: 9.7625\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.9500 - mae: 11.9500\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 9.3943 - mae: 9.3943\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 5.6071 - mae: 5.6071\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 37.4876 - mae: 37.4876\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.8830 - mae: 16.8830\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.8748 - mae: 12.8748\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.1960 - mae: 8.1960\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 13.5568 - mae: 13.5568\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 15.4354 - mae: 15.4354\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 32.9626 - mae: 32.9626\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.2040 - mae: 14.2040\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 494us/step - loss: 15.9196 - mae: 15.9196\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 19.0878 - mae: 19.0878\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 34.1178 - mae: 34.1178\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.6798 - mae: 7.6798\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 25.2287 - mae: 25.2287\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 22.6759 - mae: 22.6759\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 8.8765 - mae: 8.8765\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 21.4709 - mae: 21.4709\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 20.6073 - mae: 20.6073\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 7.0611 - mae: 7.0611\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 25.8117 - mae: 25.8117\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 32.2247 - mae: 32.2247\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.0205 - mae: 10.0205\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 9.6722 - mae: 9.6722\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 30.4171 - mae: 30.4171\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 10.5020 - mae: 10.5020\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 497us/step - loss: 14.9909 - mae: 14.9909\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 14.6580 - mae: 14.6580\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 23.3672 - mae: 23.3672\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.1025 - mae: 13.1025\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2586 - mae: 9.2586\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.6648 - mae: 9.6648\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.0041 - mae: 13.0041\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.8863 - mae: 14.8863\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 14.7932 - mae: 14.7932\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 516us/step - loss: 16.2751 - mae: 16.2751\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 20.8307 - mae: 20.8307\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 33.5318 - mae: 33.5318\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.2166 - mae: 8.2166\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.0960 - mae: 13.0960\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.3999 - mae: 8.3999\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.1283 - mae: 7.1283\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.9390 - mae: 10.9390\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 19.7654 - mae: 19.7654\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 497us/step - loss: 24.8625 - mae: 24.8625\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.7422 - mae: 8.7422\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 5.9488 - mae: 5.9488\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 24.4401 - mae: 24.4401\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 5.9771 - mae: 5.9771\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 16.3250 - mae: 16.3250\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 6.0917 - mae: 6.0917\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.0963 - mae: 11.0963\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.9601 - mae: 14.9601\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.6462 - mae: 7.6462\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.7654 - mae: 8.7654\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 14.5992 - mae: 14.5992\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.3166 - mae: 11.3166\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 21.9080 - mae: 21.9080\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 14.8654 - mae: 14.8654\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 8.4970 - mae: 8.4970\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.3957 - mae: 10.3957\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 10.2556 - mae: 10.2556\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 6.3392 - mae: 6.3392\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 17.4602 - mae: 17.4602\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 11.4627 - mae: 11.4627\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 20.7294 - mae: 20.7294\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 31.3339 - mae: 31.3339\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.2542 - mae: 9.2542\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.8621 - mae: 14.8621\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 21.7182 - mae: 21.7182\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.6615 - mae: 12.6615\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 6.0687 - mae: 6.0687\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.2201 - mae: 13.2201\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 27.4244 - mae: 27.4244\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.6407 - mae: 10.6407\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 12.8230 - mae: 12.8230\n",
      "Epoch 419/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 997us/step - loss: 15.8836 - mae: 15.8836\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 24.7510 - mae: 24.7510\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 17.3753 - mae: 17.3753\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 7.8241 - mae: 7.8241\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 25.3789 - mae: 25.3789\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 497us/step - loss: 15.1031 - mae: 15.1031\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 7.1643 - mae: 7.1643\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 20.3318 - mae: 20.3318\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 6.3283 - mae: 6.3283\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.9962 - mae: 12.9962\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.7869 - mae: 10.7869\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 11.4007 - mae: 11.4007\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.6153 - mae: 10.6153\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 11.4582 - mae: 11.4582\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 11.3850 - mae: 11.3850\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 980us/step - loss: 30.3986 - mae: 30.3986\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 515us/step - loss: 10.5052 - mae: 10.5052\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 28.8810 - mae: 28.8810\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 515us/step - loss: 8.5916 - mae: 8.5916\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 12.7378 - mae: 12.7378\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 33.6754 - mae: 33.6754\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 15.0962 - mae: 15.0962\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.4813 - mae: 17.4813\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 22.3049 - mae: 22.3049\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 23.5841 - mae: 23.5841\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 495us/step - loss: 11.0008 - mae: 11.0008\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 14.9175 - mae: 14.9175\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 17.9979 - mae: 17.9979\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 5.4482 - mae: 5.4482\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.0527 - mae: 10.0527\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 14.0052 - mae: 14.0052\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.7782 - mae: 16.7782\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 14.2937 - mae: 14.2937\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 30.6192 - mae: 30.6192\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 995us/step - loss: 7.6541 - mae: 7.6541\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 28.1428 - mae: 28.1428\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.0017 - mae: 8.0017\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 10.3933 - mae: 10.3933\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 15.0242 - mae: 15.0242\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.5653 - mae: 16.5653\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 26.8566 - mae: 26.8566\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.4852 - mae: 12.4852\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.4784 - mae: 12.4784\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.3186 - mae: 13.3186\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 29.5524 - mae: 29.5524\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 3.4664 - mae: 3.4664\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.2136 - mae: 15.2136\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 20.8327 - mae: 20.8327\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 30.5108 - mae: 30.5108\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 11.0598 - mae: 11.0598\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.8372 - mae: 12.8372\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 3.2398 - mae: 3.2398\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 16.6964 - mae: 16.6964\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.3883 - mae: 13.3883\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.2771 - mae: 15.2771\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.7448 - mae: 11.7448\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.4113 - mae: 16.4113\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 497us/step - loss: 13.8785 - mae: 13.8785\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 30.6702 - mae: 30.6702\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 8.5880 - mae: 8.5880\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.7384 - mae: 10.7384\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 17.9051 - mae: 17.9051\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 15.8094 - mae: 15.8094\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 21.3054 - mae: 21.3054\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 25.3845 - mae: 25.3845\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 23.9816 - mae: 23.9816\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.7734 - mae: 5.7734\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 20.0011 - mae: 20.0011\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.0419 - mae: 14.0419\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 30.6088 - mae: 30.6088\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.9409 - mae: 11.9409\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 12.7352 - mae: 12.7352\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 23.6139 - mae: 23.6139\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 20.5365 - mae: 20.5365\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 4.9942 - mae: 4.9942\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.7987 - mae: 12.7987\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.3772 - mae: 13.3772\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 981us/step - loss: 12.6727 - mae: 12.6727\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 17.6192 - mae: 17.6192\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 23.5629 - mae: 23.5629\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 9.3755 - mae: 9.3755\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 14.6316 - mae: 14.6316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d5d99e0790>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_3 = tf.keras.Sequential()\n",
    "model_3.add(tf.keras.layers.Dense(10))\n",
    "model_3.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "# 2. Compile the model\n",
    "model_3.compile(loss = tf.keras.losses.mae,\n",
    "               optimizer = tf.keras.optimizers.SGD(),\n",
    "               metrics = ['mae'])\n",
    "\n",
    "#. Fit the model\n",
    "model_3.fit(x_train, y_train, epochs= 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9cbf24f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_preds_3 = model_3.predict(x_test)\n",
    "plot_predictions(predictions=y_preds_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f6f73dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_3 = tf.metrics.mean_absolute_error(y_test, tf.squeeze(y_preds_3))\n",
    "mse_3 = tf.metrics.mean_squared_error(y_test, tf.squeeze(y_preds_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a83e0195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=68.713615>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4808.0273>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_3,mse_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142fb050",
   "metadata": {},
   "source": [
    "### Comparing the results of our experiments\n",
    "\n",
    "we've run a few experiments, let's compare them now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "14b77725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's compare our model's results using a pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "model_results = [['model_1', mae_1.numpy(), mse_1.numpy()],\n",
    "                 ['model_2', mae_2.numpy(), mse_2.numpy()],\n",
    "                 ['model_3', mae_3.numpy(), mse_3.numpy()]]\n",
    "\n",
    "all_results = pd.DataFrame(model_results, columns=[\"model\", \"mae\", \"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1ba6945c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>3.196940</td>\n",
       "      <td>13.070127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>3.196940</td>\n",
       "      <td>13.070127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>68.713615</td>\n",
       "      <td>4808.027344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        mae          mse\n",
       "0  model_1   3.196940    13.070127\n",
       "1  model_2   3.196940    13.070127\n",
       "2  model_3  68.713615  4808.027344"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f09e59",
   "metadata": {},
   "source": [
    "## Tracking your experiments\n",
    "\n",
    "one really good habit in machine learning modelling is to track the results of your experiments.\n",
    "\n",
    "and when doing so, it can be tedious if you're running lots of experiments.\n",
    "\n",
    "Luckily, there are tool sto help us!\n",
    "\n",
    "As you build models, you'll want to look into using:\n",
    "\n",
    "* TensorBoard - a component of the TensorFlow library to help modelling experiments (we'll see this one later).\n",
    "* Weihts and baises - a tool for tracking all of kinds of machine learning experiments (plugs straight into TensorBoard)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c640ec77",
   "metadata": {},
   "source": [
    "  ### Saving a Model \n",
    "  \n",
    "  Saving our models allows us to use them outside of Goodlecolab (or wherever they were trained) such as in a web application or a mobile app.\n",
    "  \n",
    " There are two main formats we can save our model's to:\n",
    " \n",
    "* 1. The SavedModel\n",
    "* 2. The HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02b60349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\prash\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\prash\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: Best_model_SavedModel_format\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model using SaveModel format\n",
    "model_2.save('Best_model_SavedModel_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67f4ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model using HDF5 format\n",
    "model_2.save('best_model_HDF5_format.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4c3004",
   "metadata": {},
   "source": [
    "### Loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ea73df28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_SavedModel_format = tf.keras.models.load_model('Best_model_SavedModel_format/')\n",
    "loaded_SavedModel_format.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9bea47ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare the mode_2 predictions with the savedmodel format model predictions\n",
    "\n",
    "model_2_preds = model_2.predict(x_test)\n",
    "loaded_SavedModel_format_preds = loaded_SavedModel_format.predict(x_test)\n",
    "model_2_preds == loaded_SavedModel_format_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "466bb518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[15.854746],\n",
       "        [16.617332],\n",
       "        [17.379921],\n",
       "        [18.142508],\n",
       "        [18.905096],\n",
       "        [19.667683],\n",
       "        [20.430271],\n",
       "        [21.192858],\n",
       "        [21.955446],\n",
       "        [22.718035]], dtype=float32),\n",
       " array([[15.854746],\n",
       "        [16.617332],\n",
       "        [17.379921],\n",
       "        [18.142508],\n",
       "        [18.905096],\n",
       "        [19.667683],\n",
       "        [20.430271],\n",
       "        [21.192858],\n",
       "        [21.955446],\n",
       "        [22.718035]], dtype=float32))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_preds, loaded_SavedModel_format_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0ac78b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in a model using .h6 format\n",
    "loaded_h5_model = tf.keras.models.load_model('best_model_HDF5_format.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "17b721e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_h5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a61a5ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "86267a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if loaded if .h5 model predicitons match model_2\n",
    "model_2_preds = model_2.predict(x_test)\n",
    "loaded_h5_model_preds =  loaded_h5_model.predict(x_test)\n",
    "model_2_preds == loaded_h5_model_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7687faa",
   "metadata": {},
   "source": [
    "## A larger example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8c40db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "50a9ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = pd.read_csv('insurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f1ea40d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 2, 5, 4], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance['children'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3f0915f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338</td>\n",
       "      <td>1338</td>\n",
       "      <td>1338.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1064</td>\n",
       "      <td>364</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.207025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.663397</td>\n",
       "      <td>1.094918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13270.422265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.049960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.098187</td>\n",
       "      <td>1.205493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12110.011237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1121.873900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.296250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4740.287150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9382.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.693750</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16639.912515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.130000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63770.428010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age   sex          bmi     children smoker     region  \\\n",
       "count   1338.000000  1338  1338.000000  1338.000000   1338       1338   \n",
       "unique          NaN     2          NaN          NaN      2          4   \n",
       "top             NaN  male          NaN          NaN     no  southeast   \n",
       "freq            NaN   676          NaN          NaN   1064        364   \n",
       "mean      39.207025   NaN    30.663397     1.094918    NaN        NaN   \n",
       "std       14.049960   NaN     6.098187     1.205493    NaN        NaN   \n",
       "min       18.000000   NaN    15.960000     0.000000    NaN        NaN   \n",
       "25%       27.000000   NaN    26.296250     0.000000    NaN        NaN   \n",
       "50%       39.000000   NaN    30.400000     1.000000    NaN        NaN   \n",
       "75%       51.000000   NaN    34.693750     2.000000    NaN        NaN   \n",
       "max       64.000000   NaN    53.130000     5.000000    NaN        NaN   \n",
       "\n",
       "             charges  \n",
       "count    1338.000000  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "mean    13270.422265  \n",
       "std     12110.011237  \n",
       "min      1121.873900  \n",
       "25%      4740.287150  \n",
       "50%      9382.033000  \n",
       "75%     16639.912515  \n",
       "max     63770.428010  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0bff7e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>10600.54830</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>2205.98080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>1629.83350</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>2007.94500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>29141.36030</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
       "0      19  27.900         0  16884.92400           1         0          0   \n",
       "1      18  33.770         1   1725.55230           0         1          1   \n",
       "2      28  33.000         3   4449.46200           0         1          1   \n",
       "3      33  22.705         0  21984.47061           0         1          1   \n",
       "4      32  28.880         0   3866.85520           0         1          1   \n",
       "...   ...     ...       ...          ...         ...       ...        ...   \n",
       "1333   50  30.970         3  10600.54830           0         1          1   \n",
       "1334   18  31.920         0   2205.98080           1         0          1   \n",
       "1335   18  36.850         0   1629.83350           1         0          1   \n",
       "1336   21  25.800         0   2007.94500           1         0          1   \n",
       "1337   61  29.070         0  29141.36030           1         0          0   \n",
       "\n",
       "      smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
       "0              1                 0                 0                 0   \n",
       "1              0                 0                 0                 1   \n",
       "2              0                 0                 0                 1   \n",
       "3              0                 0                 1                 0   \n",
       "4              0                 0                 1                 0   \n",
       "...          ...               ...               ...               ...   \n",
       "1333           0                 0                 1                 0   \n",
       "1334           0                 1                 0                 0   \n",
       "1335           0                 0                 0                 1   \n",
       "1336           0                 0                 0                 0   \n",
       "1337           1                 0                 1                 0   \n",
       "\n",
       "      region_southwest  \n",
       "0                    1  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "1333                 0  \n",
       "1334                 0  \n",
       "1335                 0  \n",
       "1336                 1  \n",
       "1337                 0  \n",
       "\n",
       "[1338 rows x 12 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try one hot encode our dataFrame so it's all numbers\n",
    "insurance_one_hot = pd.get_dummies(insurance)\n",
    "insurance_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cd2b951b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0   19  27.900         0           1         0          0           1   \n",
       "1   18  33.770         1           0         1          1           0   \n",
       "2   28  33.000         3           0         1          1           0   \n",
       "3   33  22.705         0           0         1          1           0   \n",
       "4   32  28.880         0           0         1          1           0   \n",
       "\n",
       "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                 0                 0                 0                 1  \n",
       "1                 0                 0                 1                 0  \n",
       "2                 0                 0                 1                 0  \n",
       "3                 0                 1                 0                 0  \n",
       "4                 0                 1                 0                 0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create X and Y values( features and labels)\n",
    "x = insurance_one_hot.drop('charges', axis=1)\n",
    "y = insurance_one_hot['charges']\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5149107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test,y_train, y_test = train_test_split(x,y, test_size= 0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5a27abef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "9/9 [==============================] - 0s 443us/step - loss: 11759.7080 - mae: 11759.7080\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 8002.1743 - mae: 8002.1743\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7600.6602 - mae: 7600.6602\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7541.0542 - mae: 7541.0542\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7792.7441 - mae: 7792.7441\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7814.1523 - mae: 7814.1523\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 8133.3359 - mae: 8133.3359\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8397.5098 - mae: 8397.5098\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 7535.5513 - mae: 7535.5513\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7808.8950 - mae: 7808.8950\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8082.7959 - mae: 8082.7959\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 7415.6816 - mae: 7415.6816\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7891.9390 - mae: 7891.9390\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8187.2173 - mae: 8187.2173\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7743.4712 - mae: 7743.4712\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7624.3452 - mae: 7624.3452\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8119.3296 - mae: 8119.3296\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7649.3135 - mae: 7649.3135\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8337.2471 - mae: 8337.2471\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 8113.0947 - mae: 8113.0947\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8085.2529 - mae: 8085.2529\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7985.3696 - mae: 7985.3696\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8181.1011 - mae: 8181.1011\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 7772.6479 - mae: 7772.6479\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8229.9414 - mae: 8229.9414\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 8272.4834 - mae: 8272.4834\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8040.9878 - mae: 8040.9878\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7785.0625 - mae: 7785.0625\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8263.6904 - mae: 8263.6904\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 7757.4590 - mae: 7757.4590\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7571.1138 - mae: 7571.1138\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 7658.4443 - mae: 7658.4443\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8041.4043 - mae: 8041.4043\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7980.3032 - mae: 7980.3032\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7915.2715 - mae: 7915.2715\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7444.4492 - mae: 7444.4492\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7936.3970 - mae: 7936.3970\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 8140.3672 - mae: 8140.3672\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7964.5918 - mae: 7964.5918\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8131.6958 - mae: 8131.6958\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7643.7539 - mae: 7643.7539\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 8547.6162 - mae: 8547.6162\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 7947.0430 - mae: 7947.0430\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7672.6870 - mae: 7672.6870\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 8147.4214 - mae: 8147.4214\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7930.6768 - mae: 7930.6768\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7940.1519 - mae: 7940.1519\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 7794.2437 - mae: 7794.2437\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8631.9229 - mae: 8631.9229\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7908.6807 - mae: 7908.6807\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7374.3628 - mae: 7374.3628\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7997.5283 - mae: 7997.5283\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7627.8091 - mae: 7627.8091\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7894.4185 - mae: 7894.4185\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 7694.0425 - mae: 7694.0425\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7631.9224 - mae: 7631.9224\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 8191.6807 - mae: 8191.6807\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7811.0312 - mae: 7811.0312\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7317.1309 - mae: 7317.1309\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 8030.6880 - mae: 8030.6880\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 553us/step - loss: 7741.2563 - mae: 7741.2563\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7263.9111 - mae: 7263.9111\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 7322.9009 - mae: 7322.9009\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 7995.5093 - mae: 7995.5093\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8390.5791 - mae: 8390.5791\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7158.2173 - mae: 7158.2173\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7826.4058 - mae: 7826.4058\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 553us/step - loss: 8057.6431 - mae: 8057.6431\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 7811.8428 - mae: 7811.8428\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7906.1948 - mae: 7906.1948\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7839.4053 - mae: 7839.4053\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 8133.2661 - mae: 8133.2661\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7886.5601 - mae: 7886.5601\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7938.7988 - mae: 7938.7988\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 443us/step - loss: 7908.6978 - mae: 7908.6978\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7414.8906 - mae: 7414.8906\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 442us/step - loss: 7752.5244 - mae: 7752.5244\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 7908.0049 - mae: 7908.0049\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7749.6973 - mae: 7749.6973\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7954.5684 - mae: 7954.5684\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7606.8291 - mae: 7606.8291\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7940.2583 - mae: 7940.2583\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 7643.9463 - mae: 7643.9463\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 444us/step - loss: 7520.8652 - mae: 7520.8652\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7907.4878 - mae: 7907.4878\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7655.6978 - mae: 7655.6978\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7796.5308 - mae: 7796.5308\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 8246.7422 - mae: 8246.7422\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 7907.0972 - mae: 7907.0972\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7650.4033 - mae: 7650.4033\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7772.5029 - mae: 7772.5029\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8432.1836 - mae: 8432.1836\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 444us/step - loss: 7644.6553 - mae: 7644.6553\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 7517.9766 - mae: 7517.9766\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 331us/step - loss: 7978.6763 - mae: 7978.6763\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7382.0137 - mae: 7382.0137\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7647.0508 - mae: 7647.0508\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8220.0928 - mae: 8220.0928\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8243.6357 - mae: 8243.6357\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 7558.3149 - mae: 7558.3149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d5e14bd640>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# Build a neural network (sort of like model_2 above)\n",
    "insurance_model= tf.keras.Sequential()\n",
    "insurance_model.add(tf.keras.layers.Dense(10))\n",
    "insurance_model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "# 2.Complile the model\n",
    "\n",
    "insurance_model.compile(loss = tf.keras.losses.mae,\n",
    "                       optimizer = tf.keras.optimizers.SGD(),\n",
    "                       metrics =['mae'])\n",
    "\n",
    "#. Fit the model\n",
    "insurance_model.fit(x_train, y_train, epochs= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "154050e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 344us/step - loss: 6908.8809 - mae: 6908.8809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6908.880859375, 6908.880859375]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results of the insurance model on the test data\n",
    "insurance_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c61ee5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9566.9909"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4819f4c2",
   "metadata": {},
   "source": [
    "Right now it looks like our model isn't performing too well... let's try and improve it\n",
    "\n",
    "To try improve our model,we'll run 2 experiments:\n",
    "* 1. Add an extra layer with more hidden units and use the Adam optimizer\n",
    "* 2. Train for longer\n",
    "* 3. (insert your own experiment here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2c364edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_28 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "9/9 [==============================] - 0s 554us/step - loss: 13417.4775 - mae: 13417.4775\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 380us/step - loss: 13388.8506 - mae: 13388.8506\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 13357.2842 - mae: 13357.2842\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 886us/step - loss: 13320.3750 - mae: 13320.3750\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 13276.5791 - mae: 13276.5791\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 649us/step - loss: 13222.0576 - mae: 13222.0576\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 537us/step - loss: 13156.5234 - mae: 13156.5234\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 593us/step - loss: 13073.8457 - mae: 13073.8457\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 12975.8057 - mae: 12975.8057\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 553us/step - loss: 12854.2959 - mae: 12854.2959\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 511us/step - loss: 12711.0166 - mae: 12711.0166\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 876us/step - loss: 12540.8770 - mae: 12540.8770\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 12340.3066 - mae: 12340.3066\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 12106.6377 - mae: 12106.6377\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 429us/step - loss: 11836.0234 - mae: 11836.0234\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 675us/step - loss: 11535.5762 - mae: 11535.5762\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 11200.5342 - mae: 11200.5342\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 10833.9082 - mae: 10833.9082\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 599us/step - loss: 10446.7158 - mae: 10446.7158\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 523us/step - loss: 10071.8643 - mae: 10071.8643\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 859us/step - loss: 9683.4561 - mae: 9683.4561\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 9301.3545 - mae: 9301.3545\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 558us/step - loss: 8914.4473 - mae: 8914.4473\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8561.4590 - mae: 8561.4590\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 8255.1328 - mae: 8255.1328\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 557us/step - loss: 8002.9185 - mae: 8002.9185\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7833.6938 - mae: 7833.6938\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 664us/step - loss: 7701.3467 - mae: 7701.3467\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 776us/step - loss: 7627.2197 - mae: 7627.2197\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7599.8481 - mae: 7599.8481\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7554.8247 - mae: 7554.8247\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 436us/step - loss: 7540.5913 - mae: 7540.5913\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 511us/step - loss: 7529.9136 - mae: 7529.9136\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7526.5083 - mae: 7526.5083\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7521.6699 - mae: 7521.6699\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 615us/step - loss: 7517.3418 - mae: 7517.3418\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7509.9360 - mae: 7509.9360\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 871us/step - loss: 7506.7441 - mae: 7506.7441\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7499.8838 - mae: 7499.8838\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7495.3184 - mae: 7495.3184\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 671us/step - loss: 7488.2441 - mae: 7488.2441\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 996us/step - loss: 7484.6719 - mae: 7484.6719\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7478.3809 - mae: 7478.3809\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 840us/step - loss: 7473.0117 - mae: 7473.0117\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 7467.5156 - mae: 7467.5156\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7461.4873 - mae: 7461.4873\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 729us/step - loss: 7456.6577 - mae: 7456.6577\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 490us/step - loss: 7450.8018 - mae: 7450.8018\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 7445.1074 - mae: 7445.1074\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 410us/step - loss: 7439.1665 - mae: 7439.1665\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7433.2910 - mae: 7433.2910\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7427.1362 - mae: 7427.1362\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 664us/step - loss: 7422.2417 - mae: 7422.2417\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7416.2944 - mae: 7416.2944\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 824us/step - loss: 7410.2246 - mae: 7410.2246\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 638us/step - loss: 7404.8623 - mae: 7404.8623\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 887us/step - loss: 7399.5327 - mae: 7399.5327\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7395.0723 - mae: 7395.0723\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 776us/step - loss: 7388.1489 - mae: 7388.1489\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7382.4033 - mae: 7382.4033\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7376.7671 - mae: 7376.7671\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 416us/step - loss: 7370.6958 - mae: 7370.6958\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 701us/step - loss: 7364.0688 - mae: 7364.0688\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 998us/step - loss: 7357.6294 - mae: 7357.6294\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 775us/step - loss: 7352.0449 - mae: 7352.0449\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7345.2861 - mae: 7345.2861\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 776us/step - loss: 7338.9141 - mae: 7338.9141\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7334.5513 - mae: 7334.5513\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 639us/step - loss: 7327.7139 - mae: 7327.7139\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 503us/step - loss: 7321.6226 - mae: 7321.6226\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7315.0435 - mae: 7315.0435\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7307.6807 - mae: 7307.6807\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 882us/step - loss: 7302.0020 - mae: 7302.0020\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 435us/step - loss: 7297.0117 - mae: 7297.0117\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 446us/step - loss: 7289.4634 - mae: 7289.4634\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 562us/step - loss: 7283.2749 - mae: 7283.2749\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 721us/step - loss: 7279.5420 - mae: 7279.5420\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 529us/step - loss: 7271.4438 - mae: 7271.4438\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7264.2051 - mae: 7264.2051\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 837us/step - loss: 7256.9546 - mae: 7256.9546\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 7250.9600 - mae: 7250.9600\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 776us/step - loss: 7243.9258 - mae: 7243.9258\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7237.3462 - mae: 7237.3462\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 7230.7710 - mae: 7230.7710\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 7225.9219 - mae: 7225.9219\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 773us/step - loss: 7217.3306 - mae: 7217.3306\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7210.4624 - mae: 7210.4624\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7203.7881 - mae: 7203.7881\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 7197.2339 - mae: 7197.2339\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 887us/step - loss: 7190.1421 - mae: 7190.1421\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 690us/step - loss: 7183.0020 - mae: 7183.0020\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 723us/step - loss: 7175.5239 - mae: 7175.5239\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7168.3828 - mae: 7168.3828\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7162.8965 - mae: 7162.8965\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 775us/step - loss: 7155.1304 - mae: 7155.1304\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7152.4673 - mae: 7152.4673\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 7141.5620 - mae: 7141.5620\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7133.2686 - mae: 7133.2686\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7126.0674 - mae: 7126.0674\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 886us/step - loss: 7120.1875 - mae: 7120.1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d5e313b9a0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "insurance_model_2 = tf.keras.Sequential()\n",
    "insurance_model_2.add(tf.keras.layers.Dense(100))\n",
    "insurance_model_2.add(tf.keras.layers.Dense(10))\n",
    "insurance_model_2.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "insurance_model_2.compile(loss = tf.keras.losses.mae,\n",
    "                          optimizer = tf.keras.optimizers.Adam(),\n",
    "                          metrics = ['mae'])\n",
    "\n",
    "# Fit the model\n",
    "insurance_model_2.fit(x_train,y_train, epochs= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f36fd269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 399us/step - loss: 7012.1650 - mae: 7012.1650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7012.1650390625, 7012.1650390625]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "insurance_model_2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "888b5436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:Layer dense_43 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "9/9 [==============================] - 0s 598us/step - loss: 13417.4775 - mae: 13417.4775\n",
      "Epoch 2/500\n",
      "9/9 [==============================] - 0s 391us/step - loss: 13388.8506 - mae: 13388.8506\n",
      "Epoch 3/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 13357.2842 - mae: 13357.2842\n",
      "Epoch 4/500\n",
      "9/9 [==============================] - 0s 609us/step - loss: 13320.3750 - mae: 13320.3750\n",
      "Epoch 5/500\n",
      "9/9 [==============================] - 0s 542us/step - loss: 13276.5791 - mae: 13276.5791\n",
      "Epoch 6/500\n",
      "9/9 [==============================] - 0s 637us/step - loss: 13222.0576 - mae: 13222.0576\n",
      "Epoch 7/500\n",
      "9/9 [==============================] - 0s 633us/step - loss: 13156.5234 - mae: 13156.5234\n",
      "Epoch 8/500\n",
      "9/9 [==============================] - 0s 961us/step - loss: 13073.8457 - mae: 13073.8457\n",
      "Epoch 9/500\n",
      "9/9 [==============================] - 0s 821us/step - loss: 12975.8057 - mae: 12975.8057\n",
      "Epoch 10/500\n",
      "9/9 [==============================] - 0s 543us/step - loss: 12854.2959 - mae: 12854.2959\n",
      "Epoch 11/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 12711.0166 - mae: 12711.0166\n",
      "Epoch 12/500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 12540.8770 - mae: 12540.8770\n",
      "Epoch 13/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 12340.3066 - mae: 12340.3066\n",
      "Epoch 14/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 12106.6377 - mae: 12106.6377\n",
      "Epoch 15/500\n",
      "9/9 [==============================] - 0s 513us/step - loss: 11836.0234 - mae: 11836.0234\n",
      "Epoch 16/500\n",
      "9/9 [==============================] - 0s 480us/step - loss: 11535.5762 - mae: 11535.5762\n",
      "Epoch 17/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 11200.5342 - mae: 11200.5342\n",
      "Epoch 18/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 10833.9082 - mae: 10833.9082\n",
      "Epoch 19/500\n",
      "9/9 [==============================] - 0s 547us/step - loss: 10446.7158 - mae: 10446.7158\n",
      "Epoch 20/500\n",
      "9/9 [==============================] - 0s 694us/step - loss: 10071.8643 - mae: 10071.8643\n",
      "Epoch 21/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 9683.4561 - mae: 9683.4561\n",
      "Epoch 22/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 9301.3545 - mae: 9301.3545\n",
      "Epoch 23/500\n",
      "9/9 [==============================] - 0s 502us/step - loss: 8914.4473 - mae: 8914.4473\n",
      "Epoch 24/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 8561.4590 - mae: 8561.4590\n",
      "Epoch 25/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8255.1328 - mae: 8255.1328\n",
      "Epoch 26/500\n",
      "9/9 [==============================] - 0s 565us/step - loss: 8002.9185 - mae: 8002.9185\n",
      "Epoch 27/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7833.6938 - mae: 7833.6938\n",
      "Epoch 28/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7701.3467 - mae: 7701.3467\n",
      "Epoch 29/500\n",
      "9/9 [==============================] - 0s 649us/step - loss: 7627.2197 - mae: 7627.2197\n",
      "Epoch 30/500\n",
      "9/9 [==============================] - 0s 505us/step - loss: 7599.8481 - mae: 7599.8481\n",
      "Epoch 31/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7554.8247 - mae: 7554.8247\n",
      "Epoch 32/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7540.5913 - mae: 7540.5913\n",
      "Epoch 33/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7529.9136 - mae: 7529.9136\n",
      "Epoch 34/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7526.5083 - mae: 7526.5083\n",
      "Epoch 35/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7521.6699 - mae: 7521.6699\n",
      "Epoch 36/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7517.3418 - mae: 7517.3418\n",
      "Epoch 37/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 7509.9360 - mae: 7509.9360\n",
      "Epoch 38/500\n",
      "9/9 [==============================] - 0s 801us/step - loss: 7506.7441 - mae: 7506.7441\n",
      "Epoch 39/500\n",
      "9/9 [==============================] - 0s 452us/step - loss: 7499.8838 - mae: 7499.8838\n",
      "Epoch 40/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7495.3184 - mae: 7495.3184\n",
      "Epoch 41/500\n",
      "9/9 [==============================] - 0s 504us/step - loss: 7488.2441 - mae: 7488.2441\n",
      "Epoch 42/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7484.6719 - mae: 7484.6719\n",
      "Epoch 43/500\n",
      "9/9 [==============================] - 0s 433us/step - loss: 7478.3809 - mae: 7478.3809\n",
      "Epoch 44/500\n",
      "9/9 [==============================] - 0s 886us/step - loss: 7473.0117 - mae: 7473.0117\n",
      "Epoch 45/500\n",
      "9/9 [==============================] - 0s 618us/step - loss: 7467.5156 - mae: 7467.5156\n",
      "Epoch 46/500\n",
      "9/9 [==============================] - 0s 511us/step - loss: 7461.4873 - mae: 7461.4873\n",
      "Epoch 47/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7456.6577 - mae: 7456.6577\n",
      "Epoch 48/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7450.8018 - mae: 7450.8018\n",
      "Epoch 49/500\n",
      "9/9 [==============================] - 0s 507us/step - loss: 7445.1074 - mae: 7445.1074\n",
      "Epoch 50/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7439.1665 - mae: 7439.1665\n",
      "Epoch 51/500\n",
      "9/9 [==============================] - 0s 444us/step - loss: 7433.2910 - mae: 7433.2910\n",
      "Epoch 52/500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 7427.1362 - mae: 7427.1362\n",
      "Epoch 53/500\n",
      "9/9 [==============================] - 0s 439us/step - loss: 7422.2417 - mae: 7422.2417\n",
      "Epoch 54/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7416.2944 - mae: 7416.2944\n",
      "Epoch 55/500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 7410.2246 - mae: 7410.2246\n",
      "Epoch 56/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 7404.8623 - mae: 7404.8623\n",
      "Epoch 57/500\n",
      "9/9 [==============================] - 0s 628us/step - loss: 7399.5327 - mae: 7399.5327\n",
      "Epoch 58/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7395.0723 - mae: 7395.0723\n",
      "Epoch 59/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7388.1489 - mae: 7388.1489\n",
      "Epoch 60/500\n",
      "9/9 [==============================] - 0s 655us/step - loss: 7382.4033 - mae: 7382.4033\n",
      "Epoch 61/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7376.7671 - mae: 7376.7671\n",
      "Epoch 62/500\n",
      "9/9 [==============================] - 0s 541us/step - loss: 7370.6958 - mae: 7370.6958\n",
      "Epoch 63/500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 7364.0688 - mae: 7364.0688\n",
      "Epoch 64/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7357.6294 - mae: 7357.6294\n",
      "Epoch 65/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7352.0449 - mae: 7352.0449\n",
      "Epoch 66/500\n",
      "9/9 [==============================] - 0s 816us/step - loss: 7345.2861 - mae: 7345.2861\n",
      "Epoch 67/500\n",
      "9/9 [==============================] - 0s 423us/step - loss: 7338.9141 - mae: 7338.9141\n",
      "Epoch 68/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7334.5513 - mae: 7334.5513\n",
      "Epoch 69/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7327.7139 - mae: 7327.7139\n",
      "Epoch 70/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7321.6226 - mae: 7321.6226\n",
      "Epoch 71/500\n",
      "9/9 [==============================] - 0s 768us/step - loss: 7315.0435 - mae: 7315.0435\n",
      "Epoch 72/500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 7307.6807 - mae: 7307.6807\n",
      "Epoch 73/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7302.0020 - mae: 7302.0020\n",
      "Epoch 74/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 666us/step - loss: 7297.0117 - mae: 7297.0117\n",
      "Epoch 75/500\n",
      "9/9 [==============================] - 0s 516us/step - loss: 7289.4634 - mae: 7289.4634\n",
      "Epoch 76/500\n",
      "9/9 [==============================] - 0s 520us/step - loss: 7283.2749 - mae: 7283.2749\n",
      "Epoch 77/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7279.5420 - mae: 7279.5420\n",
      "Epoch 78/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7271.4438 - mae: 7271.4438\n",
      "Epoch 79/500\n",
      "9/9 [==============================] - 0s 390us/step - loss: 7264.2051 - mae: 7264.2051\n",
      "Epoch 80/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7256.9546 - mae: 7256.9546\n",
      "Epoch 81/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7250.9600 - mae: 7250.9600\n",
      "Epoch 82/500\n",
      "9/9 [==============================] - 0s 553us/step - loss: 7243.9258 - mae: 7243.9258\n",
      "Epoch 83/500\n",
      "9/9 [==============================] - 0s 429us/step - loss: 7237.3462 - mae: 7237.3462\n",
      "Epoch 84/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7230.7710 - mae: 7230.7710\n",
      "Epoch 85/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7225.9219 - mae: 7225.9219\n",
      "Epoch 86/500\n",
      "9/9 [==============================] - 0s 648us/step - loss: 7217.3306 - mae: 7217.3306\n",
      "Epoch 87/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7210.4624 - mae: 7210.4624\n",
      "Epoch 88/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7203.7881 - mae: 7203.7881\n",
      "Epoch 89/500\n",
      "9/9 [==============================] - 0s 500us/step - loss: 7197.2339 - mae: 7197.2339\n",
      "Epoch 90/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7190.1421 - mae: 7190.1421\n",
      "Epoch 91/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7183.0020 - mae: 7183.0020\n",
      "Epoch 92/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7175.5239 - mae: 7175.5239\n",
      "Epoch 93/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7168.3828 - mae: 7168.3828\n",
      "Epoch 94/500\n",
      "9/9 [==============================] - 0s 506us/step - loss: 7162.8965 - mae: 7162.8965\n",
      "Epoch 95/500\n",
      "9/9 [==============================] - 0s 495us/step - loss: 7155.1304 - mae: 7155.1304\n",
      "Epoch 96/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7152.4673 - mae: 7152.4673\n",
      "Epoch 97/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7141.5620 - mae: 7141.5620\n",
      "Epoch 98/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7133.2686 - mae: 7133.2686\n",
      "Epoch 99/500\n",
      "9/9 [==============================] - 0s 557us/step - loss: 7126.0674 - mae: 7126.0674\n",
      "Epoch 100/500\n",
      "9/9 [==============================] - 0s 664us/step - loss: 7120.1875 - mae: 7120.1875\n",
      "Epoch 101/500\n",
      "9/9 [==============================] - 0s 551us/step - loss: 7112.1396 - mae: 7112.1396\n",
      "Epoch 102/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7106.0415 - mae: 7106.0415\n",
      "Epoch 103/500\n",
      "9/9 [==============================] - 0s 551us/step - loss: 7097.8726 - mae: 7097.8726\n",
      "Epoch 104/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7091.7949 - mae: 7091.7949\n",
      "Epoch 105/500\n",
      "9/9 [==============================] - 0s 440us/step - loss: 7084.5796 - mae: 7084.5796\n",
      "Epoch 106/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7082.4404 - mae: 7082.4404\n",
      "Epoch 107/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7069.6289 - mae: 7069.6289\n",
      "Epoch 108/500\n",
      "9/9 [==============================] - 0s 418us/step - loss: 7062.9819 - mae: 7062.9819\n",
      "Epoch 109/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7056.9980 - mae: 7056.9980\n",
      "Epoch 110/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7049.2529 - mae: 7049.2529\n",
      "Epoch 111/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7044.9883 - mae: 7044.9883\n",
      "Epoch 112/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7037.7549 - mae: 7037.7549\n",
      "Epoch 113/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 7028.5044 - mae: 7028.5044\n",
      "Epoch 114/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7023.6099 - mae: 7023.6099\n",
      "Epoch 115/500\n",
      "9/9 [==============================] - 0s 518us/step - loss: 7014.5659 - mae: 7014.5659\n",
      "Epoch 116/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7007.2651 - mae: 7007.2651\n",
      "Epoch 117/500\n",
      "9/9 [==============================] - 0s 456us/step - loss: 7000.6123 - mae: 7000.6123\n",
      "Epoch 118/500\n",
      "9/9 [==============================] - 0s 414us/step - loss: 6993.2051 - mae: 6993.2051\n",
      "Epoch 119/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6987.7534 - mae: 6987.7534\n",
      "Epoch 120/500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 6985.6294 - mae: 6985.6294\n",
      "Epoch 121/500\n",
      "9/9 [==============================] - 0s 589us/step - loss: 6975.8335 - mae: 6975.8335\n",
      "Epoch 122/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6969.3711 - mae: 6969.3711\n",
      "Epoch 123/500\n",
      "9/9 [==============================] - 0s 482us/step - loss: 6960.7563 - mae: 6960.7563\n",
      "Epoch 124/500\n",
      "9/9 [==============================] - 0s 505us/step - loss: 6957.0723 - mae: 6957.0723\n",
      "Epoch 125/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6949.2866 - mae: 6949.2866\n",
      "Epoch 126/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6942.2275 - mae: 6942.2275\n",
      "Epoch 127/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6937.7305 - mae: 6937.7305\n",
      "Epoch 128/500\n",
      "9/9 [==============================] - 0s 436us/step - loss: 6928.8013 - mae: 6928.8013\n",
      "Epoch 129/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6920.9565 - mae: 6920.9565\n",
      "Epoch 130/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6914.0674 - mae: 6914.0674\n",
      "Epoch 131/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6910.7852 - mae: 6910.7852\n",
      "Epoch 132/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6901.5449 - mae: 6901.5449\n",
      "Epoch 133/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6892.9541 - mae: 6892.9541\n",
      "Epoch 134/500\n",
      "9/9 [==============================] - 0s 604us/step - loss: 6885.6880 - mae: 6885.6880\n",
      "Epoch 135/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6878.4609 - mae: 6878.4609\n",
      "Epoch 136/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6871.6860 - mae: 6871.6860\n",
      "Epoch 137/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6864.1001 - mae: 6864.1001\n",
      "Epoch 138/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6856.2632 - mae: 6856.2632\n",
      "Epoch 139/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6848.8315 - mae: 6848.8315\n",
      "Epoch 140/500\n",
      "9/9 [==============================] - 0s 391us/step - loss: 6839.5815 - mae: 6839.5815\n",
      "Epoch 141/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 6831.3462 - mae: 6831.3462\n",
      "Epoch 142/500\n",
      "9/9 [==============================] - 0s 535us/step - loss: 6823.0581 - mae: 6823.0581\n",
      "Epoch 143/500\n",
      "9/9 [==============================] - 0s 530us/step - loss: 6815.6074 - mae: 6815.6074\n",
      "Epoch 144/500\n",
      "9/9 [==============================] - 0s 332us/step - loss: 6807.3008 - mae: 6807.3008\n",
      "Epoch 145/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6798.5850 - mae: 6798.5850\n",
      "Epoch 146/500\n",
      "9/9 [==============================] - 0s 608us/step - loss: 6790.8062 - mae: 6790.8062\n",
      "Epoch 147/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6782.1914 - mae: 6782.1914\n",
      "Epoch 148/500\n",
      "9/9 [==============================] - 0s 433us/step - loss: 6775.5942 - mae: 6775.5942\n",
      "Epoch 149/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6768.7407 - mae: 6768.7407\n",
      "Epoch 150/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 6758.5259 - mae: 6758.5259\n",
      "Epoch 151/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6751.2998 - mae: 6751.2998\n",
      "Epoch 152/500\n",
      "9/9 [==============================] - 0s 531us/step - loss: 6744.7251 - mae: 6744.7251\n",
      "Epoch 153/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6735.5737 - mae: 6735.5737\n",
      "Epoch 154/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 444us/step - loss: 6730.5620 - mae: 6730.5620\n",
      "Epoch 155/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6722.7217 - mae: 6722.7217\n",
      "Epoch 156/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6712.8364 - mae: 6712.8364\n",
      "Epoch 157/500\n",
      "9/9 [==============================] - 0s 382us/step - loss: 6707.5693 - mae: 6707.5693\n",
      "Epoch 158/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6698.8237 - mae: 6698.8237\n",
      "Epoch 159/500\n",
      "9/9 [==============================] - 0s 586us/step - loss: 6690.9062 - mae: 6690.9062\n",
      "Epoch 160/500\n",
      "9/9 [==============================] - 0s 528us/step - loss: 6687.0757 - mae: 6687.0757\n",
      "Epoch 161/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6677.1460 - mae: 6677.1460\n",
      "Epoch 162/500\n",
      "9/9 [==============================] - 0s 520us/step - loss: 6668.8208 - mae: 6668.8208\n",
      "Epoch 163/500\n",
      "9/9 [==============================] - 0s 530us/step - loss: 6661.0991 - mae: 6661.0991\n",
      "Epoch 164/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6655.7310 - mae: 6655.7310\n",
      "Epoch 165/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6647.3350 - mae: 6647.3350\n",
      "Epoch 166/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6641.7617 - mae: 6641.7617\n",
      "Epoch 167/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6635.4878 - mae: 6635.4878\n",
      "Epoch 168/500\n",
      "9/9 [==============================] - 0s 511us/step - loss: 6627.6655 - mae: 6627.6655\n",
      "Epoch 169/500\n",
      "9/9 [==============================] - 0s 550us/step - loss: 6623.3843 - mae: 6623.3843\n",
      "Epoch 170/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6615.0361 - mae: 6615.0361\n",
      "Epoch 171/500\n",
      "9/9 [==============================] - 0s 526us/step - loss: 6607.9521 - mae: 6607.9521\n",
      "Epoch 172/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6605.3921 - mae: 6605.3921\n",
      "Epoch 173/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6599.0098 - mae: 6599.0098\n",
      "Epoch 174/500\n",
      "9/9 [==============================] - 0s 504us/step - loss: 6592.0767 - mae: 6592.0767\n",
      "Epoch 175/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6586.3428 - mae: 6586.3428\n",
      "Epoch 176/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6580.0479 - mae: 6580.0479\n",
      "Epoch 177/500\n",
      "9/9 [==============================] - 0s 531us/step - loss: 6574.9165 - mae: 6574.9165\n",
      "Epoch 178/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6568.9966 - mae: 6568.9966\n",
      "Epoch 179/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6564.6157 - mae: 6564.6157\n",
      "Epoch 180/500\n",
      "9/9 [==============================] - 0s 444us/step - loss: 6559.4644 - mae: 6559.4644\n",
      "Epoch 181/500\n",
      "9/9 [==============================] - 0s 477us/step - loss: 6553.4751 - mae: 6553.4751\n",
      "Epoch 182/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6549.2451 - mae: 6549.2451\n",
      "Epoch 183/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6544.5317 - mae: 6544.5317\n",
      "Epoch 184/500\n",
      "9/9 [==============================] - 0s 434us/step - loss: 6540.1914 - mae: 6540.1914\n",
      "Epoch 185/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6534.4136 - mae: 6534.4136\n",
      "Epoch 186/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6530.6396 - mae: 6530.6396\n",
      "Epoch 187/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6525.5776 - mae: 6525.5776\n",
      "Epoch 188/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6521.8833 - mae: 6521.8833\n",
      "Epoch 189/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6521.6260 - mae: 6521.6260\n",
      "Epoch 190/500\n",
      "9/9 [==============================] - 0s 551us/step - loss: 6512.8320 - mae: 6512.8320\n",
      "Epoch 191/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6509.6709 - mae: 6509.6709\n",
      "Epoch 192/500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 6505.3032 - mae: 6505.3032\n",
      "Epoch 193/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6502.8560 - mae: 6502.8560\n",
      "Epoch 194/500\n",
      "9/9 [==============================] - 0s 539us/step - loss: 6502.8018 - mae: 6502.8018\n",
      "Epoch 195/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 6497.8999 - mae: 6497.8999\n",
      "Epoch 196/500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 6491.2681 - mae: 6491.2681\n",
      "Epoch 197/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 6487.1323 - mae: 6487.1323\n",
      "Epoch 198/500\n",
      "9/9 [==============================] - 0s 555us/step - loss: 6481.2041 - mae: 6481.2041\n",
      "Epoch 199/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6479.9731 - mae: 6479.9731\n",
      "Epoch 200/500\n",
      "9/9 [==============================] - 0s 738us/step - loss: 6476.6631 - mae: 6476.6631\n",
      "Epoch 201/500\n",
      "9/9 [==============================] - 0s 457us/step - loss: 6470.0361 - mae: 6470.0361\n",
      "Epoch 202/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 6467.0513 - mae: 6467.0513\n",
      "Epoch 203/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6464.3755 - mae: 6464.3755\n",
      "Epoch 204/500\n",
      "9/9 [==============================] - 0s 878us/step - loss: 6462.1084 - mae: 6462.1084\n",
      "Epoch 205/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6458.2290 - mae: 6458.2290\n",
      "Epoch 206/500\n",
      "9/9 [==============================] - 0s 546us/step - loss: 6452.4424 - mae: 6452.4424\n",
      "Epoch 207/500\n",
      "9/9 [==============================] - 0s 802us/step - loss: 6448.8179 - mae: 6448.8179\n",
      "Epoch 208/500\n",
      "9/9 [==============================] - 0s 444us/step - loss: 6446.2754 - mae: 6446.2754\n",
      "Epoch 209/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6439.9272 - mae: 6439.9272\n",
      "Epoch 210/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6434.4565 - mae: 6434.4565\n",
      "Epoch 211/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6433.1079 - mae: 6433.1079\n",
      "Epoch 212/500\n",
      "9/9 [==============================] - 0s 777us/step - loss: 6427.4858 - mae: 6427.4858\n",
      "Epoch 213/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6423.9688 - mae: 6423.9688\n",
      "Epoch 214/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 6420.2969 - mae: 6420.2969\n",
      "Epoch 215/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6415.9287 - mae: 6415.9287\n",
      "Epoch 216/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6415.2812 - mae: 6415.2812\n",
      "Epoch 217/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6411.1641 - mae: 6411.1641\n",
      "Epoch 218/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 6404.0718 - mae: 6404.0718\n",
      "Epoch 219/500\n",
      "9/9 [==============================] - 0s 478us/step - loss: 6402.2637 - mae: 6402.2637\n",
      "Epoch 220/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6402.5356 - mae: 6402.5356\n",
      "Epoch 221/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6393.1021 - mae: 6393.1021\n",
      "Epoch 222/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6388.1758 - mae: 6388.1758\n",
      "Epoch 223/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6383.1206 - mae: 6383.1206\n",
      "Epoch 224/500\n",
      "9/9 [==============================] - 0s 527us/step - loss: 6377.3882 - mae: 6377.3882\n",
      "Epoch 225/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6376.5571 - mae: 6376.5571\n",
      "Epoch 226/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6369.6533 - mae: 6369.6533\n",
      "Epoch 227/500\n",
      "9/9 [==============================] - 0s 504us/step - loss: 6366.7036 - mae: 6366.7036\n",
      "Epoch 228/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6360.4795 - mae: 6360.4795\n",
      "Epoch 229/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6357.4688 - mae: 6357.4688\n",
      "Epoch 230/500\n",
      "9/9 [==============================] - 0s 431us/step - loss: 6355.4985 - mae: 6355.4985\n",
      "Epoch 231/500\n",
      "9/9 [==============================] - 0s 332us/step - loss: 6351.1851 - mae: 6351.1851\n",
      "Epoch 232/500\n",
      "9/9 [==============================] - 0s 510us/step - loss: 6350.7319 - mae: 6350.7319\n",
      "Epoch 233/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6339.7373 - mae: 6339.7373\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 443us/step - loss: 6340.9072 - mae: 6340.9072\n",
      "Epoch 235/500\n",
      "9/9 [==============================] - 0s 388us/step - loss: 6332.7002 - mae: 6332.7002\n",
      "Epoch 236/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6328.3989 - mae: 6328.3989\n",
      "Epoch 237/500\n",
      "9/9 [==============================] - 0s 396us/step - loss: 6324.1411 - mae: 6324.1411\n",
      "Epoch 238/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6325.3955 - mae: 6325.3955\n",
      "Epoch 239/500\n",
      "9/9 [==============================] - 0s 535us/step - loss: 6316.8389 - mae: 6316.8394\n",
      "Epoch 240/500\n",
      "9/9 [==============================] - 0s 546us/step - loss: 6313.4419 - mae: 6313.4419\n",
      "Epoch 241/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6307.4878 - mae: 6307.4878\n",
      "Epoch 242/500\n",
      "9/9 [==============================] - 0s 537us/step - loss: 6303.6855 - mae: 6303.6855\n",
      "Epoch 243/500\n",
      "9/9 [==============================] - 0s 413us/step - loss: 6299.0225 - mae: 6299.0225\n",
      "Epoch 244/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6296.8125 - mae: 6296.8125\n",
      "Epoch 245/500\n",
      "9/9 [==============================] - 0s 422us/step - loss: 6289.7744 - mae: 6289.7744\n",
      "Epoch 246/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6286.1646 - mae: 6286.1646\n",
      "Epoch 247/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6279.8018 - mae: 6279.8018\n",
      "Epoch 248/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6276.9922 - mae: 6276.9922\n",
      "Epoch 249/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6277.9150 - mae: 6277.9150\n",
      "Epoch 250/500\n",
      "9/9 [==============================] - 0s 423us/step - loss: 6266.7266 - mae: 6266.7266\n",
      "Epoch 251/500\n",
      "9/9 [==============================] - 0s 538us/step - loss: 6263.0439 - mae: 6263.0439\n",
      "Epoch 252/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6261.4380 - mae: 6261.4380\n",
      "Epoch 253/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6252.8105 - mae: 6252.8105\n",
      "Epoch 254/500\n",
      "9/9 [==============================] - 0s 542us/step - loss: 6250.6587 - mae: 6250.6587\n",
      "Epoch 255/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6245.0991 - mae: 6245.0991\n",
      "Epoch 256/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6239.9399 - mae: 6239.9399\n",
      "Epoch 257/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6235.4673 - mae: 6235.4673\n",
      "Epoch 258/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6234.9775 - mae: 6234.9775\n",
      "Epoch 259/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6230.3384 - mae: 6230.3384\n",
      "Epoch 260/500\n",
      "9/9 [==============================] - 0s 523us/step - loss: 6220.6587 - mae: 6220.6587\n",
      "Epoch 261/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6216.7217 - mae: 6216.7217\n",
      "Epoch 262/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 6211.3999 - mae: 6211.3999\n",
      "Epoch 263/500\n",
      "9/9 [==============================] - 0s 515us/step - loss: 6205.8086 - mae: 6205.8086\n",
      "Epoch 264/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6200.6201 - mae: 6200.6201\n",
      "Epoch 265/500\n",
      "9/9 [==============================] - 0s 420us/step - loss: 6195.8076 - mae: 6195.8076\n",
      "Epoch 266/500\n",
      "9/9 [==============================] - 0s 537us/step - loss: 6191.0234 - mae: 6191.0234\n",
      "Epoch 267/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6185.2178 - mae: 6185.2178\n",
      "Epoch 268/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6182.8359 - mae: 6182.8359\n",
      "Epoch 269/500\n",
      "9/9 [==============================] - 0s 537us/step - loss: 6174.9004 - mae: 6174.9004\n",
      "Epoch 270/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 6172.9624 - mae: 6172.9624\n",
      "Epoch 271/500\n",
      "9/9 [==============================] - 0s 611us/step - loss: 6168.3311 - mae: 6168.3311\n",
      "Epoch 272/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6160.2671 - mae: 6160.2671\n",
      "Epoch 273/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6151.3545 - mae: 6151.3545\n",
      "Epoch 274/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 6151.2549 - mae: 6151.2549\n",
      "Epoch 275/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6142.7207 - mae: 6142.7207\n",
      "Epoch 276/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6138.9780 - mae: 6138.9780\n",
      "Epoch 277/500\n",
      "9/9 [==============================] - 0s 444us/step - loss: 6130.7671 - mae: 6130.7671\n",
      "Epoch 278/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6126.4111 - mae: 6126.4111\n",
      "Epoch 279/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6122.2466 - mae: 6122.2466\n",
      "Epoch 280/500\n",
      "9/9 [==============================] - 0s 532us/step - loss: 6112.4546 - mae: 6112.4546\n",
      "Epoch 281/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6107.8032 - mae: 6107.8032\n",
      "Epoch 282/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6099.2300 - mae: 6099.2300\n",
      "Epoch 283/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6098.9204 - mae: 6098.9204\n",
      "Epoch 284/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6088.4546 - mae: 6088.4546\n",
      "Epoch 285/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6083.2065 - mae: 6083.2065\n",
      "Epoch 286/500\n",
      "9/9 [==============================] - 0s 598us/step - loss: 6075.7979 - mae: 6075.7979\n",
      "Epoch 287/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6075.1987 - mae: 6075.1987\n",
      "Epoch 288/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6065.8706 - mae: 6065.8706\n",
      "Epoch 289/500\n",
      "9/9 [==============================] - 0s 484us/step - loss: 6061.2271 - mae: 6061.2271\n",
      "Epoch 290/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6051.2446 - mae: 6051.2446\n",
      "Epoch 291/500\n",
      "9/9 [==============================] - 0s 529us/step - loss: 6046.3262 - mae: 6046.3262\n",
      "Epoch 292/500\n",
      "9/9 [==============================] - 0s 462us/step - loss: 6039.4443 - mae: 6039.4443\n",
      "Epoch 293/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6035.5059 - mae: 6035.5059\n",
      "Epoch 294/500\n",
      "9/9 [==============================] - 0s 421us/step - loss: 6031.4360 - mae: 6031.4360\n",
      "Epoch 295/500\n",
      "9/9 [==============================] - 0s 543us/step - loss: 6020.7598 - mae: 6020.7598\n",
      "Epoch 296/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6014.7046 - mae: 6014.7046\n",
      "Epoch 297/500\n",
      "9/9 [==============================] - 0s 332us/step - loss: 6007.4331 - mae: 6007.4331\n",
      "Epoch 298/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5999.3228 - mae: 5999.3228\n",
      "Epoch 299/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 5996.6509 - mae: 5996.6509\n",
      "Epoch 300/500\n",
      "9/9 [==============================] - 0s 484us/step - loss: 5990.2280 - mae: 5990.2280\n",
      "Epoch 301/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5977.9375 - mae: 5977.9375\n",
      "Epoch 302/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5973.6650 - mae: 5973.6650\n",
      "Epoch 303/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5967.9937 - mae: 5967.9937\n",
      "Epoch 304/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5956.8750 - mae: 5956.8750\n",
      "Epoch 305/500\n",
      "9/9 [==============================] - 0s 502us/step - loss: 5961.0093 - mae: 5961.0093\n",
      "Epoch 306/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5942.5103 - mae: 5942.5103\n",
      "Epoch 307/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5936.3301 - mae: 5936.3301\n",
      "Epoch 308/500\n",
      "9/9 [==============================] - 0s 553us/step - loss: 5931.7671 - mae: 5931.7671\n",
      "Epoch 309/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5920.5278 - mae: 5920.5278\n",
      "Epoch 310/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5913.9497 - mae: 5913.9497\n",
      "Epoch 311/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5906.1089 - mae: 5906.1089\n",
      "Epoch 312/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5898.7788 - mae: 5898.7788\n",
      "Epoch 313/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5894.4956 - mae: 5894.4956\n",
      "Epoch 314/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 443us/step - loss: 5882.2930 - mae: 5882.2930\n",
      "Epoch 315/500\n",
      "9/9 [==============================] - 0s 532us/step - loss: 5877.2910 - mae: 5877.2910\n",
      "Epoch 316/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5864.2935 - mae: 5864.2935\n",
      "Epoch 317/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5862.1729 - mae: 5862.1729\n",
      "Epoch 318/500\n",
      "9/9 [==============================] - 0s 503us/step - loss: 5853.9546 - mae: 5853.9546\n",
      "Epoch 319/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5841.7266 - mae: 5841.7266\n",
      "Epoch 320/500\n",
      "9/9 [==============================] - 0s 570us/step - loss: 5831.5034 - mae: 5831.5034\n",
      "Epoch 321/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5826.7559 - mae: 5826.7559\n",
      "Epoch 322/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5815.2075 - mae: 5815.2075\n",
      "Epoch 323/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5807.3447 - mae: 5807.3447\n",
      "Epoch 324/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5800.1982 - mae: 5800.1982\n",
      "Epoch 325/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 5794.8472 - mae: 5794.8472\n",
      "Epoch 326/500\n",
      "9/9 [==============================] - 0s 385us/step - loss: 5785.0210 - mae: 5785.0210\n",
      "Epoch 327/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5774.5703 - mae: 5774.5703\n",
      "Epoch 328/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5762.8809 - mae: 5762.8809\n",
      "Epoch 329/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5758.6562 - mae: 5758.6562\n",
      "Epoch 330/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5746.7427 - mae: 5746.7427\n",
      "Epoch 331/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 5736.0864 - mae: 5736.0864\n",
      "Epoch 332/500\n",
      "9/9 [==============================] - 0s 553us/step - loss: 5724.7559 - mae: 5724.7559\n",
      "Epoch 333/500\n",
      "9/9 [==============================] - 0s 501us/step - loss: 5715.1396 - mae: 5715.1396\n",
      "Epoch 334/500\n",
      "9/9 [==============================] - 0s 536us/step - loss: 5713.1758 - mae: 5713.1758\n",
      "Epoch 335/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5694.7651 - mae: 5694.7651\n",
      "Epoch 336/500\n",
      "9/9 [==============================] - 0s 423us/step - loss: 5689.0645 - mae: 5689.0645\n",
      "Epoch 337/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5678.1543 - mae: 5678.1543\n",
      "Epoch 338/500\n",
      "9/9 [==============================] - 0s 403us/step - loss: 5667.0112 - mae: 5667.0112\n",
      "Epoch 339/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5662.7832 - mae: 5662.7832\n",
      "Epoch 340/500\n",
      "9/9 [==============================] - 0s 531us/step - loss: 5648.4746 - mae: 5648.4746\n",
      "Epoch 341/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5640.5547 - mae: 5640.5547\n",
      "Epoch 342/500\n",
      "9/9 [==============================] - 0s 775us/step - loss: 5632.5542 - mae: 5632.5542\n",
      "Epoch 343/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5629.3384 - mae: 5629.3384\n",
      "Epoch 344/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5608.3174 - mae: 5608.3174\n",
      "Epoch 345/500\n",
      "9/9 [==============================] - 0s 532us/step - loss: 5600.5601 - mae: 5600.5601\n",
      "Epoch 346/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5591.1172 - mae: 5591.1172\n",
      "Epoch 347/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5586.0308 - mae: 5586.0308\n",
      "Epoch 348/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5569.7236 - mae: 5569.7236\n",
      "Epoch 349/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5559.2275 - mae: 5559.2275\n",
      "Epoch 350/500\n",
      "9/9 [==============================] - 0s 525us/step - loss: 5548.0454 - mae: 5548.0454\n",
      "Epoch 351/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5541.0020 - mae: 5541.0020\n",
      "Epoch 352/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5530.2471 - mae: 5530.2471\n",
      "Epoch 353/500\n",
      "9/9 [==============================] - 0s 420us/step - loss: 5516.3809 - mae: 5516.3809\n",
      "Epoch 354/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5506.5146 - mae: 5506.5146\n",
      "Epoch 355/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5493.2769 - mae: 5493.2769\n",
      "Epoch 356/500\n",
      "9/9 [==============================] - 0s 509us/step - loss: 5484.0498 - mae: 5484.0498\n",
      "Epoch 357/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5471.6958 - mae: 5471.6958\n",
      "Epoch 358/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5463.5557 - mae: 5463.5557\n",
      "Epoch 359/500\n",
      "9/9 [==============================] - 0s 428us/step - loss: 5451.2661 - mae: 5451.2661\n",
      "Epoch 360/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5437.6372 - mae: 5437.6372\n",
      "Epoch 361/500\n",
      "9/9 [==============================] - 0s 534us/step - loss: 5421.4790 - mae: 5421.4790\n",
      "Epoch 362/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5410.0391 - mae: 5410.0391\n",
      "Epoch 363/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5398.0854 - mae: 5398.0854\n",
      "Epoch 364/500\n",
      "9/9 [==============================] - 0s 407us/step - loss: 5384.3057 - mae: 5384.3057\n",
      "Epoch 365/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5370.3384 - mae: 5370.3384\n",
      "Epoch 366/500\n",
      "9/9 [==============================] - 0s 523us/step - loss: 5360.3823 - mae: 5360.3823\n",
      "Epoch 367/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5346.5156 - mae: 5346.5156\n",
      "Epoch 368/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5332.2427 - mae: 5332.2427\n",
      "Epoch 369/500\n",
      "9/9 [==============================] - 0s 416us/step - loss: 5327.4033 - mae: 5327.4033\n",
      "Epoch 370/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5309.5068 - mae: 5309.5068\n",
      "Epoch 371/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5290.4111 - mae: 5290.4111\n",
      "Epoch 372/500\n",
      "9/9 [==============================] - 0s 400us/step - loss: 5279.5815 - mae: 5279.5815\n",
      "Epoch 373/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5263.6040 - mae: 5263.6040\n",
      "Epoch 374/500\n",
      "9/9 [==============================] - 0s 394us/step - loss: 5248.9590 - mae: 5248.9590\n",
      "Epoch 375/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5235.9980 - mae: 5235.9980\n",
      "Epoch 376/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5224.1333 - mae: 5224.1333\n",
      "Epoch 377/500\n",
      "9/9 [==============================] - 0s 500us/step - loss: 5211.1685 - mae: 5211.1685\n",
      "Epoch 378/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5192.9961 - mae: 5192.9961\n",
      "Epoch 379/500\n",
      "9/9 [==============================] - 0s 429us/step - loss: 5188.2383 - mae: 5188.2383\n",
      "Epoch 380/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5167.6509 - mae: 5167.6509\n",
      "Epoch 381/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5164.3018 - mae: 5164.3018\n",
      "Epoch 382/500\n",
      "9/9 [==============================] - 0s 494us/step - loss: 5138.1221 - mae: 5138.1221\n",
      "Epoch 383/500\n",
      "9/9 [==============================] - 0s 332us/step - loss: 5117.6753 - mae: 5117.6753\n",
      "Epoch 384/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5102.8530 - mae: 5102.8530\n",
      "Epoch 385/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5086.5767 - mae: 5086.5767\n",
      "Epoch 386/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5071.0586 - mae: 5071.0586\n",
      "Epoch 387/500\n",
      "9/9 [==============================] - 0s 517us/step - loss: 5065.6025 - mae: 5065.6025\n",
      "Epoch 388/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5044.8960 - mae: 5044.8960\n",
      "Epoch 389/500\n",
      "9/9 [==============================] - 0s 399us/step - loss: 5021.3887 - mae: 5021.3887\n",
      "Epoch 390/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5015.5396 - mae: 5015.5396\n",
      "Epoch 391/500\n",
      "9/9 [==============================] - 0s 553us/step - loss: 4991.2773 - mae: 4991.2773\n",
      "Epoch 392/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4978.7661 - mae: 4978.7661\n",
      "Epoch 393/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4954.8164 - mae: 4954.8164\n",
      "Epoch 394/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 443us/step - loss: 4943.6763 - mae: 4943.6763\n",
      "Epoch 395/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4937.3159 - mae: 4937.3159\n",
      "Epoch 396/500\n",
      "9/9 [==============================] - 0s 400us/step - loss: 4906.9351 - mae: 4906.9351\n",
      "Epoch 397/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4891.1553 - mae: 4891.1553\n",
      "Epoch 398/500\n",
      "9/9 [==============================] - 0s 333us/step - loss: 4869.5806 - mae: 4869.5806\n",
      "Epoch 399/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4855.8809 - mae: 4855.8809\n",
      "Epoch 400/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4828.3511 - mae: 4828.3511\n",
      "Epoch 401/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4817.2539 - mae: 4817.2539\n",
      "Epoch 402/500\n",
      "9/9 [==============================] - 0s 537us/step - loss: 4797.4321 - mae: 4797.4321\n",
      "Epoch 403/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 4775.7417 - mae: 4775.7417\n",
      "Epoch 404/500\n",
      "9/9 [==============================] - 0s 436us/step - loss: 4753.5796 - mae: 4753.5796\n",
      "Epoch 405/500\n",
      "9/9 [==============================] - 0s 412us/step - loss: 4744.4839 - mae: 4744.4839\n",
      "Epoch 406/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 4723.7314 - mae: 4723.7314\n",
      "Epoch 407/500\n",
      "9/9 [==============================] - 0s 424us/step - loss: 4699.8965 - mae: 4699.8965\n",
      "Epoch 408/500\n",
      "9/9 [==============================] - 0s 393us/step - loss: 4674.7451 - mae: 4674.7451\n",
      "Epoch 409/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4657.6841 - mae: 4657.6841\n",
      "Epoch 410/500\n",
      "9/9 [==============================] - 0s 545us/step - loss: 4633.5898 - mae: 4633.5898\n",
      "Epoch 411/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4614.8760 - mae: 4614.8760\n",
      "Epoch 412/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4594.4536 - mae: 4594.4536\n",
      "Epoch 413/500\n",
      "9/9 [==============================] - 0s 423us/step - loss: 4586.0493 - mae: 4586.0493\n",
      "Epoch 414/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4570.3354 - mae: 4570.3354\n",
      "Epoch 415/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 4533.4194 - mae: 4533.4194\n",
      "Epoch 416/500\n",
      "9/9 [==============================] - 0s 389us/step - loss: 4523.2988 - mae: 4523.2988\n",
      "Epoch 417/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 4495.9849 - mae: 4495.9849\n",
      "Epoch 418/500\n",
      "9/9 [==============================] - 0s 543us/step - loss: 4473.6567 - mae: 4473.6567\n",
      "Epoch 419/500\n",
      "9/9 [==============================] - 0s 619us/step - loss: 4458.9312 - mae: 4458.9312\n",
      "Epoch 420/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4433.7393 - mae: 4433.7393\n",
      "Epoch 421/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4416.2646 - mae: 4416.2646\n",
      "Epoch 422/500\n",
      "9/9 [==============================] - 0s 540us/step - loss: 4391.9658 - mae: 4391.9658\n",
      "Epoch 423/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4381.1606 - mae: 4381.1606\n",
      "Epoch 424/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 4357.9111 - mae: 4357.9111\n",
      "Epoch 425/500\n",
      "9/9 [==============================] - 0s 534us/step - loss: 4332.1108 - mae: 4332.1108\n",
      "Epoch 426/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 4309.2671 - mae: 4309.2671\n",
      "Epoch 427/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 4308.6860 - mae: 4308.6860\n",
      "Epoch 428/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 4271.7451 - mae: 4271.7451\n",
      "Epoch 429/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 4257.0024 - mae: 4257.0024\n",
      "Epoch 430/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 4231.9014 - mae: 4231.9014\n",
      "Epoch 431/500\n",
      "9/9 [==============================] - 0s 503us/step - loss: 4212.1157 - mae: 4212.1157\n",
      "Epoch 432/500\n",
      "9/9 [==============================] - 0s 529us/step - loss: 4191.8076 - mae: 4191.8076\n",
      "Epoch 433/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4179.2056 - mae: 4179.2056\n",
      "Epoch 434/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4171.3179 - mae: 4171.3179\n",
      "Epoch 435/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4134.4375 - mae: 4134.4375\n",
      "Epoch 436/500\n",
      "9/9 [==============================] - 0s 438us/step - loss: 4116.9922 - mae: 4116.9922\n",
      "Epoch 437/500\n",
      "9/9 [==============================] - 0s 426us/step - loss: 4104.8369 - mae: 4104.8369\n",
      "Epoch 438/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 4094.7537 - mae: 4094.7537\n",
      "Epoch 439/500\n",
      "9/9 [==============================] - 0s 420us/step - loss: 4081.7832 - mae: 4081.7832\n",
      "Epoch 440/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4100.9424 - mae: 4100.9424\n",
      "Epoch 441/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 4048.7939 - mae: 4048.7939\n",
      "Epoch 442/500\n",
      "9/9 [==============================] - 0s 572us/step - loss: 4029.4260 - mae: 4029.4260\n",
      "Epoch 443/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 4022.2725 - mae: 4022.2725\n",
      "Epoch 444/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4005.5491 - mae: 4005.5491\n",
      "Epoch 445/500\n",
      "9/9 [==============================] - 0s 423us/step - loss: 3995.6506 - mae: 3995.6506\n",
      "Epoch 446/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3990.6392 - mae: 3990.6392\n",
      "Epoch 447/500\n",
      "9/9 [==============================] - 0s 539us/step - loss: 3977.7341 - mae: 3977.7341\n",
      "Epoch 448/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3970.6792 - mae: 3970.6792\n",
      "Epoch 449/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3963.0928 - mae: 3963.0928\n",
      "Epoch 450/500\n",
      "9/9 [==============================] - 0s 489us/step - loss: 3969.8552 - mae: 3969.8552\n",
      "Epoch 451/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3958.1846 - mae: 3958.1846\n",
      "Epoch 452/500\n",
      "9/9 [==============================] - 0s 332us/step - loss: 3940.6582 - mae: 3940.6582\n",
      "Epoch 453/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3954.6353 - mae: 3954.6353\n",
      "Epoch 454/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3937.4495 - mae: 3937.4490\n",
      "Epoch 455/500\n",
      "9/9 [==============================] - 0s 420us/step - loss: 3938.7280 - mae: 3938.7280\n",
      "Epoch 456/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3931.4458 - mae: 3931.4458\n",
      "Epoch 457/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3926.5078 - mae: 3926.5078\n",
      "Epoch 458/500\n",
      "9/9 [==============================] - 0s 535us/step - loss: 3923.1472 - mae: 3923.1472\n",
      "Epoch 459/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3917.8567 - mae: 3917.8567\n",
      "Epoch 460/500\n",
      "9/9 [==============================] - 0s 501us/step - loss: 3918.3086 - mae: 3918.3086\n",
      "Epoch 461/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3912.5488 - mae: 3912.5488\n",
      "Epoch 462/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3909.5039 - mae: 3909.5039\n",
      "Epoch 463/500\n",
      "9/9 [==============================] - 0s 484us/step - loss: 3908.6392 - mae: 3908.6392\n",
      "Epoch 464/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3900.4746 - mae: 3900.4746\n",
      "Epoch 465/500\n",
      "9/9 [==============================] - 0s 431us/step - loss: 3905.1104 - mae: 3905.1104\n",
      "Epoch 466/500\n",
      "9/9 [==============================] - 0s 543us/step - loss: 3900.9912 - mae: 3900.9912\n",
      "Epoch 467/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3897.0710 - mae: 3897.0710\n",
      "Epoch 468/500\n",
      "9/9 [==============================] - 0s 426us/step - loss: 3890.8926 - mae: 3890.8926\n",
      "Epoch 469/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3884.9373 - mae: 3884.9373\n",
      "Epoch 470/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3886.8242 - mae: 3886.8242\n",
      "Epoch 471/500\n",
      "9/9 [==============================] - 0s 512us/step - loss: 3889.1694 - mae: 3889.1694\n",
      "Epoch 472/500\n",
      "9/9 [==============================] - 0s 332us/step - loss: 3879.9846 - mae: 3879.9846\n",
      "Epoch 473/500\n",
      "9/9 [==============================] - 0s 387us/step - loss: 3877.5388 - mae: 3877.5388\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 443us/step - loss: 3880.4358 - mae: 3880.4358\n",
      "Epoch 475/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3883.1958 - mae: 3883.1958\n",
      "Epoch 476/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3889.6504 - mae: 3889.6504\n",
      "Epoch 477/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3870.9722 - mae: 3870.9722\n",
      "Epoch 478/500\n",
      "9/9 [==============================] - 0s 479us/step - loss: 3878.7385 - mae: 3878.7385\n",
      "Epoch 479/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3864.1011 - mae: 3864.1011\n",
      "Epoch 480/500\n",
      "9/9 [==============================] - 0s 504us/step - loss: 3877.4919 - mae: 3877.4919\n",
      "Epoch 481/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3876.9395 - mae: 3876.9395\n",
      "Epoch 482/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3875.1519 - mae: 3875.1519\n",
      "Epoch 483/500\n",
      "9/9 [==============================] - 0s 522us/step - loss: 3858.4150 - mae: 3858.4150\n",
      "Epoch 484/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3864.1917 - mae: 3864.1917\n",
      "Epoch 485/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 3859.5618 - mae: 3859.5618\n",
      "Epoch 486/500\n",
      "9/9 [==============================] - 0s 491us/step - loss: 3852.0945 - mae: 3852.0945\n",
      "Epoch 487/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3849.3408 - mae: 3849.3408\n",
      "Epoch 488/500\n",
      "9/9 [==============================] - 0s 403us/step - loss: 3843.9636 - mae: 3843.9636\n",
      "Epoch 489/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3843.9807 - mae: 3843.9807\n",
      "Epoch 490/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3841.2585 - mae: 3841.2585\n",
      "Epoch 491/500\n",
      "9/9 [==============================] - 0s 555us/step - loss: 3838.7649 - mae: 3838.7649\n",
      "Epoch 492/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3841.7988 - mae: 3841.7988\n",
      "Epoch 493/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3852.1572 - mae: 3852.1572\n",
      "Epoch 494/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3838.9587 - mae: 3838.9587\n",
      "Epoch 495/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3830.9607 - mae: 3830.9607\n",
      "Epoch 496/500\n",
      "9/9 [==============================] - 0s 664us/step - loss: 3842.0864 - mae: 3842.0864\n",
      "Epoch 497/500\n",
      "9/9 [==============================] - 0s 750us/step - loss: 3843.7861 - mae: 3843.7861\n",
      "Epoch 498/500\n",
      "9/9 [==============================] - 0s 666us/step - loss: 3831.6477 - mae: 3831.6477\n",
      "Epoch 499/500\n",
      "9/9 [==============================] - 0s 617us/step - loss: 3822.8918 - mae: 3822.8918\n",
      "Epoch 500/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3821.5466 - mae: 3821.5466\n"
     ]
    }
   ],
   "source": [
    "# set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_3.compile(loss = tf.keras.losses.mae,\n",
    "                         optimizer = tf.keras.optimizers.Adam(),\n",
    "                         metrics =['mae'])\n",
    "# 3. Fit the model\n",
    "history = insurance_model_3.fit(x_train,y_train, epochs =500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3dce82a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 355us/step - loss: 3802.4360 - mae: 3802.4360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3802.43603515625, 3802.43603515625]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate our third model\n",
    "insurance_model_3.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b0937e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'epochs')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history (also known as a loss curve or a training curve)\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.xlabel('loss')\n",
    "plt.ylabel('epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bf39f0",
   "metadata": {},
   "source": [
    "* How long should you train for ?\n",
    "it depends, however, EarlyStopping Callback which TensorFlow component you can add to your model to stop when it stop improving after a certain metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61cab04",
   "metadata": {},
   "source": [
    "## Preprocessing data(normalization and standardization)\n",
    "\n",
    "In terms of scaling values, neural networks tend to prefer normalization.\n",
    "\n",
    "If you're not sure which to use, you could try both and decide which to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c12a4d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the insurance DataFrame\n",
    "insurance = pd.read_csv('insurance.csv')\n",
    "insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f918d93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPfUlEQVR4nO3de6xlZX3G8e8DqFzUCJ2BTgE90ExUNDLgSG0wLZeqeEXbYMe0zYRYsQkmmtrUgZhCm0xD/9DaptU6iooXxPEKVWMdp17axIqDpeU6YSIjjEOZ4y2oNVDw1z/2Oi/H4czMZpi11zmzv59kZ6/1rrX2/p03M+c56123VBWSJAEcMnQBkqTFw1CQJDWGgiSpMRQkSY2hIElqDhu6gMdi2bJlNTMzM3QZkrSk3HDDDd+vquULLVvSoTAzM8OWLVuGLkOSlpQk393TMoePJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSc2SvqL5sZpZ9/lBvnf7FS8b5HslaV/cU5AkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkprdQSHJikq8kuS3JLUne1LUfk2RTkju696PnbXNJkm1JtiZ5cV+1SZIW1ueewoPAW6rqmcDzgYuTnAKsAzZX1UpgczdPt2wN8CzgPOBdSQ7tsT5J0m56C4Wquqeqvt1N/wS4DTgeOB+4qlvtKuBV3fT5wDVVdX9V3QlsA87oqz5J0iNN5JhCkhngNOCbwHFVdQ+MggM4tlvteODueZvt6Np2/6yLkmxJsmV2drbXuiVp2vQeCkmeCHwKeHNV3be3VRdoq0c0VG2oqtVVtXr58uUHqkxJEj2HQpLHMQqEj1bVp7vme5Os6JavAHZ17TuAE+dtfgKws8/6JEm/rM+zjwJcCdxWVe+Yt+g6YG03vRa4dl77miRPSHISsBK4vq/6JEmPdFiPn30m8EfATUlu7NouBa4ANiZ5HXAXcAFAVd2SZCNwK6Mzly6uqod6rE+StJveQqGq/p2FjxMAnLuHbdYD6/uqSZK0d17RLElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1vYVCkvcn2ZXk5nltlyf5XpIbu9dL5y27JMm2JFuTvLivuiRJe9bnnsIHgfMWaP/bqlrVvb4AkOQUYA3wrG6bdyU5tMfaJEkL6C0UqurrwA/HXP184Jqqur+q7gS2AWf0VZskaWFDHFN4Y5L/7oaXju7ajgfunrfOjq7tEZJclGRLki2zs7N91ypJU2XSofBu4NeBVcA9wNu79iywbi30AVW1oapWV9Xq5cuX91KkJE2riYZCVd1bVQ9V1S+A9/LwENEO4MR5q54A7JxkbZKkCYdCkhXzZl8NzJ2ZdB2wJskTkpwErASun2RtkiQ4rK8PTvIx4CxgWZIdwGXAWUlWMRoa2g68AaCqbkmyEbgVeBC4uKoe6qs2SdLCeguFqnrtAs1X7mX99cD6vuqRpsXMus8P9t3br3jZYN+tA8MrmiVJjaEgSWrGCoUkz+67EEnS8MY9pvBPSR7P6NYVV1fVj3uraAoMNebreK+kfRlrT6GqXgD8AaNrCbYkuTrJC3utTJI0cWMfU6iqO4C3AW8Ffhv4+yS3J/ndvoqTJE3WWMNHSZ4DXAi8DNgEvKKqvp3k14BvAJ/ur0RpaRry1FBpf417TOEfGN2W4tKq+vlcY1XtTPK2XiqTJE3cuKHwUuDnc1cZJzkEOLyq/reqPtxbdZKkiRr3mMKXgSPmzR/ZtUmSDiLjhsLhVfXTuZlu+sh+SpIkDWXcUPhZktPnZpI8F/j5XtaXJC1B4x5TeDPwiSRzzzhYAfx+LxVJkgYzVihU1beSPAN4OqOnpN1eVf/Xa2WSpIl7NLfOfh4w021zWhKq6kO9VKWDjrf2UJ/893XgjHvx2ocZPVv5RmDu4TcFGAqSdBAZd09hNXBKVVWfxUiShjXu2Uc3A7/aZyGSpOGNu6ewDLg1yfXA/XONVfXKXqqSJA1i3FC4vM8iJEmLw7inpH4tydOAlVX15SRHAof2W5okadLGfRzn64FPAu/pmo4HPttTTZKkgYx7oPli4EzgPmgP3Dm2r6IkScMYNxTur6oH5maSHMboOgVJ0kFk3FD4WpJLgSO6ZzN/Avjn/sqSJA1h3FBYB8wCNwFvAL7A6HnNkqSDyLhnH/2C0eM439tvOZKkIY1776M7WeAYQlWdfMArkrRkDXVjuqEM+fP2dTO+R3PvozmHAxcAxxz4ciRJQxrrmEJV/WDe63tV9U7gnH5LkyRN2rjDR6fPmz2E0Z7Dk3qpSJI0mHGHj94+b/pBYDvwmgNejSRpUOOefXR234Wof9N2EFDSozfu8NGf7m15Vb3jwJQjSRrSozn76HnAdd38K4CvA3f3UZQkaRiP5iE7p1fVTwCSXA58oqr+uK/CJEmTN+5tLp4KPDBv/gFg5oBXI0ka1Lih8GHg+iSXJ7kM+Cbwob1tkOT9SXYluXle2zFJNiW5o3s/et6yS5JsS7I1yYv354eRJD024168th64EPgR8GPgwqr6631s9kHgvN3a1gGbq2olsLmbJ8kpwBrgWd0270rik90kacLGPaYAcCRwX1V9IMnyJCdV1Z17Wrmqvp5kZrfm84GzuumrgK8Cb+3ar6mq+4E7k2wDzgC+8Sjqkx7B03ClR2fcx3FexuiX9yVd0+OAj+zH9x1XVfcAdO9zT287nl8+k2lH1yZJmqBxjym8Gngl8DOAqtrJgb3NRRZoW/DJbkkuSrIlyZbZ2dkDWIIkadxQeKCqiu4XdZKj9vP77k2yovuMFcCurn0HcOK89U4Adi70AVW1oapWV9Xq5cuX72cZkqSFjBsKG5O8B3hKktcDX2b/HrhzHbC2m14LXDuvfU2SJyQ5CVgJXL8fny9Jegz2eaA5SYCPA88A7gOeDvxFVW3ax3YfY3RQeVmSHcBlwBWMAuZ1wF2MnstAVd2SZCNwK6Mb7l1cVQ/t7w8lSdo/+wyFqqokn62q5wJ7DYLdtnvtHhadu4f11wPrx/18SdKBN+7w0X8keV6vlUiSBjfudQpnA3+SZDujM5DCaCfiOX0VJkmavL2GQpKnVtVdwEsmVI8kaUD72lP4LKO7o343yaeq6vcmUJMkaSD7OqYw/6Kyk/ssRJI0vH2FQu1hWpJ0ENrX8NGpSe5jtMdwRDcNDx9ofnKv1UmSJmqvoVBV3r5akqbIuNcpSJKmgKEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpOawIb40yXbgJ8BDwINVtTrJMcDHgRlgO/CaqvrREPVJ0rQack/h7KpaVVWru/l1wOaqWgls7uYlSRO0mIaPzgeu6qavAl41XCmSNJ2GCoUCvpTkhiQXdW3HVdU9AN37sQttmOSiJFuSbJmdnZ1QuZI0HQY5pgCcWVU7kxwLbEpy+7gbVtUGYAPA6tWrq68CJWkaDbKnUFU7u/ddwGeAM4B7k6wA6N53DVGbJE2ziYdCkqOSPGluGngRcDNwHbC2W20tcO2ka5OkaTfE8NFxwGeSzH3/1VX1xSTfAjYmeR1wF3DBALVJ0lSbeChU1XeAUxdo/wFw7qTrkSQ9bDGdkipJGpihIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpGbRhUKS85JsTbItybqh65GkabKoQiHJocA/Ai8BTgFem+SUYauSpOmxqEIBOAPYVlXfqaoHgGuA8weuSZKmxmFDF7Cb44G7583vAH5j/gpJLgIu6mZ/mmTrhGqbswz4/oS/czGyH0bshxH7YWRi/ZC/eUybP21PCxZbKGSBtvqlmaoNwIbJlPNISbZU1eqhvn+xsB9G7IcR+2HkYOiHxTZ8tAM4cd78CcDOgWqRpKmz2ELhW8DKJCcleTywBrhu4JokaWosquGjqnowyRuBfwEOBd5fVbcMXNbuBhu6WmTshxH7YcR+GFny/ZCq2vdakqSpsNiGjyRJAzIUJEmNobAHSU5M8pUktyW5JcmbuvZjkmxKckf3fvTQtfYpyeFJrk/yX10//GXXPlX9MCfJoUn+M8nnuvlp7YftSW5KcmOSLV3b1PVFkqck+WSS27vfFb+51PvBUNizB4G3VNUzgecDF3e33FgHbK6qlcDmbv5gdj9wTlWdCqwCzkvyfKavH+a8Cbht3vy09gPA2VW1at55+dPYF38HfLGqngGcyujfxtLuh6ryNcYLuBZ4IbAVWNG1rQC2Dl3bBPvgSODbjK4yn7p+YHTdzGbgHOBzXdvU9UP3s24Hlu3WNlV9ATwZuJPuhJ2DpR/cUxhDkhngNOCbwHFVdQ9A937sgKVNRDdkciOwC9hUVVPZD8A7gT8HfjGvbRr7AUZ3GvhSkhu6W8/A9PXFycAs8IFuSPF9SY5iifeDobAPSZ4IfAp4c1XdN3Q9Q6iqh6pqFaO/lM9I8uyBS5q4JC8HdlXVDUPXskicWVWnM7qj8cVJfmvoggZwGHA68O6qOg34GUttqGgBhsJeJHkco0D4aFV9umu+N8mKbvkKRn89T4Wq+jHwVeA8pq8fzgRemWQ7o7v3npPkI0xfPwBQVTu7913AZxjd4Xja+mIHsKPbcwb4JKOQWNL9YCjsQZIAVwK3VdU75i26DljbTa9ldKzhoJVkeZKndNNHAL8D3M6U9UNVXVJVJ1TVDKPbr/xrVf0hU9YPAEmOSvKkuWngRcDNTFlfVNX/AHcneXrXdC5wK0u8H7yieQ+SvAD4N+AmHh5DvpTRcYWNwFOBu4ALquqHgxQ5AUmeA1zF6LYjhwAbq+qvkvwKU9QP8yU5C/izqnr5NPZDkpMZ7R3AaAjl6qpaP6V9sQp4H/B44DvAhXT/T1ii/WAoSJIah48kSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNf8PTH1TnHBYtpEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x['age'].plot(kind = \"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8bb60e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x['bmi'].plot(kind= \"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d3629c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    574\n",
       "1    324\n",
       "2    240\n",
       "3    157\n",
       "4     25\n",
       "5     18\n",
       "Name: children, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['children'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a0c1d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Create a coloumn transformer\n",
    "ct = make_column_transformer(\n",
    "     (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), # Turn all values in these coloumns between 0 and 1\n",
    "     (OneHotEncoder(handle_unknown= \"ignore\"), [\"sex\", \"smoker\", \"region\"]))\n",
    "\n",
    "# Create x & y\n",
    "x = insurance.drop(\"charges\", axis = 1)\n",
    "y = insurance[\"charges\"] \n",
    "\n",
    "# Build our train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.8, random_state=42)\n",
    "\n",
    "# Fit the coloumn transformer to our training data\n",
    "ct.fit(x_train)\n",
    "\n",
    "# Transfrom training and test data with momalization (MinMaxSclaer) and OneHotEncoder\n",
    "x_train_normal = ct.transform(x_train)\n",
    "x_test_normal = ct.transform(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "471809c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7826087 , 0.49001137, 0.2       , 1.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does our data looks like\n",
    "x_train_normal[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c686b5b1",
   "metadata": {},
   "source": [
    "# Build a neural network model to fit on our normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5abaf922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13222.6807 - mae: 13222.6807WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "9/9 [==============================] - 0s 651us/step - loss: 13109.7461 - mae: 13109.7461\n",
      "Epoch 2/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 13108.4150 - mae: 13108.4150\n",
      "Epoch 3/500\n",
      "9/9 [==============================] - 0s 432us/step - loss: 13106.8613 - mae: 13106.8613\n",
      "Epoch 4/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 13104.9609 - mae: 13104.9609\n",
      "Epoch 5/500\n",
      "9/9 [==============================] - 0s 552us/step - loss: 13102.5791 - mae: 13102.5791\n",
      "Epoch 6/500\n",
      "9/9 [==============================] - 0s 370us/step - loss: 13099.5586 - mae: 13099.5586\n",
      "Epoch 7/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 13095.7412 - mae: 13095.7412\n",
      "Epoch 8/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 13090.9189 - mae: 13090.9189\n",
      "Epoch 9/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 13084.9268 - mae: 13084.9268\n",
      "Epoch 10/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 13077.5391 - mae: 13077.5391\n",
      "Epoch 11/500\n",
      "9/9 [==============================] - 0s 553us/step - loss: 13068.5137 - mae: 13068.5137\n",
      "Epoch 12/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 13057.6709 - mae: 13057.6709\n",
      "Epoch 13/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 13044.7979 - mae: 13044.7979\n",
      "Epoch 14/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 13029.6504 - mae: 13029.6504\n",
      "Epoch 15/500\n",
      "9/9 [==============================] - 0s 332us/step - loss: 13012.0762 - mae: 13012.0762\n",
      "Epoch 16/500\n",
      "9/9 [==============================] - 0s 535us/step - loss: 12991.7881 - mae: 12991.7881\n",
      "Epoch 17/500\n",
      "9/9 [==============================] - 0s 332us/step - loss: 12968.6738 - mae: 12968.6738\n",
      "Epoch 18/500\n",
      "9/9 [==============================] - 0s 551us/step - loss: 12942.4766 - mae: 12942.4766\n",
      "Epoch 19/500\n",
      "9/9 [==============================] - 0s 418us/step - loss: 12913.0088 - mae: 12913.0088\n",
      "Epoch 20/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 12880.0029 - mae: 12880.0029\n",
      "Epoch 21/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 12843.3730 - mae: 12843.3730\n",
      "Epoch 22/500\n",
      "9/9 [==============================] - 0s 685us/step - loss: 12802.9307 - mae: 12802.9307\n",
      "Epoch 23/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 12758.4824 - mae: 12758.4824\n",
      "Epoch 24/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 12709.7656 - mae: 12709.7656\n",
      "Epoch 25/500\n",
      "9/9 [==============================] - 0s 451us/step - loss: 12656.7588 - mae: 12656.7588\n",
      "Epoch 26/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 12599.1582 - mae: 12599.1582\n",
      "Epoch 27/500\n",
      "9/9 [==============================] - 0s 555us/step - loss: 12536.7871 - mae: 12536.7871\n",
      "Epoch 28/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 12469.3877 - mae: 12469.3877\n",
      "Epoch 29/500\n",
      "9/9 [==============================] - 0s 534us/step - loss: 12396.6914 - mae: 12396.6914\n",
      "Epoch 30/500\n",
      "9/9 [==============================] - 0s 332us/step - loss: 12318.9287 - mae: 12318.9287\n",
      "Epoch 31/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 12235.6475 - mae: 12235.6475\n",
      "Epoch 32/500\n",
      "9/9 [==============================] - 0s 591us/step - loss: 12146.3750 - mae: 12146.3750\n",
      "Epoch 33/500\n",
      "9/9 [==============================] - 0s 501us/step - loss: 12051.4482 - mae: 12051.4482\n",
      "Epoch 34/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 11950.3369 - mae: 11950.3369\n",
      "Epoch 35/500\n",
      "9/9 [==============================] - 0s 384us/step - loss: 11843.3418 - mae: 11843.3418\n",
      "Epoch 36/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 11730.6445 - mae: 11730.6445\n",
      "Epoch 37/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 11613.0664 - mae: 11613.0664\n",
      "Epoch 38/500\n",
      "9/9 [==============================] - 0s 541us/step - loss: 11491.6416 - mae: 11491.6416\n",
      "Epoch 39/500\n",
      "9/9 [==============================] - 0s 411us/step - loss: 11363.3525 - mae: 11363.3525\n",
      "Epoch 40/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 11232.5098 - mae: 11232.5098\n",
      "Epoch 41/500\n",
      "9/9 [==============================] - 0s 532us/step - loss: 11099.1592 - mae: 11099.1592\n",
      "Epoch 42/500\n",
      "9/9 [==============================] - 0s 524us/step - loss: 10966.3525 - mae: 10966.3525\n",
      "Epoch 43/500\n",
      "9/9 [==============================] - 0s 553us/step - loss: 10834.2490 - mae: 10834.2490\n",
      "Epoch 44/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 10705.3115 - mae: 10705.3115\n",
      "Epoch 45/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 10577.7822 - mae: 10577.7822\n",
      "Epoch 46/500\n",
      "9/9 [==============================] - 0s 477us/step - loss: 10455.5684 - mae: 10455.5684\n",
      "Epoch 47/500\n",
      "9/9 [==============================] - 0s 811us/step - loss: 10335.1465 - mae: 10335.1465\n",
      "Epoch 48/500\n",
      "9/9 [==============================] - 0s 663us/step - loss: 10214.1230 - mae: 10214.1230\n",
      "Epoch 49/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 10091.8105 - mae: 10091.8105\n",
      "Epoch 50/500\n",
      "9/9 [==============================] - 0s 595us/step - loss: 9971.3145 - mae: 9971.3145\n",
      "Epoch 51/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 9862.4717 - mae: 9862.4717\n",
      "Epoch 52/500\n",
      "9/9 [==============================] - 0s 523us/step - loss: 9751.8643 - mae: 9751.8643\n",
      "Epoch 53/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 9642.0371 - mae: 9642.0371\n",
      "Epoch 54/500\n",
      "9/9 [==============================] - 0s 553us/step - loss: 9537.5928 - mae: 9537.5928\n",
      "Epoch 55/500\n",
      "9/9 [==============================] - 0s 707us/step - loss: 9434.9297 - mae: 9434.9297\n",
      "Epoch 56/500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 9335.1318 - mae: 9335.1318\n",
      "Epoch 57/500\n",
      "9/9 [==============================] - 0s 553us/step - loss: 9237.7764 - mae: 9237.7764\n",
      "Epoch 58/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 9145.6309 - mae: 9145.6309\n",
      "Epoch 59/500\n",
      "9/9 [==============================] - 0s 501us/step - loss: 9055.3779 - mae: 9055.3779\n",
      "Epoch 60/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 8969.7578 - mae: 8969.7578\n",
      "Epoch 61/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 8883.1221 - mae: 8883.1221\n",
      "Epoch 62/500\n",
      "9/9 [==============================] - 0s 563us/step - loss: 8797.0889 - mae: 8797.0889\n",
      "Epoch 63/500\n",
      "9/9 [==============================] - 0s 553us/step - loss: 8720.6182 - mae: 8720.6182\n",
      "Epoch 64/500\n",
      "9/9 [==============================] - 0s 444us/step - loss: 8655.2148 - mae: 8655.2148\n",
      "Epoch 65/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 8596.7305 - mae: 8596.7305\n",
      "Epoch 66/500\n",
      "9/9 [==============================] - 0s 606us/step - loss: 8537.1182 - mae: 8537.1182\n",
      "Epoch 67/500\n",
      "9/9 [==============================] - 0s 539us/step - loss: 8487.2715 - mae: 8487.2715\n",
      "Epoch 68/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8436.9434 - mae: 8436.9434\n",
      "Epoch 69/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 8386.3926 - mae: 8386.3926\n",
      "Epoch 70/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 8343.1738 - mae: 8343.1738\n",
      "Epoch 71/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8296.9482 - mae: 8296.9482\n",
      "Epoch 72/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 8255.6279 - mae: 8255.6279\n",
      "Epoch 73/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 8222.7246 - mae: 8222.7246\n",
      "Epoch 74/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 8192.3965 - mae: 8192.3965\n",
      "Epoch 75/500\n",
      "9/9 [==============================] - 0s 727us/step - loss: 8165.2451 - mae: 8165.2451\n",
      "Epoch 76/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8140.0093 - mae: 8140.0093\n",
      "Epoch 77/500\n",
      "9/9 [==============================] - 0s 709us/step - loss: 8109.2959 - mae: 8109.2959\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 620us/step - loss: 8084.5664 - mae: 8084.5664\n",
      "Epoch 79/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 8060.2090 - mae: 8060.2090\n",
      "Epoch 80/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 8043.7573 - mae: 8043.7573\n",
      "Epoch 81/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 8024.8735 - mae: 8024.8735\n",
      "Epoch 82/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 8010.9512 - mae: 8010.9512\n",
      "Epoch 83/500\n",
      "9/9 [==============================] - 0s 773us/step - loss: 7995.7754 - mae: 7995.7754\n",
      "Epoch 84/500\n",
      "9/9 [==============================] - 0s 662us/step - loss: 7979.4307 - mae: 7979.4307\n",
      "Epoch 85/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7964.8828 - mae: 7964.8828\n",
      "Epoch 86/500\n",
      "9/9 [==============================] - 0s 566us/step - loss: 7949.7305 - mae: 7949.7305\n",
      "Epoch 87/500\n",
      "9/9 [==============================] - 0s 397us/step - loss: 7935.4355 - mae: 7935.4355\n",
      "Epoch 88/500\n",
      "9/9 [==============================] - 0s 423us/step - loss: 7922.0010 - mae: 7922.0010\n",
      "Epoch 89/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7907.9727 - mae: 7907.9727\n",
      "Epoch 90/500\n",
      "9/9 [==============================] - 0s 569us/step - loss: 7893.9663 - mae: 7893.9663\n",
      "Epoch 91/500\n",
      "9/9 [==============================] - 0s 462us/step - loss: 7882.4468 - mae: 7882.4468\n",
      "Epoch 92/500\n",
      "9/9 [==============================] - 0s 377us/step - loss: 7867.1987 - mae: 7867.1987\n",
      "Epoch 93/500\n",
      "9/9 [==============================] - 0s 495us/step - loss: 7854.8921 - mae: 7854.8921\n",
      "Epoch 94/500\n",
      "9/9 [==============================] - 0s 559us/step - loss: 7842.4697 - mae: 7842.4697\n",
      "Epoch 95/500\n",
      "9/9 [==============================] - 0s 404us/step - loss: 7830.4917 - mae: 7830.4917\n",
      "Epoch 96/500\n",
      "9/9 [==============================] - 0s 389us/step - loss: 7818.6807 - mae: 7818.6807\n",
      "Epoch 97/500\n",
      "9/9 [==============================] - 0s 610us/step - loss: 7806.6870 - mae: 7806.6870\n",
      "Epoch 98/500\n",
      "9/9 [==============================] - 0s 551us/step - loss: 7794.7373 - mae: 7794.7373\n",
      "Epoch 99/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7782.4502 - mae: 7782.4502\n",
      "Epoch 100/500\n",
      "9/9 [==============================] - 0s 527us/step - loss: 7771.2852 - mae: 7771.2852\n",
      "Epoch 101/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7758.5415 - mae: 7758.5415\n",
      "Epoch 102/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7746.2588 - mae: 7746.2588\n",
      "Epoch 103/500\n",
      "9/9 [==============================] - 0s 503us/step - loss: 7734.3862 - mae: 7734.3862\n",
      "Epoch 104/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7721.6528 - mae: 7721.6528\n",
      "Epoch 105/500\n",
      "9/9 [==============================] - 0s 538us/step - loss: 7709.6504 - mae: 7709.6504\n",
      "Epoch 106/500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 7698.6982 - mae: 7698.6982\n",
      "Epoch 107/500\n",
      "9/9 [==============================] - 0s 702us/step - loss: 7684.7593 - mae: 7684.7593\n",
      "Epoch 108/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7672.3931 - mae: 7672.3931\n",
      "Epoch 109/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7659.5146 - mae: 7659.5146\n",
      "Epoch 110/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7648.8809 - mae: 7648.8809\n",
      "Epoch 111/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7638.2471 - mae: 7638.2471\n",
      "Epoch 112/500\n",
      "9/9 [==============================] - 0s 504us/step - loss: 7624.6470 - mae: 7624.6470\n",
      "Epoch 113/500\n",
      "9/9 [==============================] - 0s 476us/step - loss: 7611.8496 - mae: 7611.8496\n",
      "Epoch 114/500\n",
      "9/9 [==============================] - 0s 664us/step - loss: 7599.5073 - mae: 7599.5073\n",
      "Epoch 115/500\n",
      "9/9 [==============================] - 0s 522us/step - loss: 7587.8145 - mae: 7587.8145\n",
      "Epoch 116/500\n",
      "9/9 [==============================] - 0s 497us/step - loss: 7575.4751 - mae: 7575.4751\n",
      "Epoch 117/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7563.3101 - mae: 7563.3101\n",
      "Epoch 118/500\n",
      "9/9 [==============================] - 0s 547us/step - loss: 7550.6748 - mae: 7550.6748\n",
      "Epoch 119/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7538.6104 - mae: 7538.6104\n",
      "Epoch 120/500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 7525.9673 - mae: 7525.9673\n",
      "Epoch 121/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7513.2749 - mae: 7513.2749\n",
      "Epoch 122/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7501.6509 - mae: 7501.6509\n",
      "Epoch 123/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7487.3169 - mae: 7487.3169\n",
      "Epoch 124/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7474.6587 - mae: 7474.6587\n",
      "Epoch 125/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7461.4487 - mae: 7461.4487\n",
      "Epoch 126/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7447.8726 - mae: 7447.8726\n",
      "Epoch 127/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7434.9756 - mae: 7434.9756\n",
      "Epoch 128/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7419.7104 - mae: 7419.7104\n",
      "Epoch 129/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7405.9424 - mae: 7405.9424\n",
      "Epoch 130/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7392.9141 - mae: 7392.9141\n",
      "Epoch 131/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7379.3271 - mae: 7379.3271\n",
      "Epoch 132/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7363.6416 - mae: 7363.6416\n",
      "Epoch 133/500\n",
      "9/9 [==============================] - 0s 555us/step - loss: 7349.2939 - mae: 7349.2939\n",
      "Epoch 134/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7335.7119 - mae: 7335.7119\n",
      "Epoch 135/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7321.5845 - mae: 7321.5850\n",
      "Epoch 136/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7307.9829 - mae: 7307.9829\n",
      "Epoch 137/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7293.2983 - mae: 7293.2983\n",
      "Epoch 138/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7278.8003 - mae: 7278.8003\n",
      "Epoch 139/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7265.3086 - mae: 7265.3086\n",
      "Epoch 140/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7249.9028 - mae: 7249.9028\n",
      "Epoch 141/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7235.0845 - mae: 7235.0845\n",
      "Epoch 142/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7220.6084 - mae: 7220.6084\n",
      "Epoch 143/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7205.2793 - mae: 7205.2793\n",
      "Epoch 144/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7191.4912 - mae: 7191.4912\n",
      "Epoch 145/500\n",
      "9/9 [==============================] - 0s 444us/step - loss: 7176.0806 - mae: 7176.0806\n",
      "Epoch 146/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7162.1528 - mae: 7162.1528\n",
      "Epoch 147/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7145.1411 - mae: 7145.1411\n",
      "Epoch 148/500\n",
      "9/9 [==============================] - 0s 478us/step - loss: 7129.9756 - mae: 7129.9756\n",
      "Epoch 149/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7113.8062 - mae: 7113.8062\n",
      "Epoch 150/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7098.0205 - mae: 7098.0205\n",
      "Epoch 151/500\n",
      "9/9 [==============================] - 0s 409us/step - loss: 7082.9165 - mae: 7082.9165\n",
      "Epoch 152/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7064.7856 - mae: 7064.7856\n",
      "Epoch 153/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 7048.1816 - mae: 7048.1816\n",
      "Epoch 154/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 7032.6011 - mae: 7032.6011\n",
      "Epoch 155/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 7016.9844 - mae: 7016.9844\n",
      "Epoch 156/500\n",
      "9/9 [==============================] - 0s 643us/step - loss: 6999.3901 - mae: 6999.3901\n",
      "Epoch 157/500\n",
      "9/9 [==============================] - 0s 476us/step - loss: 6980.9185 - mae: 6980.9185\n",
      "Epoch 158/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 522us/step - loss: 6964.5962 - mae: 6964.5962\n",
      "Epoch 159/500\n",
      "9/9 [==============================] - 0s 819us/step - loss: 6947.5449 - mae: 6947.5449\n",
      "Epoch 160/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 6930.3638 - mae: 6930.3638\n",
      "Epoch 161/500\n",
      "9/9 [==============================] - 0s 664us/step - loss: 6913.4946 - mae: 6913.4946\n",
      "Epoch 162/500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 6895.0674 - mae: 6895.0674\n",
      "Epoch 163/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6876.5596 - mae: 6876.5596\n",
      "Epoch 164/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6857.8467 - mae: 6857.8467\n",
      "Epoch 165/500\n",
      "9/9 [==============================] - 0s 555us/step - loss: 6838.9922 - mae: 6838.9922\n",
      "Epoch 166/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6821.0522 - mae: 6821.0522\n",
      "Epoch 167/500\n",
      "9/9 [==============================] - 0s 613us/step - loss: 6801.5425 - mae: 6801.5425\n",
      "Epoch 168/500\n",
      "9/9 [==============================] - 0s 539us/step - loss: 6782.3516 - mae: 6782.3516\n",
      "Epoch 169/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 6763.1709 - mae: 6763.1709\n",
      "Epoch 170/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6743.1768 - mae: 6743.1768\n",
      "Epoch 171/500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 6723.6929 - mae: 6723.6929\n",
      "Epoch 172/500\n",
      "9/9 [==============================] - 0s 513us/step - loss: 6703.3174 - mae: 6703.3174\n",
      "Epoch 173/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 6682.9951 - mae: 6682.9951\n",
      "Epoch 174/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6664.7856 - mae: 6664.7856\n",
      "Epoch 175/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6641.5356 - mae: 6641.5356\n",
      "Epoch 176/500\n",
      "9/9 [==============================] - 0s 517us/step - loss: 6620.9487 - mae: 6620.9487\n",
      "Epoch 177/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6599.4561 - mae: 6599.4561\n",
      "Epoch 178/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 6578.9331 - mae: 6578.9331\n",
      "Epoch 179/500\n",
      "9/9 [==============================] - 0s 499us/step - loss: 6557.1396 - mae: 6557.1396\n",
      "Epoch 180/500\n",
      "9/9 [==============================] - 0s 641us/step - loss: 6534.7354 - mae: 6534.7354\n",
      "Epoch 181/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6512.8960 - mae: 6512.8960\n",
      "Epoch 182/500\n",
      "9/9 [==============================] - 0s 421us/step - loss: 6491.0020 - mae: 6491.0020\n",
      "Epoch 183/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6469.1001 - mae: 6469.1001\n",
      "Epoch 184/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6447.1411 - mae: 6447.1411\n",
      "Epoch 185/500\n",
      "9/9 [==============================] - 0s 528us/step - loss: 6425.0220 - mae: 6425.0220\n",
      "Epoch 186/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6402.0610 - mae: 6402.0610\n",
      "Epoch 187/500\n",
      "9/9 [==============================] - 0s 534us/step - loss: 6379.0020 - mae: 6379.0020\n",
      "Epoch 188/500\n",
      "9/9 [==============================] - 0s 508us/step - loss: 6356.4604 - mae: 6356.4604\n",
      "Epoch 189/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 6331.1479 - mae: 6331.1479\n",
      "Epoch 190/500\n",
      "9/9 [==============================] - 0s 428us/step - loss: 6306.5088 - mae: 6306.5088\n",
      "Epoch 191/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6280.8140 - mae: 6280.8140\n",
      "Epoch 192/500\n",
      "9/9 [==============================] - 0s 500us/step - loss: 6254.4932 - mae: 6254.4932\n",
      "Epoch 193/500\n",
      "9/9 [==============================] - 0s 509us/step - loss: 6228.3389 - mae: 6228.3389\n",
      "Epoch 194/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 6202.1987 - mae: 6202.1987\n",
      "Epoch 195/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6175.1953 - mae: 6175.1953\n",
      "Epoch 196/500\n",
      "9/9 [==============================] - 0s 551us/step - loss: 6149.1479 - mae: 6149.1479\n",
      "Epoch 197/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6121.7295 - mae: 6121.7295\n",
      "Epoch 198/500\n",
      "9/9 [==============================] - 0s 553us/step - loss: 6095.8032 - mae: 6095.8032\n",
      "Epoch 199/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6066.5459 - mae: 6066.5459\n",
      "Epoch 200/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 6039.1187 - mae: 6039.1187\n",
      "Epoch 201/500\n",
      "9/9 [==============================] - 0s 552us/step - loss: 6009.8301 - mae: 6009.8301\n",
      "Epoch 202/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5980.1533 - mae: 5980.1533\n",
      "Epoch 203/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5950.3315 - mae: 5950.3315\n",
      "Epoch 204/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5919.6221 - mae: 5919.6221\n",
      "Epoch 205/500\n",
      "9/9 [==============================] - 0s 428us/step - loss: 5888.9634 - mae: 5888.9634\n",
      "Epoch 206/500\n",
      "9/9 [==============================] - 0s 503us/step - loss: 5857.0664 - mae: 5857.0664\n",
      "Epoch 207/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5826.4341 - mae: 5826.4341\n",
      "Epoch 208/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5794.8823 - mae: 5794.8823\n",
      "Epoch 209/500\n",
      "9/9 [==============================] - 0s 533us/step - loss: 5766.2217 - mae: 5766.2217\n",
      "Epoch 210/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5732.3584 - mae: 5732.3584\n",
      "Epoch 211/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 5702.5742 - mae: 5702.5742\n",
      "Epoch 212/500\n",
      "9/9 [==============================] - 0s 496us/step - loss: 5669.9331 - mae: 5669.9331\n",
      "Epoch 213/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5637.4302 - mae: 5637.4302\n",
      "Epoch 214/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 5606.7686 - mae: 5606.7686\n",
      "Epoch 215/500\n",
      "9/9 [==============================] - 0s 998us/step - loss: 5574.3193 - mae: 5574.3193\n",
      "Epoch 216/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 5541.9644 - mae: 5541.9644\n",
      "Epoch 217/500\n",
      "9/9 [==============================] - 0s 887us/step - loss: 5512.6997 - mae: 5512.6997\n",
      "Epoch 218/500\n",
      "9/9 [==============================] - 0s 775us/step - loss: 5475.1309 - mae: 5475.1309\n",
      "Epoch 219/500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 5443.7700 - mae: 5443.7700\n",
      "Epoch 220/500\n",
      "9/9 [==============================] - 0s 647us/step - loss: 5411.3101 - mae: 5411.3101\n",
      "Epoch 221/500\n",
      "9/9 [==============================] - 0s 693us/step - loss: 5374.4517 - mae: 5374.4517\n",
      "Epoch 222/500\n",
      "9/9 [==============================] - 0s 778us/step - loss: 5340.0698 - mae: 5340.0698\n",
      "Epoch 223/500\n",
      "9/9 [==============================] - 0s 701us/step - loss: 5302.7217 - mae: 5302.7217\n",
      "Epoch 224/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 5266.8237 - mae: 5266.8237\n",
      "Epoch 225/500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 5229.8389 - mae: 5229.8389\n",
      "Epoch 226/500\n",
      "9/9 [==============================] - 0s 809us/step - loss: 5195.0259 - mae: 5195.0259\n",
      "Epoch 227/500\n",
      "9/9 [==============================] - 0s 744us/step - loss: 5157.7451 - mae: 5157.7451\n",
      "Epoch 228/500\n",
      "9/9 [==============================] - 0s 784us/step - loss: 5123.1943 - mae: 5123.1943\n",
      "Epoch 229/500\n",
      "9/9 [==============================] - 0s 848us/step - loss: 5086.3521 - mae: 5086.3521\n",
      "Epoch 230/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 5050.8892 - mae: 5050.8892\n",
      "Epoch 231/500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 5013.6621 - mae: 5013.6621\n",
      "Epoch 232/500\n",
      "9/9 [==============================] - 0s 883us/step - loss: 4977.7363 - mae: 4977.7363\n",
      "Epoch 233/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4941.2534 - mae: 4941.2534\n",
      "Epoch 234/500\n",
      "9/9 [==============================] - 0s 611us/step - loss: 4905.1846 - mae: 4905.1846\n",
      "Epoch 235/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4868.7651 - mae: 4868.7651\n",
      "Epoch 236/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4834.2100 - mae: 4834.2100\n",
      "Epoch 237/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4797.7754 - mae: 4797.7754\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 443us/step - loss: 4765.7876 - mae: 4765.7876\n",
      "Epoch 239/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4732.0796 - mae: 4732.0796\n",
      "Epoch 240/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4699.3921 - mae: 4699.3921\n",
      "Epoch 241/500\n",
      "9/9 [==============================] - 0s 618us/step - loss: 4664.3291 - mae: 4664.3291\n",
      "Epoch 242/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4630.5635 - mae: 4630.5635\n",
      "Epoch 243/500\n",
      "9/9 [==============================] - 0s 538us/step - loss: 4596.7261 - mae: 4596.7261\n",
      "Epoch 244/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4562.0918 - mae: 4562.0918\n",
      "Epoch 245/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 4526.4751 - mae: 4526.4751\n",
      "Epoch 246/500\n",
      "9/9 [==============================] - 0s 555us/step - loss: 4492.9927 - mae: 4492.9927\n",
      "Epoch 247/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4462.0835 - mae: 4462.0835\n",
      "Epoch 248/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4431.7832 - mae: 4431.7832\n",
      "Epoch 249/500\n",
      "9/9 [==============================] - 0s 543us/step - loss: 4402.9409 - mae: 4402.9409\n",
      "Epoch 250/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4372.7603 - mae: 4372.7603\n",
      "Epoch 251/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4342.5000 - mae: 4342.5000\n",
      "Epoch 252/500\n",
      "9/9 [==============================] - 0s 511us/step - loss: 4314.7500 - mae: 4314.7500\n",
      "Epoch 253/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4286.3760 - mae: 4286.3760\n",
      "Epoch 254/500\n",
      "9/9 [==============================] - 0s 413us/step - loss: 4259.8042 - mae: 4259.8042\n",
      "Epoch 255/500\n",
      "9/9 [==============================] - 0s 524us/step - loss: 4234.3667 - mae: 4234.3667\n",
      "Epoch 256/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4210.4771 - mae: 4210.4771\n",
      "Epoch 257/500\n",
      "9/9 [==============================] - 0s 506us/step - loss: 4189.2319 - mae: 4189.2319\n",
      "Epoch 258/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4166.0308 - mae: 4166.0308\n",
      "Epoch 259/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 4143.9102 - mae: 4143.9102\n",
      "Epoch 260/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 4120.8491 - mae: 4120.8491\n",
      "Epoch 261/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4098.9629 - mae: 4098.9629\n",
      "Epoch 262/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 4077.2041 - mae: 4077.2041\n",
      "Epoch 263/500\n",
      "9/9 [==============================] - 0s 510us/step - loss: 4058.3623 - mae: 4058.3623\n",
      "Epoch 264/500\n",
      "9/9 [==============================] - 0s 480us/step - loss: 4034.6750 - mae: 4034.6750\n",
      "Epoch 265/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 4014.1643 - mae: 4014.1643\n",
      "Epoch 266/500\n",
      "9/9 [==============================] - 0s 406us/step - loss: 3993.8081 - mae: 3993.8081\n",
      "Epoch 267/500\n",
      "9/9 [==============================] - 0s 519us/step - loss: 3976.3577 - mae: 3976.3577\n",
      "Epoch 268/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3961.6052 - mae: 3961.6052\n",
      "Epoch 269/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3945.6882 - mae: 3945.6882\n",
      "Epoch 270/500\n",
      "9/9 [==============================] - 0s 510us/step - loss: 3933.1750 - mae: 3933.1750\n",
      "Epoch 271/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3917.7012 - mae: 3917.7012\n",
      "Epoch 272/500\n",
      "9/9 [==============================] - 0s 664us/step - loss: 3903.4072 - mae: 3903.4072\n",
      "Epoch 273/500\n",
      "9/9 [==============================] - 0s 404us/step - loss: 3886.4644 - mae: 3886.4644\n",
      "Epoch 274/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3873.8403 - mae: 3873.8403\n",
      "Epoch 275/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3860.4675 - mae: 3860.4675\n",
      "Epoch 276/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3846.0144 - mae: 3846.0144\n",
      "Epoch 277/500\n",
      "9/9 [==============================] - 0s 529us/step - loss: 3831.5000 - mae: 3831.5000\n",
      "Epoch 278/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3816.6765 - mae: 3816.6765\n",
      "Epoch 279/500\n",
      "9/9 [==============================] - 0s 506us/step - loss: 3806.2188 - mae: 3806.2188\n",
      "Epoch 280/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3794.3491 - mae: 3794.3491\n",
      "Epoch 281/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3784.3608 - mae: 3784.3608\n",
      "Epoch 282/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3777.5144 - mae: 3777.5144\n",
      "Epoch 283/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3766.6240 - mae: 3766.6240\n",
      "Epoch 284/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3760.1343 - mae: 3760.1343\n",
      "Epoch 285/500\n",
      "9/9 [==============================] - 0s 425us/step - loss: 3751.2090 - mae: 3751.2090\n",
      "Epoch 286/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3743.4033 - mae: 3743.4033\n",
      "Epoch 287/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3735.0029 - mae: 3735.0029\n",
      "Epoch 288/500\n",
      "9/9 [==============================] - 0s 428us/step - loss: 3730.8586 - mae: 3730.8586\n",
      "Epoch 289/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3726.6147 - mae: 3726.6147\n",
      "Epoch 290/500\n",
      "9/9 [==============================] - 0s 553us/step - loss: 3721.9832 - mae: 3721.9832\n",
      "Epoch 291/500\n",
      "9/9 [==============================] - 0s 538us/step - loss: 3717.5015 - mae: 3717.5015\n",
      "Epoch 292/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3714.0984 - mae: 3714.0984\n",
      "Epoch 293/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3711.2883 - mae: 3711.2883\n",
      "Epoch 294/500\n",
      "9/9 [==============================] - 0s 511us/step - loss: 3709.0125 - mae: 3709.0125\n",
      "Epoch 295/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3708.2178 - mae: 3708.2178\n",
      "Epoch 296/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3703.8550 - mae: 3703.8550\n",
      "Epoch 297/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3701.6248 - mae: 3701.6248\n",
      "Epoch 298/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3697.0996 - mae: 3697.0996\n",
      "Epoch 299/500\n",
      "9/9 [==============================] - 0s 368us/step - loss: 3694.1750 - mae: 3694.1750\n",
      "Epoch 300/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3690.8093 - mae: 3690.8093\n",
      "Epoch 301/500\n",
      "9/9 [==============================] - 0s 504us/step - loss: 3688.9695 - mae: 3688.9695\n",
      "Epoch 302/500\n",
      "9/9 [==============================] - 0s 512us/step - loss: 3684.2080 - mae: 3684.2080\n",
      "Epoch 303/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3682.8098 - mae: 3682.8098\n",
      "Epoch 304/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3680.3591 - mae: 3680.3591\n",
      "Epoch 305/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3678.0244 - mae: 3678.0244\n",
      "Epoch 306/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3675.2483 - mae: 3675.2483\n",
      "Epoch 307/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3673.1824 - mae: 3673.1824\n",
      "Epoch 308/500\n",
      "9/9 [==============================] - 0s 420us/step - loss: 3672.3274 - mae: 3672.3274\n",
      "Epoch 309/500\n",
      "9/9 [==============================] - 0s 484us/step - loss: 3671.6897 - mae: 3671.6897\n",
      "Epoch 310/500\n",
      "9/9 [==============================] - 0s 333us/step - loss: 3667.5608 - mae: 3667.5608\n",
      "Epoch 311/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3667.7588 - mae: 3667.7588\n",
      "Epoch 312/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3666.4802 - mae: 3666.4802\n",
      "Epoch 313/500\n",
      "9/9 [==============================] - 0s 426us/step - loss: 3666.7231 - mae: 3666.7231\n",
      "Epoch 314/500\n",
      "9/9 [==============================] - 0s 522us/step - loss: 3663.2756 - mae: 3663.2756\n",
      "Epoch 315/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3661.1985 - mae: 3661.1985\n",
      "Epoch 316/500\n",
      "9/9 [==============================] - 0s 450us/step - loss: 3661.0144 - mae: 3661.0144\n",
      "Epoch 317/500\n",
      "9/9 [==============================] - 0s 333us/step - loss: 3658.2478 - mae: 3658.2478\n",
      "Epoch 318/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 471us/step - loss: 3658.3054 - mae: 3658.3054\n",
      "Epoch 319/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3657.3970 - mae: 3657.3970\n",
      "Epoch 320/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 3655.3442 - mae: 3655.3442\n",
      "Epoch 321/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3655.4094 - mae: 3655.4094\n",
      "Epoch 322/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3655.2642 - mae: 3655.2642\n",
      "Epoch 323/500\n",
      "9/9 [==============================] - 0s 502us/step - loss: 3653.2415 - mae: 3653.2415\n",
      "Epoch 324/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3653.0635 - mae: 3653.0635\n",
      "Epoch 325/500\n",
      "9/9 [==============================] - 0s 421us/step - loss: 3651.2405 - mae: 3651.2405\n",
      "Epoch 326/500\n",
      "9/9 [==============================] - 0s 397us/step - loss: 3650.9331 - mae: 3650.9331\n",
      "Epoch 327/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3649.1904 - mae: 3649.1904\n",
      "Epoch 328/500\n",
      "9/9 [==============================] - 0s 565us/step - loss: 3647.6572 - mae: 3647.6572\n",
      "Epoch 329/500\n",
      "9/9 [==============================] - 0s 506us/step - loss: 3649.2773 - mae: 3649.2773\n",
      "Epoch 330/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3647.1367 - mae: 3647.1367\n",
      "Epoch 331/500\n",
      "9/9 [==============================] - 0s 546us/step - loss: 3645.6890 - mae: 3645.6890\n",
      "Epoch 332/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3644.9985 - mae: 3644.9985\n",
      "Epoch 333/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3643.6262 - mae: 3643.6262\n",
      "Epoch 334/500\n",
      "9/9 [==============================] - 0s 653us/step - loss: 3642.9214 - mae: 3642.9214\n",
      "Epoch 335/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3641.9463 - mae: 3641.9463\n",
      "Epoch 336/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3641.2180 - mae: 3641.2180\n",
      "Epoch 337/500\n",
      "9/9 [==============================] - 0s 510us/step - loss: 3640.2307 - mae: 3640.2307\n",
      "Epoch 338/500\n",
      "9/9 [==============================] - 0s 543us/step - loss: 3639.8560 - mae: 3639.8560\n",
      "Epoch 339/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3638.6165 - mae: 3638.6165\n",
      "Epoch 340/500\n",
      "9/9 [==============================] - 0s 618us/step - loss: 3638.1514 - mae: 3638.1514\n",
      "Epoch 341/500\n",
      "9/9 [==============================] - 0s 617us/step - loss: 3637.0356 - mae: 3637.0356\n",
      "Epoch 342/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3635.3931 - mae: 3635.3931\n",
      "Epoch 343/500\n",
      "9/9 [==============================] - 0s 411us/step - loss: 3635.3147 - mae: 3635.3147\n",
      "Epoch 344/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3634.8494 - mae: 3634.8494\n",
      "Epoch 345/500\n",
      "9/9 [==============================] - 0s 430us/step - loss: 3636.2415 - mae: 3636.2415\n",
      "Epoch 346/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3633.2659 - mae: 3633.2659\n",
      "Epoch 347/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3630.4202 - mae: 3630.4202\n",
      "Epoch 348/500\n",
      "9/9 [==============================] - 0s 486us/step - loss: 3630.5439 - mae: 3630.5439\n",
      "Epoch 349/500\n",
      "9/9 [==============================] - 0s 629us/step - loss: 3629.5762 - mae: 3629.5762\n",
      "Epoch 350/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3626.6948 - mae: 3626.6948\n",
      "Epoch 351/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3626.4988 - mae: 3626.4988\n",
      "Epoch 352/500\n",
      "9/9 [==============================] - 0s 501us/step - loss: 3625.7937 - mae: 3625.7937\n",
      "Epoch 353/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3625.1655 - mae: 3625.1655\n",
      "Epoch 354/500\n",
      "9/9 [==============================] - 0s 584us/step - loss: 3622.8918 - mae: 3622.8918\n",
      "Epoch 355/500\n",
      "9/9 [==============================] - 0s 502us/step - loss: 3621.4866 - mae: 3621.4866\n",
      "Epoch 356/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3620.5852 - mae: 3620.5852\n",
      "Epoch 357/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3622.1138 - mae: 3622.1138\n",
      "Epoch 358/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3618.0635 - mae: 3618.0635\n",
      "Epoch 359/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3618.2070 - mae: 3618.2070\n",
      "Epoch 360/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3616.5830 - mae: 3616.5830\n",
      "Epoch 361/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3615.8958 - mae: 3615.8958\n",
      "Epoch 362/500\n",
      "9/9 [==============================] - 0s 428us/step - loss: 3613.8662 - mae: 3613.8662\n",
      "Epoch 363/500\n",
      "9/9 [==============================] - 0s 416us/step - loss: 3612.8489 - mae: 3612.8489\n",
      "Epoch 364/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3612.0103 - mae: 3612.0103\n",
      "Epoch 365/500\n",
      "9/9 [==============================] - 0s 489us/step - loss: 3610.6902 - mae: 3610.6902\n",
      "Epoch 366/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3609.7849 - mae: 3609.7849\n",
      "Epoch 367/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3609.5627 - mae: 3609.5627\n",
      "Epoch 368/500\n",
      "9/9 [==============================] - 0s 418us/step - loss: 3607.2861 - mae: 3607.2861\n",
      "Epoch 369/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3606.6296 - mae: 3606.6296\n",
      "Epoch 370/500\n",
      "9/9 [==============================] - 0s 355us/step - loss: 3604.8770 - mae: 3604.8770\n",
      "Epoch 371/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3603.3567 - mae: 3603.3567\n",
      "Epoch 372/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3602.2227 - mae: 3602.2227\n",
      "Epoch 373/500\n",
      "9/9 [==============================] - 0s 505us/step - loss: 3601.8323 - mae: 3601.8323\n",
      "Epoch 374/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3599.7146 - mae: 3599.7146\n",
      "Epoch 375/500\n",
      "9/9 [==============================] - 0s 427us/step - loss: 3597.5916 - mae: 3597.5916\n",
      "Epoch 376/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3596.6514 - mae: 3596.6514\n",
      "Epoch 377/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 3595.7595 - mae: 3595.7595\n",
      "Epoch 378/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3594.4758 - mae: 3594.4758\n",
      "Epoch 379/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3593.7283 - mae: 3593.7283\n",
      "Epoch 380/500\n",
      "9/9 [==============================] - 0s 494us/step - loss: 3595.6384 - mae: 3595.6384\n",
      "Epoch 381/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3591.9336 - mae: 3591.9336\n",
      "Epoch 382/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3590.8188 - mae: 3590.8188\n",
      "Epoch 383/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3588.9426 - mae: 3588.9426\n",
      "Epoch 384/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 3587.6138 - mae: 3587.6138\n",
      "Epoch 385/500\n",
      "9/9 [==============================] - 0s 374us/step - loss: 3586.1064 - mae: 3586.1064\n",
      "Epoch 386/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3585.2009 - mae: 3585.2009\n",
      "Epoch 387/500\n",
      "9/9 [==============================] - 0s 484us/step - loss: 3583.3611 - mae: 3583.3611\n",
      "Epoch 388/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3582.4023 - mae: 3582.4023\n",
      "Epoch 389/500\n",
      "9/9 [==============================] - 0s 437us/step - loss: 3582.5117 - mae: 3582.5117\n",
      "Epoch 390/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3578.7429 - mae: 3578.7429\n",
      "Epoch 391/500\n",
      "9/9 [==============================] - 0s 553us/step - loss: 3578.0366 - mae: 3578.0366\n",
      "Epoch 392/500\n",
      "9/9 [==============================] - 0s 485us/step - loss: 3578.0872 - mae: 3578.0872\n",
      "Epoch 393/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3575.8142 - mae: 3575.8142\n",
      "Epoch 394/500\n",
      "9/9 [==============================] - 0s 505us/step - loss: 3575.9243 - mae: 3575.9243\n",
      "Epoch 395/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3573.5496 - mae: 3573.5496\n",
      "Epoch 396/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3571.3862 - mae: 3571.3862\n",
      "Epoch 397/500\n",
      "9/9 [==============================] - 0s 413us/step - loss: 3569.6536 - mae: 3569.6536\n",
      "Epoch 398/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 443us/step - loss: 3568.0710 - mae: 3568.0710\n",
      "Epoch 399/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3568.2097 - mae: 3568.2097\n",
      "Epoch 400/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3565.8174 - mae: 3565.8174\n",
      "Epoch 401/500\n",
      "9/9 [==============================] - 0s 506us/step - loss: 3566.0132 - mae: 3566.0132\n",
      "Epoch 402/500\n",
      "9/9 [==============================] - 0s 529us/step - loss: 3564.1672 - mae: 3564.1672\n",
      "Epoch 403/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3561.6123 - mae: 3561.6123\n",
      "Epoch 404/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3560.6521 - mae: 3560.6521\n",
      "Epoch 405/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3559.3931 - mae: 3559.3931\n",
      "Epoch 406/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3557.9478 - mae: 3557.9478\n",
      "Epoch 407/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3556.5388 - mae: 3556.5388\n",
      "Epoch 408/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3554.9304 - mae: 3554.9304\n",
      "Epoch 409/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3554.0381 - mae: 3554.0381\n",
      "Epoch 410/500\n",
      "9/9 [==============================] - 0s 552us/step - loss: 3552.5103 - mae: 3552.5103\n",
      "Epoch 411/500\n",
      "9/9 [==============================] - 0s 495us/step - loss: 3550.3230 - mae: 3550.3230\n",
      "Epoch 412/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3548.5291 - mae: 3548.5291\n",
      "Epoch 413/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3544.9424 - mae: 3544.9424\n",
      "Epoch 414/500\n",
      "9/9 [==============================] - 0s 503us/step - loss: 3547.1194 - mae: 3547.1194\n",
      "Epoch 415/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3542.9749 - mae: 3542.9749\n",
      "Epoch 416/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3541.7378 - mae: 3541.7378\n",
      "Epoch 417/500\n",
      "9/9 [==============================] - 0s 560us/step - loss: 3542.8655 - mae: 3542.8655\n",
      "Epoch 418/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3538.2732 - mae: 3538.2732\n",
      "Epoch 419/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3536.5459 - mae: 3536.5459\n",
      "Epoch 420/500\n",
      "9/9 [==============================] - 0s 552us/step - loss: 3534.8142 - mae: 3534.8142\n",
      "Epoch 421/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3533.4548 - mae: 3533.4548\n",
      "Epoch 422/500\n",
      "9/9 [==============================] - 0s 526us/step - loss: 3532.5349 - mae: 3532.5349\n",
      "Epoch 423/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3530.6514 - mae: 3530.6514\n",
      "Epoch 424/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3531.5540 - mae: 3531.5540\n",
      "Epoch 425/500\n",
      "9/9 [==============================] - 0s 535us/step - loss: 3527.8882 - mae: 3527.8882\n",
      "Epoch 426/500\n",
      "9/9 [==============================] - 0s 631us/step - loss: 3527.2019 - mae: 3527.2019\n",
      "Epoch 427/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3526.3518 - mae: 3526.3518\n",
      "Epoch 428/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3524.4204 - mae: 3524.4204\n",
      "Epoch 429/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3524.0183 - mae: 3524.0183\n",
      "Epoch 430/500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 3523.7542 - mae: 3523.7542\n",
      "Epoch 431/500\n",
      "9/9 [==============================] - 0s 445us/step - loss: 3521.2881 - mae: 3521.2881\n",
      "Epoch 432/500\n",
      "9/9 [==============================] - 0s 332us/step - loss: 3521.3486 - mae: 3521.3486\n",
      "Epoch 433/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3519.6492 - mae: 3519.6492\n",
      "Epoch 434/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3518.6250 - mae: 3518.6250\n",
      "Epoch 435/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 3518.6392 - mae: 3518.6392\n",
      "Epoch 436/500\n",
      "9/9 [==============================] - 0s 488us/step - loss: 3516.3743 - mae: 3516.3743\n",
      "Epoch 437/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3516.2690 - mae: 3516.2690\n",
      "Epoch 438/500\n",
      "9/9 [==============================] - 0s 652us/step - loss: 3515.8037 - mae: 3515.8037\n",
      "Epoch 439/500\n",
      "9/9 [==============================] - 0s 412us/step - loss: 3514.1628 - mae: 3514.1628\n",
      "Epoch 440/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3513.3936 - mae: 3513.3936\n",
      "Epoch 441/500\n",
      "9/9 [==============================] - 0s 407us/step - loss: 3512.1377 - mae: 3512.1377\n",
      "Epoch 442/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3511.4749 - mae: 3511.4749\n",
      "Epoch 443/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3510.8721 - mae: 3510.8721\n",
      "Epoch 444/500\n",
      "9/9 [==============================] - 0s 535us/step - loss: 3509.5952 - mae: 3509.5952\n",
      "Epoch 445/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3509.3289 - mae: 3509.3289\n",
      "Epoch 446/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 3508.7051 - mae: 3508.7051\n",
      "Epoch 447/500\n",
      "9/9 [==============================] - 0s 504us/step - loss: 3507.4468 - mae: 3507.4468\n",
      "Epoch 448/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3506.4897 - mae: 3506.4897\n",
      "Epoch 449/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3506.1504 - mae: 3506.1504\n",
      "Epoch 450/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3505.5063 - mae: 3505.5063\n",
      "Epoch 451/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3504.8774 - mae: 3504.8774\n",
      "Epoch 452/500\n",
      "9/9 [==============================] - 0s 531us/step - loss: 3504.2874 - mae: 3504.2874\n",
      "Epoch 453/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3502.0178 - mae: 3502.0178\n",
      "Epoch 454/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3501.5332 - mae: 3501.5332\n",
      "Epoch 455/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3499.9224 - mae: 3499.9224\n",
      "Epoch 456/500\n",
      "9/9 [==============================] - 0s 350us/step - loss: 3499.5847 - mae: 3499.5847\n",
      "Epoch 457/500\n",
      "9/9 [==============================] - 0s 541us/step - loss: 3497.9578 - mae: 3497.9578\n",
      "Epoch 458/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3498.2898 - mae: 3498.2898\n",
      "Epoch 459/500\n",
      "9/9 [==============================] - 0s 395us/step - loss: 3496.8674 - mae: 3496.8674\n",
      "Epoch 460/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3497.2400 - mae: 3497.2400\n",
      "Epoch 461/500\n",
      "9/9 [==============================] - 0s 509us/step - loss: 3496.7200 - mae: 3496.7200\n",
      "Epoch 462/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3494.7268 - mae: 3494.7268\n",
      "Epoch 463/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3494.0017 - mae: 3494.0017\n",
      "Epoch 464/500\n",
      "9/9 [==============================] - 0s 448us/step - loss: 3493.1978 - mae: 3493.1978\n",
      "Epoch 465/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3491.5911 - mae: 3491.5911\n",
      "Epoch 466/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 3490.7302 - mae: 3490.7302\n",
      "Epoch 467/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3490.1069 - mae: 3490.1069\n",
      "Epoch 468/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 3488.3945 - mae: 3488.3945\n",
      "Epoch 469/500\n",
      "9/9 [==============================] - 0s 424us/step - loss: 3488.2417 - mae: 3488.2417\n",
      "Epoch 470/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3486.3528 - mae: 3486.3528\n",
      "Epoch 471/500\n",
      "9/9 [==============================] - 0s 411us/step - loss: 3484.8730 - mae: 3484.8730\n",
      "Epoch 472/500\n",
      "9/9 [==============================] - 0s 444us/step - loss: 3484.6899 - mae: 3484.6899\n",
      "Epoch 473/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3483.2954 - mae: 3483.2954\n",
      "Epoch 474/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3483.8804 - mae: 3483.8804\n",
      "Epoch 475/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3481.7061 - mae: 3481.7061\n",
      "Epoch 476/500\n",
      "9/9 [==============================] - 0s 440us/step - loss: 3481.3142 - mae: 3481.3142\n",
      "Epoch 477/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3480.3552 - mae: 3480.3552\n",
      "Epoch 478/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 431us/step - loss: 3479.4949 - mae: 3479.4949\n",
      "Epoch 479/500\n",
      "9/9 [==============================] - 0s 421us/step - loss: 3478.0486 - mae: 3478.0486\n",
      "Epoch 480/500\n",
      "9/9 [==============================] - 0s 332us/step - loss: 3477.2644 - mae: 3477.2644\n",
      "Epoch 481/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3477.4368 - mae: 3477.4368\n",
      "Epoch 482/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3477.1431 - mae: 3477.1431\n",
      "Epoch 483/500\n",
      "9/9 [==============================] - 0s 398us/step - loss: 3475.1987 - mae: 3475.1987\n",
      "Epoch 484/500\n",
      "9/9 [==============================] - 0s 504us/step - loss: 3474.7773 - mae: 3474.7773\n",
      "Epoch 485/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3474.4019 - mae: 3474.4019\n",
      "Epoch 486/500\n",
      "9/9 [==============================] - 0s 416us/step - loss: 3474.0857 - mae: 3474.0857\n",
      "Epoch 487/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3472.1611 - mae: 3472.1611\n",
      "Epoch 488/500\n",
      "9/9 [==============================] - 0s 553us/step - loss: 3472.0632 - mae: 3472.0632\n",
      "Epoch 489/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3471.6631 - mae: 3471.6631\n",
      "Epoch 490/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3469.9780 - mae: 3469.9780\n",
      "Epoch 491/500\n",
      "9/9 [==============================] - 0s 442us/step - loss: 3468.3826 - mae: 3468.3826\n",
      "Epoch 492/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3468.3755 - mae: 3468.3755\n",
      "Epoch 493/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3467.5049 - mae: 3467.5049\n",
      "Epoch 494/500\n",
      "9/9 [==============================] - 0s 504us/step - loss: 3468.1174 - mae: 3468.1174\n",
      "Epoch 495/500\n",
      "9/9 [==============================] - 0s 526us/step - loss: 3466.9460 - mae: 3466.9460\n",
      "Epoch 496/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3468.8479 - mae: 3468.8479\n",
      "Epoch 497/500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 3463.8496 - mae: 3463.8496\n",
      "Epoch 498/500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 3462.2510 - mae: 3462.2510\n",
      "Epoch 499/500\n",
      "9/9 [==============================] - 0s 429us/step - loss: 3462.5369 - mae: 3462.5369\n",
      "Epoch 500/500\n",
      "9/9 [==============================] - 0s 484us/step - loss: 3462.5334 - mae: 3462.5334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d5e7be7e80>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tf.random.set_seed(42)\n",
    "    \n",
    "# 1. Create the model\n",
    "insurance_model_4= tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_4.compile(loss = tf.keras.losses.mae,\n",
    "                         optimizer = tf.keras.optimizers.Adam(),\n",
    "                         metrics = ['mae'])\n",
    "\n",
    "# Fit the model\n",
    "insurance_model_4.fit(x_train_normal, y_train, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "aba83740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 323us/step - loss: 3480.9514 - mae: 3480.9514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3480.951416015625, 3480.951416015625]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "insurance_model_4.evaluate(x_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60925fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
